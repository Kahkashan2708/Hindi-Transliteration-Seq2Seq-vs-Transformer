{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12723479,"sourceType":"datasetVersion","datasetId":8041935}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\nwandb.login(key=\"fb4c8007ed0d1fb692b2279b11bb69081f2c698d\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:16:02.595980Z","iopub.execute_input":"2025-08-30T06:16:02.596216Z","iopub.status.idle":"2025-08-30T06:16:11.131052Z","shell.execute_reply.started":"2025-08-30T06:16:02.596194Z","shell.execute_reply":"2025-08-30T06:16:11.130260Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma23c014\u001b[0m (\u001b[33mma23c014-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Repro \ndef set_seed(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# =============== Data ====================\nclass TransliterationDataset(Dataset):\n    def __init__(self, pairs, input_vocab, output_vocab):\n        self.pairs = pairs\n        self.input_vocab = input_vocab\n        self.output_vocab = output_vocab\n        self.sos = output_vocab['<sos>']\n        self.eos = output_vocab['<eos>']\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        source, target = self.pairs[idx]\n        # map OOV chars to <pad>=0 silently\n        input_ids = [self.input_vocab.get(c, 0) for c in source]\n        target_ids = [self.sos] + [self.output_vocab.get(c, 0) for c in target] + [self.eos]\n        return torch.tensor(input_ids, dtype=torch.long), torch.tensor(target_ids, dtype=torch.long)\n\ndef build_vocab(pairs):\n    input_chars = set()\n    output_chars = set()\n    for source, target in pairs:\n        input_chars.update(list(source))\n        output_chars.update(list(target))\n    # 0: <pad>\n    input_vocab = {c: i + 1 for i, c in enumerate(sorted(input_chars))}\n    input_vocab['<pad>'] = 0\n    # 0:<pad> 1:<sos> 2:<eos>\n    output_vocab = {c: i + 3 for i, c in enumerate(sorted(output_chars))}\n    output_vocab.update({'<pad>': 0, '<sos>': 1, '<eos>': 2})\n    return input_vocab, output_vocab\n\ndef invert_vocab(v):\n    return {i: c for c, i in v.items()}\n\ndef load_pairs(path):\n    # Dakshina TSV: target \\t source \\t count\n    df = pd.read_csv(path, sep=\"\\t\", header=None, names=[\"target\", \"source\", \"count\"], dtype=str)\n    df.dropna(subset=[\"source\", \"target\"], inplace=True)\n    # Strip whitespace just in case\n    df[\"source\"] = df[\"source\"].astype(str).str.strip()\n    df[\"target\"] = df[\"target\"].astype(str).str.strip()\n    return list(zip(df[\"source\"], df[\"target\"]))\n\ndef collate_fn(batch):\n    inputs, targets = zip(*batch)\n    input_lens = [len(seq) for seq in inputs]\n    target_lens = [len(seq) for seq in targets]\n    inputs_padded = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n    targets_padded = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=0)\n    return inputs_padded, targets_padded, input_lens, target_lens\n\n# =============== Models ==================\nclass Encoder(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, num_layers, cell_type, dropout):\n        super().__init__()\n        self.cell_type = cell_type\n        self.embedding = nn.Embedding(input_size, embed_size, padding_idx=0)\n        rnn_class = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[cell_type]\n        self.rnn = rnn_class(\n            embed_size, hidden_size, num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n\n    def forward(self, x, lengths):\n        x = self.embedding(x)  # (B, T, E)\n        packed = nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n        outputs, hidden = self.rnn(packed)\n        # We only need the final hidden(s) to initialize decoder\n        return hidden  # GRU/RNN: (num_layers, B, H). LSTM: tuple((num_layers, B, H), (num_layers, B, H))\n\nclass Decoder(nn.Module):\n    def __init__(self, output_size, embed_size, hidden_size, num_layers, cell_type, dropout):\n        super().__init__()\n        self.cell_type = cell_type\n        self.embedding = nn.Embedding(output_size, embed_size, padding_idx=0)\n        rnn_class = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[cell_type]\n        self.rnn = rnn_class(\n            embed_size, hidden_size, num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, input_token, hidden):\n        \"\"\"\n        input_token: (B,) longs\n        hidden: same type/shape as encoder hidden\n        returns: logits (B, V), new_hidden\n        \"\"\"\n        x = self.embedding(input_token).unsqueeze(1)  # (B, 1, E)\n        output, hidden = self.rnn(x, hidden)          # output: (B, 1, H)\n        logits = self.fc(output.squeeze(1))           # (B, V)\n        return logits, hidden\n\n    @torch.no_grad()\n    def beam_search(self, hidden, max_len, sos_idx, eos_idx, beam_size=3):\n        \"\"\"\n        Non-batched beam search (runs per sample). Handles LSTM/GRU hidden.\n        hidden is either:\n          - Tensor (num_layers, 1, H) OR\n          - Tuple(h, c) with each (num_layers, 1, H)\n        \"\"\"\n        device = next(self.parameters()).device\n\n        def clone_hidden(h):\n            if isinstance(h, tuple):\n                return (h[0].clone(), h[1].clone())\n            else:\n                return h.clone()\n\n        # Each item: (seq[LongTensor], hidden, log_prob)\n        start_seq = torch.tensor([sos_idx], device=device, dtype=torch.long)\n        sequences = [(start_seq, clone_hidden(hidden), 0.0)]\n        completed = []\n\n        for _ in range(max_len):\n            new_sequences = []\n            for seq, h, score in sequences:\n                last_token = seq[-1].view(1)  # (1,)\n                logits, new_h = self.forward(last_token, h)\n                log_probs = torch.log_softmax(logits, dim=-1).squeeze(0)  # (V,)\n                topk_logp, topk_idx = torch.topk(log_probs, beam_size)\n\n                for lp, idx in zip(topk_logp, topk_idx):\n                    idx = idx.item()\n                    new_seq = torch.cat([seq, torch.tensor([idx], device=device)])\n                    new_score = score + lp.item()\n                    new_sequences.append((new_seq, clone_hidden(new_h), new_score))\n\n            # Keep top-k\n            new_sequences.sort(key=lambda x: x[2], reverse=True)\n            sequences = new_sequences[:beam_size]\n\n            # Move completed to list\n            still_running = []\n            for seq, h, score in sequences:\n                if seq[-1].item() == eos_idx:\n                    completed.append((seq, h, score))\n                else:\n                    still_running.append((seq, h, score))\n            sequences = still_running\n            if not sequences:\n                break\n\n        if not completed:\n            completed = sequences\n        completed.sort(key=lambda x: x[2], reverse=True)\n        return completed[0][0]  # best seq\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, sos_idx=1, eos_idx=2, max_len=40):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.sos_idx = sos_idx\n        self.eos_idx = eos_idx\n        self.max_len = max_len\n\n    def forward(self, src, src_lens, tgt=None, teacher_forcing_ratio=0.5):\n        \"\"\"\n        If tgt is provided: training mode (returns logits over time).\n        Else: returns list of token sequences (beam search per sample).\n        \"\"\"\n        batch_size = src.size(0)\n        device = src.device\n\n        # Encode\n        hidden = self.encoder(src, src_lens)\n\n        if tgt is not None:\n            tgt_len = tgt.size(1)\n            vocab_size = self.decoder.fc.out_features\n            outputs = torch.zeros(batch_size, tgt_len, vocab_size, device=device)\n\n            input_token = tgt[:, 0]  # <sos>\n            dec_hidden = hidden\n\n            for t in range(1, tgt_len):\n                logits, dec_hidden = self.decoder(input_token, dec_hidden)\n                outputs[:, t] = logits\n                teacher_force = torch.rand(1, device=device).item() < teacher_forcing_ratio\n                next_token = tgt[:, t] if teacher_force else torch.argmax(logits, dim=-1)\n                input_token = next_token\n            return outputs\n        else:\n            # Inference: beam search per example with batch_size=1 hidden slices\n            sequences = []\n            # Split hidden for each item in batch\n            for b in range(batch_size):\n                if isinstance(hidden, tuple):\n                    h_b = tuple(h[:, b:b+1, :].contiguous() for h in hidden)\n                else:\n                    h_b = hidden[:, b:b+1, :].contiguous()\n                seq = self.decoder.beam_search(\n                    h_b, max_len=self.max_len, sos_idx=self.sos_idx, eos_idx=self.eos_idx, beam_size=3\n                )\n                sequences.append(seq)\n            return sequences\n\n# =============== Metrics =================\ndef char_accuracy(logits, targets, pad_idx=0):\n    \"\"\"\n    logits: (B, T, V), targets: (B, T)\n    \"\"\"\n    with torch.no_grad():\n        preds = logits.argmax(dim=-1)\n        mask = (targets != pad_idx)\n        correct = ((preds == targets) & mask).sum().item()\n        total = mask.sum().item()\n        return (correct / total) if total > 0 else 0.0\n\ndef levenshtein(a, b):\n    \"\"\"\n    Simple DP Levenshtein distance between two strings.\n    \"\"\"\n    n, m = len(a), len(b)\n    if n == 0: return m\n    if m == 0: return n\n    dp = [[0]*(m+1) for _ in range(n+1)]\n    for i in range(n+1): dp[i][0] = i\n    for j in range(m+1): dp[0][j] = j\n    for i in range(1, n+1):\n        for j in range(1, m+1):\n            cost = 0 if a[i-1] == b[j-1] else 1\n            dp[i][j] = min(\n                dp[i-1][j] + 1,      # delete\n                dp[i][j-1] + 1,      # insert\n                dp[i-1][j-1] + cost  # substitute\n            )\n    return dp[n][m]\n\ndef decode_greedy(model, src, src_lens, output_ivocab, max_len=40, sos_idx=1, eos_idx=2):\n    \"\"\"\n    Greedy decoding for batch (faster than beam for eval metrics).\n    Returns list of strings.\n    \"\"\"\n    model.eval()\n    device = src.device\n    batch_size = src.size(0)\n\n    # Encode\n    hidden = model.encoder(src, src_lens)\n\n    # Initialize\n    input_token = torch.full((batch_size,), sos_idx, dtype=torch.long, device=device)\n    dec_hidden = hidden\n    outputs = [[] for _ in range(batch_size)]\n\n    for _ in range(max_len):\n        logits, dec_hidden = model.decoder(input_token, dec_hidden)  # (B, V)\n        next_token = torch.argmax(logits, dim=-1)                    # (B,)\n        for b in range(batch_size):\n            outputs[b].append(next_token[b].item())\n        input_token = next_token\n\n    # Convert ids to strings, stopping at eos\n    decoded = []\n    for seq in outputs:\n        chars = []\n        for tok in seq:\n            if tok == eos_idx:\n                break\n            if tok in output_ivocab:\n                ch = output_ivocab[tok]\n                if ch not in ['<pad>', '<sos>', '<eos>']:\n                    chars.append(ch)\n        decoded.append(''.join(chars))\n    return decoded\n\ndef batch_word_accuracy_and_cer(pred_strs, tgt_strs):\n    \"\"\"\n    pred_strs, tgt_strs: lists of strings length B\n    Returns (word_acc, cer)\n    \"\"\"\n    assert len(pred_strs) == len(tgt_strs)\n    exact = 0\n    total_char_err = 0\n    total_char = 0\n    for p, t in zip(pred_strs, tgt_strs):\n        if p == t:\n            exact += 1\n        dist = levenshtein(p, t)\n        total_char_err += dist\n        total_char += max(len(t), 1)\n    word_acc = exact / len(pred_strs) if pred_strs else 0.0\n    cer = total_char_err / total_char if total_char > 0 else 0.0\n    return word_acc, cer\n\n# =============== Train/Eval ==============\ndef train_one_epoch(model, loader, optimizer, criterion, device, clip_norm=5.0, teacher_forcing_ratio=0.5):\n    model.train()\n    total_loss, total_acc = 0.0, 0.0\n    for src, tgt, src_lens, tgt_lens in tqdm(loader, desc=\"Training\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n        optimizer.zero_grad()\n        logits = model(src, src_lens, tgt, teacher_forcing_ratio=teacher_forcing_ratio)  # (B, T, V)\n        # shift to ignore first token (<sos> position 0)\n        loss = criterion(logits[:, 1:].reshape(-1, logits.size(-1)), tgt[:, 1:].reshape(-1))\n        acc = char_accuracy(logits[:, 1:], tgt[:, 1:])\n        loss.backward()\n        if clip_norm is not None:\n            nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_norm)\n        optimizer.step()\n        total_loss += loss.item()\n        total_acc += acc\n    n = len(loader)\n    return total_loss / n, total_acc / n\n\n@torch.no_grad()\ndef evaluate(model, loader, criterion, device, output_ivocab, eos_idx=2, sos_idx=1, max_len=40):\n    model.eval()\n    total_loss, total_char_acc = 0.0, 0.0\n    all_pred, all_gold = [], []\n    for src, tgt, src_lens, tgt_lens in tqdm(loader, desc=\"Evaluating\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n\n        # Teacher forcing OFF for loss/char-acc to mimic inference distribution\n        logits = model(src, src_lens, tgt, teacher_forcing_ratio=0.0)\n        loss = criterion(logits[:, 1:].reshape(-1, logits.size(-1)), tgt[:, 1:].reshape(-1))\n        acc = char_accuracy(logits[:, 1:], tgt[:, 1:])\n        total_loss += loss.item()\n        total_char_acc += acc\n\n        # Word-level metrics via greedy decode\n        batch_pred = decode_greedy(model, src, src_lens, output_ivocab, max_len=max_len, sos_idx=sos_idx, eos_idx=eos_idx)\n\n        # Convert gold to string for the same batch\n        gold_strs = []\n        for seq in tgt.cpu().numpy():\n            chars = []\n            for tok in seq[1:]:  # skip <sos>\n                if tok == eos_idx or tok == 0:\n                    break\n                ch = output_ivocab.get(int(tok), '')\n                if ch not in ['<pad>', '<sos>', '<eos>']:\n                    chars.append(ch)\n            gold_strs.append(''.join(chars))\n\n        all_pred.extend(batch_pred)\n        all_gold.extend(gold_strs)\n\n    n = len(loader)\n    avg_loss = total_loss / n if n > 0 else 0.0\n    avg_char_acc = total_char_acc / n if n > 0 else 0.0\n    word_acc, cer = batch_word_accuracy_and_cer(all_pred, all_gold)\n    return avg_loss, avg_char_acc, word_acc, cer\n\n# =============== Main / W&B =============\ndef main():\n    # This function is called by wandb.agent in a sweep\n    config = wandb.config\n\n    # Give each run a readable name\n    run_name = f\"cell:{config.cell_type}_emb:{config.embed_size}_hid:{config.hidden_size}_L:{config.num_layers}_bs:{config.batch_size}_lr:{config.lr}\"\n    if hasattr(wandb.run, \"name\") and (wandb.run.name is None or wandb.run.name == \"\"):\n        wandb.run.name = run_name\n\n    set_seed(42)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # ---- Data ----\n    train_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    dev_pairs   = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\")\n\n    input_vocab, output_vocab = build_vocab(train_pairs)\n    output_ivocab = invert_vocab(output_vocab)\n\n    train_dataset = TransliterationDataset(train_pairs, input_vocab, output_vocab)\n    dev_dataset   = TransliterationDataset(dev_pairs,   input_vocab, output_vocab)\n\n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True,  collate_fn=collate_fn)\n    dev_loader   = DataLoader(dev_dataset,   batch_size=config.batch_size, shuffle=False, collate_fn=collate_fn)\n\n    # ---- Model ----\n    encoder = Encoder(\n        input_size=len(input_vocab),\n        embed_size=config.embed_size,\n        hidden_size=config.hidden_size,\n        num_layers=config.num_layers,\n        cell_type=config.cell_type,\n        dropout=config.dropout\n    )\n    decoder = Decoder(\n        output_size=len(output_vocab),\n        embed_size=config.embed_size,\n        hidden_size=config.hidden_size,\n        num_layers=config.num_layers,\n        cell_type=config.cell_type,\n        dropout=config.dropout\n    )\n    model = Seq2Seq(\n        encoder=encoder,\n        decoder=decoder,\n        sos_idx=output_vocab['<sos>'],\n        eos_idx=output_vocab['<eos>'],\n        max_len=40\n    ).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    best_val_word_acc = -1.0\n\n    for epoch in range(config.epochs):\n        train_loss, train_char_acc = train_one_epoch(\n            model, train_loader, optimizer, criterion, device,\n            clip_norm=5.0,\n            teacher_forcing_ratio=getattr(config, \"teacher_forcing\", 0.5)\n        )\n        val_loss, val_char_acc, val_word_acc, val_cer = evaluate(\n            model, dev_loader, criterion, device, output_ivocab,\n            eos_idx=output_vocab['<eos>'], sos_idx=output_vocab['<sos>'], max_len=40\n        )\n\n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss,\n            \"train_char_accuracy\": train_char_acc,\n            \"val_loss\": val_loss,\n            \"val_char_accuracy\": val_char_acc,\n            \"val_word_accuracy\": val_word_acc,\n            \"val_CER\": val_cer\n        })\n\n        # Save best on word accuracy\n        if val_word_acc > best_val_word_acc:\n            best_val_word_acc = val_word_acc\n            save_path = os.path.join(wandb.run.dir, \"best_model.pt\")\n            torch.save({\n                \"model_state\": model.state_dict(),\n                \"config\": dict(config),\n                \"input_vocab\": input_vocab,\n                \"output_vocab\": output_vocab\n            }, save_path)\n            wandb.log({\"best_model_path\": save_path, \"best_val_word_accuracy\": best_val_word_acc})\n\n# =============== Entry ================\nif __name__ == \"__main__\":\n    # Define sweep if running this file directly.\n    sweep_config = {\n        \"method\": \"bayes\",\n        \"metric\": {\"name\": \"val_word_accuracy\", \"goal\": \"maximize\"},\n        \"parameters\": {\n            \"embed_size\":  {\"values\": [64, 128]},\n            \"hidden_size\": {\"values\": [128, 256]},\n            \"num_layers\":  {\"values\": [1, 2]},\n            \"cell_type\":   {\"values\": [\"GRU\", \"LSTM\"]},\n            \"dropout\":     {\"values\": [0.1, 0.2, 0.3]},\n            \"lr\":          {\"min\": 1e-4, \"max\": 5e-3},\n            \"batch_size\":  {\"values\": [32, 64]},\n            \"epochs\":      {\"values\": [8]},                  \n            \"teacher_forcing\": {\"values\": [0.5, 0.6, 0.7]},\n        }\n    }\n\n    # Initialize sweep\n    sweep_id = wandb.sweep(sweep_config, project=\"Dakshina-Transliteration\")\n\n    # The function given here must call wandb.init() internally; we do that implicitly when wandb.agent starts a run.\n    # We'll initialize the run at the top of main via wandb.config access.\n    def sweep_main():\n        # Make sure a run is created and config is readable\n        wandb.init(project=\"Dakshina-Transliteration\")\n        main()\n        wandb.finish()\n\n    # Launch N runs (adjust count as you like)\n    wandb.agent(sweep_id, function=sweep_main, count=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T15:45:27.279927Z","iopub.execute_input":"2025-08-29T15:45:27.280647Z","iopub.status.idle":"2025-08-29T16:27:48.877982Z","shell.execute_reply.started":"2025-08-29T15:45:27.280623Z","shell.execute_reply":"2025-08-29T16:27:48.877412Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: r72d84fg\nSweep URL: https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vfoo6bub with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0003808171759622872\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing: 0.6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250829_154541-vfoo6bub</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/vfoo6bub' target=\"_blank\">fiery-sweep-1</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/vfoo6bub' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/vfoo6bub</a>"},"metadata":{}},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_word_accuracy</td><td>▁▄▆▇▇▇██</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▅▆▇▇███</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▁▁▁</td></tr><tr><td>val_CER</td><td>█▄▃▂▂▂▁▁</td></tr><tr><td>val_char_accuracy</td><td>▁▅▆▇▇▇██</td></tr><tr><td>val_loss</td><td>█▄▂▂▁▁▁▁</td></tr><tr><td>val_word_accuracy</td><td>▁▄▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_model_path</td><td>/kaggle/working/wand...</td></tr><tr><td>best_val_word_accuracy</td><td>0.36508</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_char_accuracy</td><td>0.85783</td></tr><tr><td>train_loss</td><td>0.48068</td></tr><tr><td>val_CER</td><td>0.19339</td></tr><tr><td>val_char_accuracy</td><td>0.71221</td></tr><tr><td>val_loss</td><td>1.10285</td></tr><tr><td>val_word_accuracy</td><td>0.36508</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fiery-sweep-1</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/vfoo6bub' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/vfoo6bub</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250829_154541-vfoo6bub/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t8o82lp7 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.004006031483882168\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing: 0.7\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250829_154928-t8o82lp7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/t8o82lp7' target=\"_blank\">fanciful-sweep-2</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/t8o82lp7' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/t8o82lp7</a>"},"metadata":{}},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_word_accuracy</td><td>▁▄▆▇█</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁</td></tr><tr><td>val_CER</td><td>█▄▂▂▁▁▁▁</td></tr><tr><td>val_char_accuracy</td><td>▁▅▇▇█▇██</td></tr><tr><td>val_loss</td><td>█▁▂▄▂▆▄▃</td></tr><tr><td>val_word_accuracy</td><td>▁▄▆▇█▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_model_path</td><td>/kaggle/working/wand...</td></tr><tr><td>best_val_word_accuracy</td><td>0.34901</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_char_accuracy</td><td>0.85539</td></tr><tr><td>train_loss</td><td>0.47978</td></tr><tr><td>val_CER</td><td>0.21462</td></tr><tr><td>val_char_accuracy</td><td>0.69458</td></tr><tr><td>val_loss</td><td>1.27966</td></tr><tr><td>val_word_accuracy</td><td>0.33846</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fanciful-sweep-2</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/t8o82lp7' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/t8o82lp7</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250829_154928-t8o82lp7/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7yjwxans with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0040177054683746575\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing: 0.7\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250829_155550-7yjwxans</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/7yjwxans' target=\"_blank\">eager-sweep-3</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/7yjwxans' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/7yjwxans</a>"},"metadata":{}},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_word_accuracy</td><td>▁▅█</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▇██████</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁</td></tr><tr><td>val_CER</td><td>█▃▂▁▃▂▄▃</td></tr><tr><td>val_char_accuracy</td><td>▁██▇▆▆▇▆</td></tr><tr><td>val_loss</td><td>▂▁▄▆▇▇▆█</td></tr><tr><td>val_word_accuracy</td><td>▁▅▄█▃▄▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_model_path</td><td>/kaggle/working/wand...</td></tr><tr><td>best_val_word_accuracy</td><td>0.23612</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_char_accuracy</td><td>0.78217</td></tr><tr><td>train_loss</td><td>0.72892</td></tr><tr><td>val_CER</td><td>0.29513</td></tr><tr><td>val_char_accuracy</td><td>0.61144</td></tr><tr><td>val_loss</td><td>1.57366</td></tr><tr><td>val_word_accuracy</td><td>0.22602</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">eager-sweep-3</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/7yjwxans' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/7yjwxans</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250829_155550-7yjwxans/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ai2v3o7k with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00343904249198481\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing: 0.6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250829_160044-ai2v3o7k</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/ai2v3o7k' target=\"_blank\">deep-sweep-4</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/ai2v3o7k' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/ai2v3o7k</a>"},"metadata":{}},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_word_accuracy</td><td>▁▅▆▆▇██</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▅▆▇▇███</td></tr><tr><td>train_loss</td><td>█▄▂▂▂▁▁▁</td></tr><tr><td>val_CER</td><td>█▄▃▃▁▁▁▁</td></tr><tr><td>val_char_accuracy</td><td>▁▄▅▆▇▇██</td></tr><tr><td>val_loss</td><td>█▃▅▄▂▃▁▂</td></tr><tr><td>val_word_accuracy</td><td>▁▅▆▆▇█▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_model_path</td><td>/kaggle/working/wand...</td></tr><tr><td>best_val_word_accuracy</td><td>0.2726</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_char_accuracy</td><td>0.80944</td></tr><tr><td>train_loss</td><td>0.6347</td></tr><tr><td>val_CER</td><td>0.26142</td></tr><tr><td>val_char_accuracy</td><td>0.65155</td></tr><tr><td>val_loss</td><td>1.32382</td></tr><tr><td>val_word_accuracy</td><td>0.2726</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">deep-sweep-4</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/ai2v3o7k' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/ai2v3o7k</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250829_160044-ai2v3o7k/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a0euzo9m with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.004647932765344562\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing: 0.6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250829_160541-a0euzo9m</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/a0euzo9m' target=\"_blank\">floral-sweep-5</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/a0euzo9m' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/a0euzo9m</a>"},"metadata":{}},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_word_accuracy</td><td>▁▅▆▇▇█</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▆▇▇████</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁</td></tr><tr><td>val_CER</td><td>█▃▂▂▂▁▁▁</td></tr><tr><td>val_char_accuracy</td><td>▁▅▇▇▇▇▇█</td></tr><tr><td>val_loss</td><td>██▃▃▃▂▂▁</td></tr><tr><td>val_word_accuracy</td><td>▁▅▆▇▇▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_model_path</td><td>/kaggle/working/wand...</td></tr><tr><td>best_val_word_accuracy</td><td>0.26801</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_char_accuracy</td><td>0.75671</td></tr><tr><td>train_loss</td><td>0.80208</td></tr><tr><td>val_CER</td><td>0.25849</td></tr><tr><td>val_char_accuracy</td><td>0.64901</td></tr><tr><td>val_loss</td><td>1.28939</td></tr><tr><td>val_word_accuracy</td><td>0.26801</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">floral-sweep-5</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/a0euzo9m' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/a0euzo9m</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250829_160541-a0euzo9m/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nflv14df with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0017376366776770415\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing: 0.5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250829_160934-nflv14df</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/nflv14df' target=\"_blank\">deft-sweep-6</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/nflv14df' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/nflv14df</a>"},"metadata":{}},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_word_accuracy</td><td>▁▅▆▇▇█</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁</td></tr><tr><td>val_CER</td><td>█▃▂▂▃▂▁▂</td></tr><tr><td>val_char_accuracy</td><td>▁▄▆▇▆▇█▇</td></tr><tr><td>val_loss</td><td>▆▁▂▂▃▅▅█</td></tr><tr><td>val_word_accuracy</td><td>▁▅▆▇▇▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_model_path</td><td>/kaggle/working/wand...</td></tr><tr><td>best_val_word_accuracy</td><td>0.32859</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_char_accuracy</td><td>0.86687</td></tr><tr><td>train_loss</td><td>0.44526</td></tr><tr><td>val_CER</td><td>0.21435</td></tr><tr><td>val_char_accuracy</td><td>0.69214</td></tr><tr><td>val_loss</td><td>1.22419</td></tr><tr><td>val_word_accuracy</td><td>0.31643</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">deft-sweep-6</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/nflv14df' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/nflv14df</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250829_160934-nflv14df/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dt051nwy with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.004869115139146405\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing: 0.7\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250829_161531-dt051nwy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/dt051nwy' target=\"_blank\">winter-sweep-7</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/dt051nwy' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/dt051nwy</a>"},"metadata":{}},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_word_accuracy</td><td>▁▄▆▇█</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▇▇█████</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁</td></tr><tr><td>val_CER</td><td>█▄▂▂▂▁▁▁</td></tr><tr><td>val_char_accuracy</td><td>▁▅▆▇▇▇▇█</td></tr><tr><td>val_loss</td><td>█▆▄▄▃▃▂▁</td></tr><tr><td>val_word_accuracy</td><td>▁▄▆▇▆▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_model_path</td><td>/kaggle/working/wand...</td></tr><tr><td>best_val_word_accuracy</td><td>0.22625</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_char_accuracy</td><td>0.72255</td></tr><tr><td>train_loss</td><td>0.91394</td></tr><tr><td>val_CER</td><td>0.29833</td></tr><tr><td>val_char_accuracy</td><td>0.61142</td></tr><tr><td>val_loss</td><td>1.46013</td></tr><tr><td>val_word_accuracy</td><td>0.22327</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">winter-sweep-7</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/dt051nwy' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/dt051nwy</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250829_161531-dt051nwy/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4266uag1 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.000820041416310915\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing: 0.6\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Transliteration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250829_162140-4266uag1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/4266uag1' target=\"_blank\">serene-sweep-8</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/sweeps/r72d84fg</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/4266uag1' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/4266uag1</a>"},"metadata":{}},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_word_accuracy</td><td>▁▅▇▇█</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▅▆▇▇███</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▁▁▁</td></tr><tr><td>val_CER</td><td>█▄▂▂▁▁▁▁</td></tr><tr><td>val_char_accuracy</td><td>▁▅▇▇████</td></tr><tr><td>val_loss</td><td>█▂▁▁▁▂▆▆</td></tr><tr><td>val_word_accuracy</td><td>▁▅▇▇██▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_model_path</td><td>/kaggle/working/wand...</td></tr><tr><td>best_val_word_accuracy</td><td>0.37907</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_char_accuracy</td><td>0.92017</td></tr><tr><td>train_loss</td><td>0.27098</td></tr><tr><td>val_CER</td><td>0.192</td></tr><tr><td>val_char_accuracy</td><td>0.71744</td></tr><tr><td>val_loss</td><td>1.22975</td></tr><tr><td>val_word_accuracy</td><td>0.37219</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">serene-sweep-8</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/4266uag1' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration/runs/4266uag1</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transliteration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250829_162140-4266uag1/logs</code>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## Test","metadata":{}},{"cell_type":"code","source":"class TransliterationDataset(Dataset):\n    def __init__(self, pairs, input_vocab, output_vocab):\n        self.pairs = pairs\n        self.input_vocab = input_vocab\n        self.output_vocab = output_vocab\n        self.sos = output_vocab['<sos>']\n        self.eos = output_vocab['<eos>']\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        source, target = self.pairs[idx]\n        input_ids = [self.input_vocab[c] for c in source]\n        target_ids = [self.sos] + [self.output_vocab[c] for c in target] + [self.eos]\n        return torch.tensor(input_ids), torch.tensor(target_ids)\n\ndef load_pairs(path):\n    df = pd.read_csv(path, sep='\\t', header=None, names=['target', 'source', 'count'], dtype=str)\n    df.dropna(subset=[\"source\", \"target\"], inplace=True)\n    return list(zip(df['source'], df['target']))\n\ndef build_vocab(pairs):\n    input_chars = set()\n    output_chars = set()\n    for src, tgt in pairs:\n        input_chars.update(src)\n        output_chars.update(tgt)\n    input_vocab = {c: i+1 for i, c in enumerate(sorted(input_chars))}\n    input_vocab['<pad>'] = 0\n    output_vocab = {c: i+3 for i, c in enumerate(sorted(output_chars))}\n    output_vocab.update({'<pad>': 0, '<sos>': 1, '<eos>': 2})\n    return input_vocab, output_vocab\n\ndef collate_fn(batch):\n    inputs, targets = zip(*batch)\n    input_lens = [len(x) for x in inputs]\n    target_lens = [len(x) for x in targets]\n    inputs_padded = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n    targets_padded = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=0)\n    return inputs_padded, targets_padded, input_lens, target_lens\n\n# ---------------- Models ----------------\nclass Encoder(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, num_layers, cell_type, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(input_size, embed_size, padding_idx=0)\n        rnn_cls = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[cell_type]\n        self.rnn = rnn_cls(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n\n    def forward(self, x, lengths):\n        embedded = self.embedding(x)\n        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)\n        outputs, hidden = self.rnn(packed)\n        return hidden\n\nclass Decoder(nn.Module):\n    def __init__(self, output_size, embed_size, hidden_size, num_layers, cell_type, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(output_size, embed_size, padding_idx=0)\n        rnn_cls = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[cell_type]\n        self.rnn = rnn_cls(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, token, hidden):\n        x = self.embedding(token.unsqueeze(1))\n        output, hidden = self.rnn(x, hidden)\n        output = self.fc(output.squeeze(1))\n        return output, hidden\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, src, src_lens, tgt=None, teacher_forcing_ratio=0.5):\n        batch_size = src.size(0)\n        hidden = self.encoder(src, src_lens)\n        tgt_len = tgt.size(1)\n        outputs = torch.zeros(batch_size, tgt_len, self.decoder.fc.out_features).to(src.device)\n        input_token = tgt[:, 0]\n        for t in range(1, tgt_len):\n            output, hidden = self.decoder(input_token, hidden)\n            outputs[:, t] = output\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            input_token = tgt[:, t] if teacher_force else output.argmax(1)\n        return outputs\n\n# ---------------- Train + Eval ----------------\ndef train_model(model, dataloader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    for src, tgt, src_lens, _ in dataloader:\n        src, tgt = src.to(device), tgt.to(device)\n        optimizer.zero_grad()\n        output = model(src, src_lens, tgt)\n        loss = criterion(output[:, 1:].reshape(-1, output.shape[-1]), tgt[:, 1:].reshape(-1))\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(dataloader)\n\ndef evaluate_and_save(model, dataloader, input_vocab, output_vocab, device, csv_path=None):\n    model.eval()\n    inv_input_vocab = {v: k for k, v in input_vocab.items()}\n    inv_output_vocab = {v: k for k, v in output_vocab.items()}\n    correct = 0\n    total = 0\n    results = []\n\n    with torch.no_grad():\n        for src, tgt, src_lens, _ in dataloader:\n            src = src.to(device)\n            hidden = model.encoder(src, src_lens)\n            input_token = torch.tensor([output_vocab['<sos>']] * src.size(0)).to(device)\n            decoded = []\n            for _ in range(20):\n                output, hidden = model.decoder(input_token, hidden)\n                input_token = output.argmax(1)\n                decoded.append(input_token)\n            decoded = torch.stack(decoded, dim=1)\n\n            for i in range(src.size(0)):\n                pred = ''.join([inv_output_vocab[t.item()] for t in decoded[i] if t.item() not in [output_vocab['<eos>'], 0]])\n                truth = ''.join([inv_output_vocab[t.item()] for t in tgt[i][1:-1]])\n                inp = ''.join([inv_input_vocab[t.item()] for t in src[i] if t.item() != 0])\n                results.append((inp, pred, truth))\n                if pred == truth:\n                    correct += 1\n                total += 1\n\n    acc = correct / total * 100\n    print(f\"\\n Test Accuracy: {acc:.2f}%\")\n    for inp, pred, truth in results[:10]:\n        print(f\"{inp:<15} | Pred: {pred:<20} | Truth: {truth}\")\n\n    if csv_path is not None:\n        with open(csv_path, mode='w', newline='', encoding='utf-8') as f:\n            writer = csv.writer(f)\n            writer.writerow(['Input', 'Prediction', 'GroundTruth'])\n            writer.writerows(results)\n        print(f\"\\n Predictions saved to: {csv_path}\")\n\n    return acc, results\n\n\n# ------------ Run ----------------\nif __name__ == \"__main__\":\n    config = {\n        \"embed_size\": 128,\n        \"hidden_size\": 256,\n        \"num_layers\": 3,\n        \"cell_type\": \"LSTM\",\n        \"dropout\": 0.2,\n        \"batch_size\": 32,\n        \"lr\": 0.00082004,\n        \"epochs\": 10,\n    }\n\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    train_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    test_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\")\n    input_vocab, output_vocab = build_vocab(train_pairs)\n    train_dataset = TransliterationDataset(train_pairs, input_vocab, output_vocab)\n    test_dataset = TransliterationDataset(test_pairs, input_vocab, output_vocab)\n\n    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate_fn)\n    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n\n    encoder = Encoder(len(input_vocab), config[\"embed_size\"], config[\"hidden_size\"],\n                      config[\"num_layers\"], config[\"cell_type\"], config[\"dropout\"])\n    decoder = Decoder(len(output_vocab), config[\"embed_size\"], config[\"hidden_size\"],\n                      config[\"num_layers\"], config[\"cell_type\"], config[\"dropout\"])\n    model = Seq2Seq(encoder, decoder).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    best_acc = 0\n    for epoch in range(config[\"epochs\"]):\n        train_loss = train_model(model, train_loader, optimizer, criterion, device)\n        print(f\"Epoch {epoch+1} Train Loss: {train_loss:.4f}\")\n        acc, results = evaluate_and_save(model, test_loader, input_vocab, output_vocab, device, csv_path=None)\n        if acc > best_acc:\n            best_acc = acc\n            torch.save(model.state_dict(), \"best_model.pth\")\n\n    print(\"\\n Loading best model for final evaluation...\")\n    model.load_state_dict(torch.load(\"best_model.pth\"))\n\n    # Save predictions CSV here\n    evaluate_and_save(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-29T16:37:53.156602Z","iopub.execute_input":"2025-08-29T16:37:53.157254Z","iopub.status.idle":"2025-08-29T16:53:14.649520Z","shell.execute_reply.started":"2025-08-29T16:37:53.157232Z","shell.execute_reply":"2025-08-29T16:53:14.648736Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 Train Loss: 1.7050\n\n Test Accuracy: 22.57%\nank             | Pred: एंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनकों                | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: एंकों                | Truth: अंकों\nangkor          | Pred: अंगकोर               | Truth: अंकोर\nankor           | Pred: एंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगाकर               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\nEpoch 2 Train Loss: 0.8184\n\n Test Accuracy: 29.05%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनाकों               | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगकोर               | Truth: अंकोर\nankor           | Pred: अंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगारक               | Truth: अंगारक\nEpoch 3 Train Loss: 0.6446\n\n Test Accuracy: 35.14%\nank             | Pred: एंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनकों                | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगकोर               | Truth: अंकोर\nankor           | Pred: एंकर                 | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\nEpoch 4 Train Loss: 0.5320\n\n Test Accuracy: 36.92%\nank             | Pred: एंक                  | Truth: अंक\nanka            | Pred: आंका                 | Truth: अंक\nankit           | Pred: आंकित                | Truth: अंकित\nanakon          | Pred: अनाकों               | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: आंकों                | Truth: अंकों\nangkor          | Pred: एंक्कोर              | Truth: अंकोर\nankor           | Pred: एनकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\nEpoch 5 Train Loss: 0.4644\n\n Test Accuracy: 36.43%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनाकों               | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकोन                | Truth: अंकों\nangkor          | Pred: अंगकोर               | Truth: अंकोर\nankor           | Pred: एंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगारक               | Truth: अंगारक\nEpoch 6 Train Loss: 0.4040\n\n Test Accuracy: 37.43%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनकों                | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: एंकों                | Truth: अंकों\nangkor          | Pred: एंककोर               | Truth: अंकोर\nankor           | Pred: एंकर                 | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगारक               | Truth: अंगारक\nEpoch 7 Train Loss: 0.3584\n\n Test Accuracy: 38.34%\nank             | Pred: एंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनाकों               | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: एंकॉर                | Truth: अंकोर\nankor           | Pred: एंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगराक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\nEpoch 8 Train Loss: 0.3235\n\n Test Accuracy: 37.43%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकितत               | Truth: अंकित\nanakon          | Pred: अनककों               | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगकोर               | Truth: अंकोर\nankor           | Pred: एंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\nEpoch 9 Train Loss: 0.2950\n\n Test Accuracy: 35.96%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनाकों               | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगोर                | Truth: अंकोर\nankor           | Pred: अंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\nEpoch 10 Train Loss: 0.2680\n\n Test Accuracy: 37.49%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: आंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनाकों               | Truth: अंकों\nankhon          | Pred: अनखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: आंगकोर               | Truth: अंकोर\nankor           | Pred: आंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\n\n Loading best model for final evaluation...\n\n Test Accuracy: 38.34%\nank             | Pred: एंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनाकों               | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: एंकॉर                | Truth: अंकोर\nankor           | Pred: एंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगराक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\n\n Predictions saved to: test_predictions.csv\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"___\n___","metadata":{}},{"cell_type":"markdown","source":"#  **$$Transformer-Model$$**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport math\nimport random\nimport wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:23:37.104344Z","iopub.execute_input":"2025-08-30T06:23:37.104995Z","iopub.status.idle":"2025-08-30T06:23:37.109235Z","shell.execute_reply.started":"2025-08-30T06:23:37.104966Z","shell.execute_reply":"2025-08-30T06:23:37.108461Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Dataset\nclass DakshinaDataset(Dataset):\n    def __init__(self, file_path, inp_vocab=None, tgt_vocab=None, build_vocab=False):\n        self.pairs = []\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                parts = line.strip().split(\"\\t\")\n                if len(parts) >= 2:\n                    self.pairs.append((parts[0], parts[1]))  # (input_word, output_word)\n\n        if len(self.pairs) == 0:\n            raise ValueError(f\"No valid data found in file: {file_path}\")\n\n        if build_vocab:\n            self.inp_vocab = self.build_vocab([p[0] for p in self.pairs])\n            self.tgt_vocab = self.build_vocab([p[1] for p in self.pairs])\n        else:\n            self.inp_vocab = inp_vocab\n            self.tgt_vocab = tgt_vocab\n\n    def build_vocab(self, texts):\n        vocab = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n        idx = 4\n        for text in texts:\n            for ch in text:\n                if ch not in vocab:\n                    vocab[ch] = idx\n                    idx += 1\n        return vocab\n\n    def encode(self, text, vocab):\n        return [vocab.get(ch, vocab[\"<unk>\"]) for ch in text]\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        inp, tgt = self.pairs[idx]\n        inp_ids = [self.inp_vocab[\"<sos>\"]] + self.encode(inp, self.inp_vocab) + [self.inp_vocab[\"<eos>\"]]\n        tgt_ids = [self.tgt_vocab[\"<sos>\"]] + self.encode(tgt, self.tgt_vocab) + [self.tgt_vocab[\"<eos>\"]]\n        return torch.tensor(inp_ids), torch.tensor(tgt_ids)\n\n\ndef collate_fn(batch):\n    inps, tgts = zip(*batch)\n    inp_lens = [len(x) for x in inps]\n    tgt_lens = [len(x) for x in tgts]\n    max_inp = max(inp_lens)\n    max_tgt = max(tgt_lens)\n    inp_pad = torch.zeros(len(batch), max_inp, dtype=torch.long)\n    tgt_pad = torch.zeros(len(batch), max_tgt, dtype=torch.long)\n    for i, (inp, tgt) in enumerate(zip(inps, tgts)):\n        inp_pad[i, :len(inp)] = inp\n        tgt_pad[i, :len(tgt)] = tgt\n    return inp_pad, tgt_pad\n\n\n# Transformer Model\nclass TransformerModel(nn.Module):\n    def __init__(self, inp_vocab_size, tgt_vocab_size, d_model=256, nhead=4, num_layers=3, dim_feedforward=512, dropout=0.1):\n        super().__init__()\n        self.d_model = d_model\n        self.embedding_inp = nn.Embedding(inp_vocab_size, d_model)\n        self.embedding_tgt = nn.Embedding(tgt_vocab_size, d_model)\n        self.pos_encoder = nn.Embedding(500, d_model)\n        self.pos_decoder = nn.Embedding(500, d_model)\n\n        self.transformer = nn.Transformer(\n            d_model=d_model, nhead=nhead, num_encoder_layers=num_layers,\n            num_decoder_layers=num_layers, dim_feedforward=dim_feedforward,\n            dropout=dropout, batch_first=True\n        )\n        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n\n    def forward(self, src, tgt):\n        src_pos = torch.arange(0, src.size(1), device=src.device).unsqueeze(0)\n        tgt_pos = torch.arange(0, tgt.size(1), device=src.device).unsqueeze(0)\n\n        src_emb = self.embedding_inp(src) * math.sqrt(self.d_model) + self.pos_encoder(src_pos)\n        tgt_emb = self.embedding_tgt(tgt) * math.sqrt(self.d_model) + self.pos_decoder(tgt_pos)\n\n        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(src.device)\n\n        output = self.transformer(src_emb, tgt_emb, tgt_mask=tgt_mask)\n        return self.fc_out(output)\n\n\n# -----------------------------\n# Training & Evaluation\n# -----------------------------\ndef train_one_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    for src, tgt in loader:\n        src, tgt = src.to(device), tgt.to(device)\n        tgt_inp = tgt[:, :-1]\n        tgt_out = tgt[:, 1:]\n\n        optimizer.zero_grad()\n        output = model(src, tgt_inp)\n        loss = criterion(output.reshape(-1, output.size(-1)), tgt_out.reshape(-1))\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(loader)\n\n\ndef evaluate(model, loader, criterion, inp_vocab, tgt_vocab, device, print_samples=False):\n    model.eval()\n    total, correct = 0, 0\n    inv_tgt_vocab = {v: k for k, v in tgt_vocab.items()}\n    inv_inp_vocab = {v: k for k, v in inp_vocab.items()}\n\n    samples = []\n    with torch.no_grad():\n        for src, tgt in loader:\n            src, tgt = src.to(device), tgt.to(device)\n            tgt_inp = tgt[:, :-1]\n            tgt_out = tgt[:, 1:]\n            output = model(src, tgt_inp)\n            pred_tokens = output.argmax(-1)\n\n            total += tgt_out.numel()\n            correct += (pred_tokens == tgt_out).sum().item()\n\n            if print_samples and len(samples) < 10:\n                for i in range(min(5, src.size(0))):\n                    inp_text = \"\".join(inv_inp_vocab.get(x.item(), \"\") for x in src[i] if x.item() > 3)\n                    pred_text = \"\".join(inv_tgt_vocab.get(x.item(), \"\") for x in pred_tokens[i] if x.item() > 3)\n                    truth_text = \"\".join(inv_tgt_vocab.get(x.item(), \"\") for x in tgt[i] if x.item() > 3)\n                    samples.append((inp_text, pred_text, truth_text))\n\n    acc = correct / total\n    return acc, samples\n\n\n# Main Training Script\ndef main():\n    wandb.init(project=\"dakshina-transformer\", config={\n        \"epochs\": 25,\n        \"batch_size\": 64,\n        \"lr\": 0.001,\n        \"d_model\": 256,\n        \"nhead\": 4,\n        \"num_layers\": 3,\n        \"dropout\": 0.1\n    })\n    config = wandb.config\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    train_file = \"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n    dev_file = \"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\"\n\n    train_dataset = DakshinaDataset(train_file, build_vocab=True)\n    dev_dataset = DakshinaDataset(dev_file, inp_vocab=train_dataset.inp_vocab, tgt_vocab=train_dataset.tgt_vocab)\n\n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n    dev_loader = DataLoader(dev_dataset, batch_size=config.batch_size, collate_fn=collate_fn)\n\n    model = TransformerModel(len(train_dataset.inp_vocab), len(train_dataset.tgt_vocab),\n                             d_model=config.d_model, nhead=config.nhead,\n                             num_layers=config.num_layers, dropout=config.dropout).to(device)\n\n    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    best_acc = 0.0\n    for epoch in range(1, config.epochs + 1):\n        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n        dev_acc, samples = evaluate(model, dev_loader, criterion,\n                                    train_dataset.inp_vocab, train_dataset.tgt_vocab, device,\n                                    print_samples=True)\n\n        print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f}, Dev Accuracy: {dev_acc:.4f}\")\n        for inp, pred, truth in samples:\n            print(f\"{inp:15} | Pred: {pred:15} | Truth: {truth}\")\n\n        wandb.log({\"epoch\": epoch, \"train_loss\": train_loss, \"dev_accuracy\": dev_acc})\n        \n\n        if dev_acc > best_acc:\n            best_acc = dev_acc\n            torch.save(model.state_dict(), \"best_transformer.pt\")\n            print(\"Best model saved.\")\n            \n        print()    \n\n    print(\"Training finished. Best Dev Accuracy:\", best_acc)\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:26:19.050276Z","iopub.execute_input":"2025-08-30T06:26:19.050991Z","iopub.status.idle":"2025-08-30T06:33:00.394181Z","shell.execute_reply.started":"2025-08-30T06:26:19.050962Z","shell.execute_reply":"2025-08-30T06:33:00.393376Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250830_062619-k5cwz1c5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transformer/runs/k5cwz1c5' target=\"_blank\">resilient-tree-2</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transformer/runs/k5cwz1c5' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/dakshina-transformer/runs/k5cwz1c5</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 1, Train Loss: 1.3944, Dev Accuracy: 0.4414\nअंकन            | Pred: ankan           | Truth: ankan\nअंगकोर          | Pred: aggaorooooo     | Truth: angkor\nअंगिरा          | Pred: angara          | Truth: angira\nअंगीठी          | Pred: angathiiiiii    | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikttiiiii    | Truth: adhikat\nअधिकांशत        | Pred: adhiksnnthtt    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhiksnthtta    | Truth: adhikanshat\nअधिकाश          | Pred: adhisssshiii    | Truth: adhikaash\nअधिकाश          | Pred: adhissshihiii   | Truth: adhikash\nBest model saved.\n\nEpoch 2, Train Loss: 0.7507, Dev Accuracy: 0.4860\nअंकन            | Pred: anaan           | Truth: ankan\nअंगकोर          | Pred: angkora         | Truth: angkor\nअंगिरा          | Pred: angiraaaaaaa    | Truth: angira\nअंगीठी          | Pred: angith          | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshan    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshan     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassha      | Truth: adhikaash\nअधिकाश          | Pred: adhikashaaaa    | Truth: adhikash\nBest model saved.\n\nEpoch 3, Train Loss: 0.5929, Dev Accuracy: 0.5041\nअंकन            | Pred: ankan           | Truth: ankan\nअंगकोर          | Pred: angoor          | Truth: angkor\nअंगिरा          | Pred: angira          | Truth: angira\nअंगीठी          | Pred: angithiiiii     | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshtt    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshtt     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\nBest model saved.\n\nEpoch 4, Train Loss: 0.5150, Dev Accuracy: 0.5120\nअंकन            | Pred: ankan           | Truth: ankan\nअंगकोर          | Pred: angkor          | Truth: angkor\nअंगिरा          | Pred: angira          | Truth: angira\nअंगीठी          | Pred: angithi         | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\nBest model saved.\n\nEpoch 5, Train Loss: 0.4785, Dev Accuracy: 0.5173\nअंकन            | Pred: ankan           | Truth: ankan\nअंगकोर          | Pred: angkor          | Truth: angkor\nअंगिरा          | Pred: angira          | Truth: angira\nअंगीठी          | Pred: angethi         | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshtt    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshtt     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\nBest model saved.\n\nEpoch 6, Train Loss: 0.4469, Dev Accuracy: 0.5138\nअंकन            | Pred: ankanaaaaa      | Truth: ankan\nअंगकोर          | Pred: angaor          | Truth: angkor\nअंगिरा          | Pred: angira          | Truth: angira\nअंगीठी          | Pred: angithiiiii     | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\n\nEpoch 7, Train Loss: 0.4263, Dev Accuracy: 0.5208\nअंकन            | Pred: ankannaaaaaa    | Truth: ankan\nअंगकोर          | Pred: angkoreeeee     | Truth: angkor\nअंगिरा          | Pred: angiraaaaaaa    | Truth: angira\nअंगीठी          | Pred: angithih        | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshan    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshan     | Truth: adhikanshat\nअधिकाश          | Pred: adhikasshh      | Truth: adhikaash\nअधिकाश          | Pred: adhikashh       | Truth: adhikash\nBest model saved.\n\nEpoch 8, Train Loss: 0.4223, Dev Accuracy: 0.5220\nअंकन            | Pred: ankannaaaaaa    | Truth: ankan\nअंगकोर          | Pred: angkoroooo      | Truth: angkor\nअंगिरा          | Pred: angiraaaaaaa    | Truth: angira\nअंगीठी          | Pred: angithi         | Truth: angithi\nअंग्रेज         | Pred: angraj          | Truth: angrej\nअधिकत           | Pred: adhikath        | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshath    | Truth: adhikanshat\nअधिकाश          | Pred: adhikasshhhh    | Truth: adhikaash\nअधिकाश          | Pred: adhikashhhhh    | Truth: adhikash\nBest model saved.\n\nEpoch 9, Train Loss: 0.4073, Dev Accuracy: 0.5236\nअंकन            | Pred: ankann          | Truth: ankan\nअंगकोर          | Pred: angkor          | Truth: angkor\nअंगिरा          | Pred: angiraaaaaaa    | Truth: angira\nअंगीठी          | Pred: angithiiiiii    | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\nBest model saved.\n\nEpoch 10, Train Loss: 0.4068, Dev Accuracy: 0.5246\nअंकन            | Pred: ankanaaaaaa     | Truth: ankan\nअंगकोर          | Pred: angkor          | Truth: angkor\nअंगिरा          | Pred: angiraaaaaaa    | Truth: angira\nअंगीठी          | Pred: angithiiiii     | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\nBest model saved.\n\nEpoch 11, Train Loss: 0.4111, Dev Accuracy: 0.5247\nअंकन            | Pred: ankana          | Truth: ankan\nअंगकोर          | Pred: angkor          | Truth: angkor\nअंगिरा          | Pred: angiraaaaaaa    | Truth: angira\nअंगीठी          | Pred: angethi         | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\nBest model saved.\n\nEpoch 12, Train Loss: 0.3728, Dev Accuracy: 0.5271\nअंकन            | Pred: ankanaaaaaa     | Truth: ankan\nअंगकोर          | Pred: angkoroaaaa     | Truth: angkor\nअंगिरा          | Pred: angiraaaaaa     | Truth: angira\nअंगीठी          | Pred: angithihhhh     | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikasshh      | Truth: adhikaash\nअधिकाश          | Pred: adhikashh       | Truth: adhikash\nBest model saved.\n\nEpoch 13, Train Loss: 0.3938, Dev Accuracy: 0.5259\nअंकन            | Pred: ankanaaa        | Truth: ankan\nअंगकोर          | Pred: angkoreee       | Truth: angkor\nअंगिरा          | Pred: angira          | Truth: angira\nअंगीठी          | Pred: angethihhhhh    | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshata    | Truth: adhikanshat\nअधिकाश          | Pred: adhikassha      | Truth: adhikaash\nअधिकाश          | Pred: adhikasha       | Truth: adhikash\n\nEpoch 14, Train Loss: 0.3753, Dev Accuracy: 0.5273\nअंकन            | Pred: ankanaaaaaaa    | Truth: ankan\nअंगकोर          | Pred: angkor          | Truth: angkor\nअंगिरा          | Pred: angiraaaaaa     | Truth: angira\nअंगीठी          | Pred: angithi         | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikasshhh     | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\nBest model saved.\n\nEpoch 15, Train Loss: 0.3589, Dev Accuracy: 0.5283\nअंकन            | Pred: ankan           | Truth: ankan\nअंगकोर          | Pred: angkor          | Truth: angkor\nअंगिरा          | Pred: angira          | Truth: angira\nअंगीठी          | Pred: angethihhiih    | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikasshh      | Truth: adhikaash\nअधिकाश          | Pred: adhikashh       | Truth: adhikash\nBest model saved.\n\nEpoch 16, Train Loss: 0.3547, Dev Accuracy: 0.5263\nअंकन            | Pred: ankana          | Truth: ankan\nअंगकोर          | Pred: angkor          | Truth: angkor\nअंगिरा          | Pred: angiraa         | Truth: angira\nअंगीठी          | Pred: angithihhhh     | Truth: angithi\nअंग्रेज         | Pred: angrejjaaeee    | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\n\nEpoch 17, Train Loss: 0.3665, Dev Accuracy: 0.5267\nअंकन            | Pred: ankan           | Truth: ankan\nअंगकोर          | Pred: angkore         | Truth: angkor\nअंगिरा          | Pred: angiraaaaaaa    | Truth: angira\nअंगीठी          | Pred: angithiiiiii    | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\n\nEpoch 18, Train Loss: 0.3582, Dev Accuracy: 0.5272\nअंकन            | Pred: ankan           | Truth: ankan\nअंगकोर          | Pred: angkor          | Truth: angkor\nअंगिरा          | Pred: angiraa         | Truth: angira\nअंगीठी          | Pred: angithi         | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\n\nEpoch 19, Train Loss: 0.4154, Dev Accuracy: 0.5148\nअंकन            | Pred: ankana          | Truth: ankan\nअंगकोर          | Pred: angkor          | Truth: angkor\nअंगिरा          | Pred: angira          | Truth: angira\nअंगीठी          | Pred: angithi         | Truth: angithi\nअंग्रेज         | Pred: angre           | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikanntht     | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanthth     | Truth: adhikanshat\nअधिकाश          | Pred: adhikasshhh     | Truth: adhikaash\nअधिकाश          | Pred: adhikashhhh     | Truth: adhikash\n\nEpoch 20, Train Loss: 0.3600, Dev Accuracy: 0.5311\nअंकन            | Pred: ankanaaaaaa     | Truth: ankan\nअंगकोर          | Pred: angkoreee       | Truth: angkor\nअंगिरा          | Pred: angira          | Truth: angira\nअंगीठी          | Pred: angithihhh      | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\nBest model saved.\n\nEpoch 21, Train Loss: 0.3342, Dev Accuracy: 0.5313\nअंकन            | Pred: ankanaaaa       | Truth: ankan\nअंगकोर          | Pred: angkoreeee      | Truth: angkor\nअंगिरा          | Pred: angiraaa        | Truth: angira\nअंगीठी          | Pred: angithi         | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshtt    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshtt     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\nBest model saved.\n\nEpoch 22, Train Loss: 0.3318, Dev Accuracy: 0.5295\nअंकन            | Pred: ankanaaaaaa     | Truth: ankan\nअंगकोर          | Pred: angkor          | Truth: angkor\nअंगिरा          | Pred: angiraaaa       | Truth: angira\nअंगीठी          | Pred: angethih        | Truth: angithi\nअंग्रेज         | Pred: ungraj          | Truth: angrej\nअधिकत           | Pred: adhikatta       | Truth: adhikat\nअधिकांशत        | Pred: adhikannshtt    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshttt    | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\n\nEpoch 23, Train Loss: 0.3399, Dev Accuracy: 0.5293\nअंकन            | Pred: ankanaaaaaa     | Truth: ankan\nअंगकोर          | Pred: angkor          | Truth: angkor\nअंगिरा          | Pred: angiraaaa       | Truth: angira\nअंगीठी          | Pred: angithi         | Truth: angithi\nअंग्रेज         | Pred: angreje         | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\n\nEpoch 24, Train Loss: 0.3336, Dev Accuracy: 0.5309\nअंकन            | Pred: ankana          | Truth: ankan\nअंगकोर          | Pred: angkor          | Truth: angkor\nअंगिरा          | Pred: angiraaaaaa     | Truth: angira\nअंगीठी          | Pred: angithihh       | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\n\nEpoch 25, Train Loss: 0.3413, Dev Accuracy: 0.5286\nअंकन            | Pred: ankan           | Truth: ankan\nअंगकोर          | Pred: angkor          | Truth: angkor\nअंगिरा          | Pred: angira          | Truth: angira\nअंगीठी          | Pred: angithi         | Truth: angithi\nअंग्रेज         | Pred: angrej          | Truth: angrej\nअधिकत           | Pred: adhikat         | Truth: adhikat\nअधिकांशत        | Pred: adhikannshat    | Truth: adhikaanshat\nअधिकांशत        | Pred: adhikanshat     | Truth: adhikanshat\nअधिकाश          | Pred: adhikassh       | Truth: adhikaash\nअधिकाश          | Pred: adhikash        | Truth: adhikash\n\nTraining finished. Best Dev Accuracy: 0.5313303396976656\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## For Test data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nimport math\nimport csv\nfrom collections import namedtuple","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:43:44.831495Z","iopub.execute_input":"2025-08-30T06:43:44.831824Z","iopub.status.idle":"2025-08-30T06:43:50.564771Z","shell.execute_reply.started":"2025-08-30T06:43:44.831794Z","shell.execute_reply":"2025-08-30T06:43:50.564113Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"#### Single Run","metadata":{}},{"cell_type":"code","source":"# Load Dataset + Collate Fn\nclass DakshinaDataset(torch.utils.data.Dataset):\n    def __init__(self, file_path, inp_vocab=None, tgt_vocab=None, build_vocab=False):\n        self.pairs = []\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                parts = line.strip().split(\"\\t\")\n                if len(parts) >= 2:\n                    self.pairs.append((parts[0], parts[1]))\n\n        if build_vocab:\n            self.inp_vocab = self.build_vocab([p[0] for p in self.pairs])\n            self.tgt_vocab = self.build_vocab([p[1] for p in self.pairs])\n        else:\n            self.inp_vocab = inp_vocab\n            self.tgt_vocab = tgt_vocab\n\n    def build_vocab(self, texts):\n        vocab = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n        idx = 4\n        for text in texts:\n            for ch in text:\n                if ch not in vocab:\n                    vocab[ch] = idx\n                    idx += 1\n        return vocab\n\n    def encode(self, text, vocab):\n        return [vocab.get(ch, vocab[\"<unk>\"]) for ch in text]\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        inp, tgt = self.pairs[idx]\n        inp_ids = [self.inp_vocab[\"<sos>\"]] + self.encode(inp, self.inp_vocab) + [self.inp_vocab[\"<eos>\"]]\n        tgt_ids = [self.tgt_vocab[\"<sos>\"]] + self.encode(tgt, self.tgt_vocab) + [self.tgt_vocab[\"<eos>\"]]\n        return torch.tensor(inp_ids), torch.tensor(tgt_ids)\n\n\ndef collate_fn(batch):\n    inps, tgts = zip(*batch)\n    max_inp = max(len(x) for x in inps)\n    max_tgt = max(len(x) for x in tgts)\n    inp_pad = torch.zeros(len(batch), max_inp, dtype=torch.long)\n    tgt_pad = torch.zeros(len(batch), max_tgt, dtype=torch.long)\n    for i, (inp, tgt) in enumerate(zip(inps, tgts)):\n        inp_pad[i, :len(inp)] = inp\n        tgt_pad[i, :len(tgt)] = tgt\n    return inp_pad, tgt_pad\n\n\n# Transformer Model\nclass TransformerModel(nn.Module):\n    def __init__(self, inp_vocab_size, tgt_vocab_size, d_model=256, nhead=4, num_layers=3, dim_feedforward=512, dropout=0.1):\n        super().__init__()\n        self.d_model = d_model\n        self.embedding_inp = nn.Embedding(inp_vocab_size, d_model)\n        self.embedding_tgt = nn.Embedding(tgt_vocab_size, d_model)\n        self.pos_encoder = nn.Embedding(500, d_model)\n        self.pos_decoder = nn.Embedding(500, d_model)\n\n        self.transformer = nn.Transformer(\n            d_model=d_model, nhead=nhead, num_encoder_layers=num_layers,\n            num_decoder_layers=num_layers, dim_feedforward=dim_feedforward,\n            dropout=dropout, batch_first=True\n        )\n        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n\n    def forward(self, src, tgt):\n        src_pos = torch.arange(0, src.size(1), device=src.device).unsqueeze(0)\n        tgt_pos = torch.arange(0, tgt.size(1), device=src.device).unsqueeze(0)\n\n        src_emb = self.embedding_inp(src) * math.sqrt(self.d_model) + self.pos_encoder(src_pos)\n        tgt_emb = self.embedding_tgt(tgt) * math.sqrt(self.d_model) + self.pos_decoder(tgt_pos)\n\n        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(src.device)\n\n        output = self.transformer(src_emb, tgt_emb, tgt_mask=tgt_mask)\n        return self.fc_out(output)\n\n\n# Test Evaluation\ndef evaluate_test(model, loader, inp_vocab, tgt_vocab, device, save_csv=True):\n    model.eval()\n    total, correct = 0, 0\n    inv_tgt_vocab = {v: k for k, v in tgt_vocab.items()}\n    inv_inp_vocab = {v: k for k, v in inp_vocab.items()}\n\n    samples = []\n    preds_list = []\n\n    with torch.no_grad():\n        for src, tgt in loader:\n            src, tgt = src.to(device), tgt.to(device)\n            tgt_inp = tgt[:, :-1]\n            tgt_out = tgt[:, 1:]\n            output = model(src, tgt_inp)\n            pred_tokens = output.argmax(-1)\n\n            total += tgt_out.numel()\n            correct += (pred_tokens == tgt_out).sum().item()\n\n            for i in range(src.size(0)):\n                inp_text = \"\".join(inv_inp_vocab.get(x.item(), \"\") for x in src[i] if x.item() > 3)\n                pred_text = \"\".join(inv_tgt_vocab.get(x.item(), \"\") for x in pred_tokens[i] if x.item() > 3)\n                truth_text = \"\".join(inv_tgt_vocab.get(x.item(), \"\") for x in tgt[i] if x.item() > 3)\n                preds_list.append([inp_text, pred_text, truth_text])\n                if len(samples) < 10:\n                    samples.append((inp_text, pred_text, truth_text))\n\n    acc = correct / total\n    print(f\"\\nTest Accuracy: {acc*100:.2f}%\")\n    for inp, pred, truth in samples:\n        print(f\"{inp:15} | Pred: {pred:20} | Truth: {truth}\")\n\n    if save_csv:\n        df = pd.DataFrame(preds_list, columns=[\"Input\", \"Prediction\", \"Truth\"])\n        df.to_csv(\"test_predictions.csv\", index=False)\n        print(\"\\nPredictions saved to: test_predictions.csv\")\n\n    return acc\n\n\n# Run Test\ndef main():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    train_file = \"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n    test_file = \"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\"\n\n    # Load vocab from train set\n    train_dataset = DakshinaDataset(train_file, build_vocab=True)\n    test_dataset = DakshinaDataset(test_file, inp_vocab=train_dataset.inp_vocab, tgt_vocab=train_dataset.tgt_vocab)\n\n    test_loader = DataLoader(test_dataset, batch_size=64, collate_fn=collate_fn)\n\n    # Load model\n    model = TransformerModel(len(train_dataset.inp_vocab), len(train_dataset.tgt_vocab)).to(device)\n    model.load_state_dict(torch.load(\"best_transformer.pt\", map_location=device))\n    print(\"\\nLoaded best model for final evaluation...\")\n\n    # Evaluate\n    acc = evaluate_test(model, test_loader, train_dataset.inp_vocab, train_dataset.tgt_vocab, device)\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:43:50.565450Z","iopub.execute_input":"2025-08-30T06:43:50.565653Z","iopub.status.idle":"2025-08-30T06:43:59.937726Z","shell.execute_reply.started":"2025-08-30T06:43:50.565636Z","shell.execute_reply":"2025-08-30T06:43:59.936904Z"}},"outputs":[{"name":"stdout","text":"\nLoaded best model for final evaluation...\n\nTest Accuracy: 53.34%\nअंक             | Pred: ank                  | Truth: ank\nअंक             | Pred: ank                  | Truth: anka\nअंकित           | Pred: ankit                | Truth: ankit\nअंकों           | Pred: ankkon               | Truth: anakon\nअंकों           | Pred: ankoonoo             | Truth: ankhon\nअंकों           | Pred: ankonoo              | Truth: ankon\nअंकोर           | Pred: ankoor               | Truth: angkor\nअंकोर           | Pred: ankor                | Truth: ankor\nअंगारक          | Pred: angarrak             | Truth: angaarak\nअंगारक          | Pred: angarak              | Truth: angarak\n\nPredictions saved to: test_predictions.csv\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"#### 10-Epoch","metadata":{}},{"cell_type":"code","source":"# Dataset + Collate Fn\nclass DakshinaDataset(torch.utils.data.Dataset):\n    def __init__(self, file_path, inp_vocab=None, tgt_vocab=None, build_vocab=False):\n        self.pairs = []\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                parts = line.strip().split(\"\\t\")\n                if len(parts) >= 2:\n                    self.pairs.append((parts[0], parts[1]))\n\n        if build_vocab:\n            self.inp_vocab = self.build_vocab([p[0] for p in self.pairs])\n            self.tgt_vocab = self.build_vocab([p[1] for p in self.pairs])\n        else:\n            self.inp_vocab = inp_vocab\n            self.tgt_vocab = tgt_vocab\n\n    def build_vocab(self, texts):\n        vocab = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n        idx = 4\n        for text in texts:\n            for ch in text:\n                if ch not in vocab:\n                    vocab[ch] = idx\n                    idx += 1\n        return vocab\n\n    def encode(self, text, vocab):\n        return [vocab.get(ch, vocab[\"<unk>\"]) for ch in text]\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        inp, tgt = self.pairs[idx]\n        inp_ids = [self.inp_vocab[\"<sos>\"]] + self.encode(inp, self.inp_vocab) + [self.inp_vocab[\"<eos>\"]]\n        tgt_ids = [self.tgt_vocab[\"<sos>\"]] + self.encode(tgt, self.tgt_vocab) + [self.tgt_vocab[\"<eos>\"]]\n        return torch.tensor(inp_ids), torch.tensor(tgt_ids)\n\n\ndef collate_fn(batch):\n    inps, tgts = zip(*batch)\n    max_inp = max(len(x) for x in inps)\n    max_tgt = max(len(x) for x in tgts)\n    inp_pad = torch.zeros(len(batch), max_inp, dtype=torch.long)\n    tgt_pad = torch.zeros(len(batch), max_tgt, dtype=torch.long)\n    for i, (inp, tgt) in enumerate(zip(inps, tgts)):\n        inp_pad[i, :len(inp)] = inp\n        tgt_pad[i, :len(tgt)] = tgt\n    return inp_pad, tgt_pad\n\n\n# Transformer Model\nclass TransformerModel(nn.Module):\n    def __init__(self, inp_vocab_size, tgt_vocab_size, d_model=256, nhead=4, num_layers=3, dim_feedforward=512, dropout=0.1):\n        super().__init__()\n        self.d_model = d_model\n        self.embedding_inp = nn.Embedding(inp_vocab_size, d_model)\n        self.embedding_tgt = nn.Embedding(tgt_vocab_size, d_model)\n        self.pos_encoder = nn.Embedding(500, d_model)\n        self.pos_decoder = nn.Embedding(500, d_model)\n\n        self.transformer = nn.Transformer(\n            d_model=d_model, nhead=nhead, num_encoder_layers=num_layers,\n            num_decoder_layers=num_layers, dim_feedforward=dim_feedforward,\n            dropout=dropout, batch_first=True\n        )\n        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n\n    def forward(self, src, tgt):\n        src_pos = torch.arange(0, src.size(1), device=src.device).unsqueeze(0)\n        tgt_pos = torch.arange(0, tgt.size(1), device=src.device).unsqueeze(0)\n\n        src_emb = self.embedding_inp(src) * math.sqrt(self.d_model) + self.pos_encoder(src_pos)\n        tgt_emb = self.embedding_tgt(tgt) * math.sqrt(self.d_model) + self.pos_decoder(tgt_pos)\n\n        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(src.device)\n\n        output = self.transformer(src_emb, tgt_emb, tgt_mask=tgt_mask)\n        return self.fc_out(output)\n\n\n# Evaluation\ndef evaluate_test(model, loader, inp_vocab, tgt_vocab, device, show_samples=True, save_csv=False):\n    model.eval()\n    total, correct = 0, 0\n    inv_tgt_vocab = {v: k for k, v in tgt_vocab.items()}\n    inv_inp_vocab = {v: k for k, v in inp_vocab.items()}\n\n    samples, preds_list = [], []\n\n    with torch.no_grad():\n        for src, tgt in loader:\n            src, tgt = src.to(device), tgt.to(device)\n            tgt_inp = tgt[:, :-1]\n            tgt_out = tgt[:, 1:]\n            output = model(src, tgt_inp)\n            pred_tokens = output.argmax(-1)\n\n            total += tgt_out.numel()\n            correct += (pred_tokens == tgt_out).sum().item()\n\n            for i in range(src.size(0)):\n                inp_text = \"\".join(inv_inp_vocab.get(x.item(), \"\") for x in src[i] if x.item() > 3)\n                pred_text = \"\".join(inv_tgt_vocab.get(x.item(), \"\") for x in pred_tokens[i] if x.item() > 3)\n                truth_text = \"\".join(inv_tgt_vocab.get(x.item(), \"\") for x in tgt[i] if x.item() > 3)\n                preds_list.append([inp_text, pred_text, truth_text])\n                if len(samples) < 10:\n                    samples.append((inp_text, pred_text, truth_text))\n\n    acc = correct / total\n    if show_samples:\n        print(f\"\\n Test Accuracy: {acc*100:.2f}%\")\n        for inp, pred, truth in samples:\n            print(f\"{inp:15} | Pred: {pred:20} | Truth: {truth}\")\n\n    if save_csv:\n        df = pd.DataFrame(preds_list, columns=[\"Input\", \"Prediction\", \"Truth\"])\n        df.to_csv(\"test_predictions.csv\", index=False)\n        print(\"\\n Predictions saved to: test_predictions.csv\")\n\n    return acc\n\n\n\n# Training Loop\ndef train_model(model, train_loader, test_loader, inp_vocab, tgt_vocab, device, epochs=10):\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    best_acc = 0.0\n    for epoch in range(1, epochs + 1):\n        model.train()\n        total_loss = 0\n        for src, tgt in train_loader:\n            src, tgt = src.to(device), tgt.to(device)\n            tgt_inp = tgt[:, :-1]\n            tgt_out = tgt[:, 1:]\n\n            optimizer.zero_grad()\n            output = model(src, tgt_inp)\n            loss = criterion(output.reshape(-1, output.size(-1)), tgt_out.reshape(-1))\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_loss = total_loss / len(train_loader)\n        print(f\"\\nEpoch {epoch} Train Loss: {avg_loss:.4f}\")\n\n        acc = evaluate_test(model, test_loader, inp_vocab, tgt_vocab, device)\n\n        if acc > best_acc:\n            best_acc = acc\n            torch.save(model.state_dict(), \"best_transformer.pt\")\n\n    print(\"\\n Loading best model for final evaluation...\")\n    model.load_state_dict(torch.load(\"best_transformer.pt\", map_location=device))\n    final_acc = evaluate_test(model, test_loader, inp_vocab, tgt_vocab, device, save_csv=True)\n    return final_acc\n\n\n\n# Main\ndef main():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    train_file = \"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\"\n    test_file = \"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\"\n\n    # Load datasets\n    train_dataset = DakshinaDataset(train_file, build_vocab=True)\n    test_dataset = DakshinaDataset(test_file, inp_vocab=train_dataset.inp_vocab, tgt_vocab=train_dataset.tgt_vocab)\n\n    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn)\n    test_loader = DataLoader(test_dataset, batch_size=64, collate_fn=collate_fn)\n\n    # Init model\n    model = TransformerModel(len(train_dataset.inp_vocab), len(train_dataset.tgt_vocab)).to(device)\n\n    # Train + Eval\n    train_model(model, train_loader, test_loader, train_dataset.inp_vocab, train_dataset.tgt_vocab, device, epochs=10)\n\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-30T06:47:28.468504Z","iopub.execute_input":"2025-08-30T06:47:28.469117Z","iopub.status.idle":"2025-08-30T06:50:42.802882Z","shell.execute_reply.started":"2025-08-30T06:47:28.469094Z","shell.execute_reply":"2025-08-30T06:50:42.802256Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1 Train Loss: 1.3305\n\n Test Accuracy: 43.33%\nअंक             | Pred: anka                 | Truth: ank\nअंक             | Pred: ankan                | Truth: anka\nअंकित           | Pred: ankitaattttt         | Truth: ankit\nअंकों           | Pred: akkkonoooonn         | Truth: anakon\nअंकों           | Pred: akkoononnnnn         | Truth: ankhon\nअंकों           | Pred: akkonooooonn         | Truth: ankon\nअंकोर           | Pred: akkooroorrrrr        | Truth: angkor\nअंकोर           | Pred: akkoroorrrrrr        | Truth: ankor\nअंगारक          | Pred: angarrakaaaaa        | Truth: angaarak\nअंगारक          | Pred: angarakaaaaaa        | Truth: angarak\n\nEpoch 2 Train Loss: 0.7339\n\n Test Accuracy: 50.55%\nअंक             | Pred: ank                  | Truth: ank\nअंक             | Pred: ank                  | Truth: anka\nअंकित           | Pred: ankit                | Truth: ankit\nअंकों           | Pred: ankkonnn             | Truth: anakon\nअंकों           | Pred: ankoon               | Truth: ankhon\nअंकों           | Pred: ankonnn              | Truth: ankon\nअंकोर           | Pred: ankaar               | Truth: angkor\nअंकोर           | Pred: ankar                | Truth: ankor\nअंगारक          | Pred: angarrak             | Truth: angaarak\nअंगारक          | Pred: angarak              | Truth: angarak\n\nEpoch 3 Train Loss: 0.5642\n\n Test Accuracy: 51.98%\nअंक             | Pred: ank                  | Truth: ank\nअंक             | Pred: ank                  | Truth: anka\nअंकित           | Pred: ankit                | Truth: ankit\nअंकों           | Pred: anknon               | Truth: anakon\nअंकों           | Pred: ankoan               | Truth: ankhon\nअंकों           | Pred: ankon                | Truth: ankon\nअंकोर           | Pred: ankoor               | Truth: angkor\nअंकोर           | Pred: ankor                | Truth: ankor\nअंगारक          | Pred: angarrkk             | Truth: angaarak\nअंगारक          | Pred: angarak              | Truth: angarak\n\nEpoch 4 Train Loss: 0.4963\n\n Test Accuracy: 52.46%\nअंक             | Pred: ank                  | Truth: ank\nअंक             | Pred: ank                  | Truth: anka\nअंकित           | Pred: ankit                | Truth: ankit\nअंकों           | Pred: ankkonooo            | Truth: anakon\nअंकों           | Pred: ankoonoooo           | Truth: ankhon\nअंकों           | Pred: ankonoooo            | Truth: ankon\nअंकोर           | Pred: ankoor               | Truth: angkor\nअंकोर           | Pred: ankor                | Truth: ankor\nअंगारक          | Pred: angarrkk             | Truth: angaarak\nअंगारक          | Pred: angarkk              | Truth: angarak\n\nEpoch 5 Train Loss: 0.4653\n\n Test Accuracy: 52.80%\nअंक             | Pred: ank                  | Truth: ank\nअंक             | Pred: ank                  | Truth: anka\nअंकित           | Pred: ankit                | Truth: ankit\nअंकों           | Pred: ankkonnnnnn          | Truth: anakon\nअंकों           | Pred: ankoann              | Truth: ankhon\nअंकों           | Pred: ankonnnn             | Truth: ankon\nअंकोर           | Pred: ankoor               | Truth: angkor\nअंकोर           | Pred: ankor                | Truth: ankor\nअंगारक          | Pred: angarrak             | Truth: angaarak\nअंगारक          | Pred: angarak              | Truth: angarak\n\nEpoch 6 Train Loss: 0.4436\n\n Test Accuracy: 53.30%\nअंक             | Pred: ank                  | Truth: ank\nअंक             | Pred: ank                  | Truth: anka\nअंकित           | Pred: ankit                | Truth: ankit\nअंकों           | Pred: ankkon               | Truth: anakon\nअंकों           | Pred: ankoonnnnnn          | Truth: ankhon\nअंकों           | Pred: ankonnnnnnn          | Truth: ankon\nअंकोर           | Pred: ankhor               | Truth: angkor\nअंकोर           | Pred: ankor                | Truth: ankor\nअंगारक          | Pred: angarrak             | Truth: angaarak\nअंगारक          | Pred: angarak              | Truth: angarak\n\nEpoch 7 Train Loss: 0.4359\n\n Test Accuracy: 53.23%\nअंक             | Pred: ank                  | Truth: ank\nअंक             | Pred: ank                  | Truth: anka\nअंकित           | Pred: ankit                | Truth: ankit\nअंकों           | Pred: ankkon               | Truth: anakon\nअंकों           | Pred: ankoonnn             | Truth: ankhon\nअंकों           | Pred: ankonnnnnnn          | Truth: ankon\nअंकोर           | Pred: ankkor               | Truth: angkor\nअंकोर           | Pred: ankor                | Truth: ankor\nअंगारक          | Pred: angarrak             | Truth: angaarak\nअंगारक          | Pred: angarak              | Truth: angarak\n\nEpoch 8 Train Loss: 0.4116\n\n Test Accuracy: 53.47%\nअंक             | Pred: ankkkkkkkkk          | Truth: ank\nअंक             | Pred: ankkkkkk             | Truth: anka\nअंकित           | Pred: ankit                | Truth: ankit\nअंकों           | Pred: anknonnnnnn          | Truth: anakon\nअंकों           | Pred: ankoonnnnnn          | Truth: ankhon\nअंकों           | Pred: ankonnnnnnn          | Truth: ankon\nअंकोर           | Pred: ankoor               | Truth: angkor\nअंकोर           | Pred: ankorrrrr            | Truth: ankor\nअंगारक          | Pred: angarrak             | Truth: angaarak\nअंगारक          | Pred: angarak              | Truth: angarak\n\nEpoch 9 Train Loss: 0.4043\n\n Test Accuracy: 53.51%\nअंक             | Pred: ank                  | Truth: ank\nअंक             | Pred: ankn                 | Truth: anka\nअंकित           | Pred: ankit                | Truth: ankit\nअंकों           | Pred: ankkon               | Truth: anakon\nअंकों           | Pred: ankoon               | Truth: ankhon\nअंकों           | Pred: ankon                | Truth: ankon\nअंकोर           | Pred: ankoor               | Truth: angkor\nअंकोर           | Pred: ankor                | Truth: ankor\nअंगारक          | Pred: angarrak             | Truth: angaarak\nअंगारक          | Pred: angarak              | Truth: angarak\n\nEpoch 10 Train Loss: 0.3876\n\n Test Accuracy: 53.45%\nअंक             | Pred: ank                  | Truth: ank\nअंक             | Pred: ank                  | Truth: anka\nअंकित           | Pred: ankit                | Truth: ankit\nअंकों           | Pred: ankkonn              | Truth: anakon\nअंकों           | Pred: ankoon               | Truth: ankhon\nअंकों           | Pred: ankon                | Truth: ankon\nअंकोर           | Pred: ankoor               | Truth: angkor\nअंकोर           | Pred: ankor                | Truth: ankor\nअंगारक          | Pred: angarrak             | Truth: angaarak\nअंगारक          | Pred: angarak              | Truth: angarak\n\n Loading best model for final evaluation...\n\n Test Accuracy: 53.51%\nअंक             | Pred: ank                  | Truth: ank\nअंक             | Pred: ankn                 | Truth: anka\nअंकित           | Pred: ankit                | Truth: ankit\nअंकों           | Pred: ankkon               | Truth: anakon\nअंकों           | Pred: ankoon               | Truth: ankhon\nअंकों           | Pred: ankon                | Truth: ankon\nअंकोर           | Pred: ankoor               | Truth: angkor\nअंकोर           | Pred: ankor                | Truth: ankor\nअंगारक          | Pred: angarrak             | Truth: angaarak\nअंगारक          | Pred: angarak              | Truth: angarak\n\n Predictions saved to: test_predictions.csv\n","output_type":"stream"}],"execution_count":10}]}