{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12723479,"sourceType":"datasetVersion","datasetId":8041935}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\nwandb.login(key=\"fb4c8007ed0d1fb692b2279b11bb69081f2c698d\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-10T08:15:46.885180Z","iopub.execute_input":"2025-08-10T08:15:46.885718Z","iopub.status.idle":"2025-08-10T08:15:47.978708Z","shell.execute_reply.started":"2025-08-10T08:15:46.885696Z","shell.execute_reply":"2025-08-10T08:15:47.977982Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport pandas as pd\nimport wandb\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T08:15:58.926440Z","iopub.execute_input":"2025-08-10T08:15:58.926703Z","iopub.status.idle":"2025-08-10T08:15:58.930911Z","shell.execute_reply.started":"2025-08-10T08:15:58.926684Z","shell.execute_reply":"2025-08-10T08:15:58.930240Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Dataset utilities\nclass TransliterationDataset(Dataset):\n    def __init__(self, pairs, input_vocab, output_vocab):\n        self.pairs = pairs\n        self.input_vocab = input_vocab\n        self.output_vocab = output_vocab\n        self.sos = output_vocab['<sos>']\n        self.eos = output_vocab['<eos>']\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        source, target = self.pairs[idx]\n        input_ids = [self.input_vocab[c] for c in source]\n        target_ids = [self.sos] + [self.output_vocab[c] for c in target] + [self.eos]\n        return torch.tensor(input_ids), torch.tensor(target_ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T08:16:01.712164Z","iopub.execute_input":"2025-08-10T08:16:01.712392Z","iopub.status.idle":"2025-08-10T08:16:01.717898Z","shell.execute_reply.started":"2025-08-10T08:16:01.712376Z","shell.execute_reply":"2025-08-10T08:16:01.717199Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def build_vocab(pairs):\n    input_chars = set()\n    output_chars = set()\n    for source, target in pairs:\n        input_chars.update(source)\n        output_chars.update(target)\n    input_vocab = {c: i + 1 for i, c in enumerate(sorted(input_chars))}\n    input_vocab['<pad>'] = 0\n    output_vocab = {c: i + 3 for i, c in enumerate(sorted(output_chars))}\n    output_vocab.update({'<pad>': 0, '<sos>': 1, '<eos>': 2})\n    return input_vocab, output_vocab\n\ndef load_pairs(path):\n    df = pd.read_csv(path, sep=\"\\t\", header=None, names=[\"target\", \"source\", \"count\"], dtype=str)\n    df.dropna(subset=[\"source\", \"target\"], inplace=True)\n    return list(zip(df[\"source\"], df[\"target\"]))\n\ndef collate_fn(batch):\n    inputs, targets = zip(*batch)\n    input_lens = [len(seq) for seq in inputs]\n    target_lens = [len(seq) for seq in targets]\n    inputs_padded = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n    targets_padded = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=0)\n    return inputs_padded, targets_padded, input_lens, target_lens\n\nclass Encoder(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, num_layers, cell_type, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(input_size, embed_size, padding_idx=0)\n        rnn_class = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[cell_type]\n        self.rnn = rnn_class(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n\n    def forward(self, x, lengths):\n        x = self.embedding(x)\n        packed = nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n        outputs, hidden = self.rnn(packed)\n        return hidden\n\nclass Decoder(nn.Module):\n    def __init__(self, output_size, embed_size, hidden_size, num_layers, cell_type, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(output_size, embed_size, padding_idx=0)\n        rnn_class = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[cell_type]\n        self.rnn = rnn_class(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, input_token, hidden):\n        x = self.embedding(input_token.unsqueeze(1))\n        output, hidden = self.rnn(x, hidden)\n        output = self.fc(output.squeeze(1))\n        return output, hidden\n\n    def beam_search(self, hidden, max_len, sos_idx, eos_idx, beam_size=3):\n        device = next(self.parameters()).device\n        sequences = [[torch.tensor([sos_idx], device=device), hidden, 0.0]]\n        completed = []\n\n        for _ in range(max_len):\n            new_sequences = []\n            for seq, h, score in sequences:\n                input_token = seq[-1].unsqueeze(0)\n                output, new_hidden = self.forward(input_token, h)\n                probs = torch.log_softmax(output, dim=-1).squeeze(0)\n                topk_probs, topk_indices = probs.topk(beam_size)\n                for i in range(beam_size):\n                    next_token = topk_indices[i].item()\n                    new_score = score + topk_probs[i].item()\n                    new_seq = torch.cat([seq, torch.tensor([next_token], device=device)])\n                    new_sequences.append([new_seq, new_hidden, new_score])\n            sequences = sorted(new_sequences, key=lambda x: x[2], reverse=True)[:beam_size]\n            completed.extend([seq for seq in sequences if seq[0][-1].item() == eos_idx])\n            sequences = [seq for seq in sequences if seq[0][-1].item() != eos_idx]\n            if not sequences:\n                break\n        completed = sorted(completed, key=lambda x: x[2], reverse=True)\n        return completed[0][0] if completed else sequences[0][0]\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, src, src_lens, tgt=None, teacher_forcing_ratio=0.5):\n        batch_size = src.size(0)\n        device = src.device\n        hidden = self.encoder(src, src_lens)\n        if tgt is not None:\n            tgt_len = tgt.size(1)\n            outputs = torch.zeros(batch_size, tgt_len, self.decoder.fc.out_features, device=device)\n            input_token = tgt[:, 0]\n            for t in range(1, tgt_len):\n                output, hidden = self.decoder(input_token, hidden)\n                outputs[:, t] = output\n                teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n                input_token = tgt[:, t] if teacher_force else output.argmax(1)\n            return outputs\n        else:\n            return [self.decoder.beam_search(hidden, max_len=20, sos_idx=1, eos_idx=2) for _ in range(batch_size)]\n\ndef accuracy(preds, targets, pad_idx=0):\n    pred_tokens = preds.argmax(dim=-1)\n    correct = ((pred_tokens == targets) & (targets != pad_idx)).sum().item()\n    total = (targets != pad_idx).sum().item()\n    return correct / total if total > 0 else 0.0\n\ndef train(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss, total_acc = 0, 0\n    for src, tgt, src_lens, tgt_lens in tqdm(loader, desc=\"Training\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n        optimizer.zero_grad()\n        output = model(src, src_lens, tgt)\n        loss = criterion(output[:, 1:].reshape(-1, output.size(-1)), tgt[:, 1:].reshape(-1))\n        acc = accuracy(output[:, 1:], tgt[:, 1:])\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        total_acc += acc\n    return total_loss / len(loader), total_acc / len(loader)\n\n@torch.no_grad()\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    total_loss, total_acc = 0, 0\n    for src, tgt, src_lens, tgt_lens in tqdm(loader, desc=\"Evaluating\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n        output = model(src, src_lens, tgt, teacher_forcing_ratio=0.0)\n        loss = criterion(output[:, 1:].reshape(-1, output.size(-1)), tgt[:, 1:].reshape(-1))\n        acc = accuracy(output[:, 1:], tgt[:, 1:])\n        total_loss += loss.item()\n        total_acc += acc\n    return total_loss / len(loader), total_acc / len(loader)\n\ndef main():\n    import wandb\n    # Run name will be assigned after wandb.init with config\n    def generate_run_name(config):\n        return f\"cell:{config.cell_type}_embed:{config.embed_size}_hid:{config.hidden_size}_layers:{config.num_layers}_beam:{config.beam_size}\"\n\n    # First initialize W&B run with placeholder name\n    wandb.init(project=\"Dakshina-Translitration\", config=wandb.config)\n    config = wandb.config\n\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    train_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    dev_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\")\n\n    input_vocab, output_vocab = build_vocab(train_pairs)\n    train_dataset = TransliterationDataset(train_pairs, input_vocab, output_vocab)\n    dev_dataset = TransliterationDataset(dev_pairs, input_vocab, output_vocab)\n\n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n    dev_loader = DataLoader(dev_dataset, batch_size=config.batch_size, shuffle=False, collate_fn=collate_fn)\n\n    encoder = Encoder(len(input_vocab), config.embed_size, config.hidden_size, config.num_layers, config.cell_type, config.dropout)\n    decoder = Decoder(len(output_vocab), config.embed_size, config.hidden_size, config.num_layers, config.cell_type, config.dropout)\n    model = Seq2Seq(encoder, decoder).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    for epoch in range(10):\n        train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n        val_loss, val_acc = evaluate(model, dev_loader, criterion, device)\n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss,\n            \"train_accuracy\": train_acc,\n            \"val_loss\": val_loss,\n            \"val_accuracy\": val_acc\n        })\n\n\nif __name__ == \"__main__\":\n    sweep_config = {\n        \"method\": \"bayes\",\n        \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n        \"parameters\": {\n            \"embed_size\": {\"values\": [32, 64, 128]},\n            \"hidden_size\": {\"values\": [64, 128, 256]},\n            \"num_layers\": {\"values\": [1,2,3]},\n            \"cell_type\": {\"values\": [\"RNN\", \"GRU\", \"LSTM\"]},\n            \"dropout\": {\"values\": [0.1,0.2, 0.3]},\n            \"lr\": {\"min\": 0.0001, \"max\": 0.01},\n            \"batch_size\": {\"values\": [16,32, 64]},\n            \"beam_size\": {\"values\": [1, 3, 5]}  \n        }\n    }\n\n    sweep_id = wandb.sweep(sweep_config, project=\"Dakshina-Translitration\")\n    wandb.agent(sweep_id, function=main, count=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T08:16:04.498314Z","iopub.execute_input":"2025-08-10T08:16:04.498595Z","iopub.status.idle":"2025-08-10T09:13:05.341480Z","shell.execute_reply.started":"2025-08-10T08:16:04.498560Z","shell.execute_reply":"2025-08-10T09:13:05.340731Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: gycjj862\nSweep URL: https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8zjzrrw8 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001922051055737968\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_081611-8zjzrrw8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/8zjzrrw8' target=\"_blank\">snowy-sweep-1</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/8zjzrrw8' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/8zjzrrw8</a>"},"metadata":{}},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▃▅▆▇▇████</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▄▅▇█▇▇▇█</td></tr><tr><td>val_loss</td><td>█▆▅▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.42475</td></tr><tr><td>train_loss</td><td>2.06822</td></tr><tr><td>val_accuracy</td><td>0.36221</td></tr><tr><td>val_loss</td><td>2.3299</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">snowy-sweep-1</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/8zjzrrw8' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/8zjzrrw8</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250810_081611-8zjzrrw8/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fx2h5q07 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.009732487749796489\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_082328-fx2h5q07</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/fx2h5q07' target=\"_blank\">cool-sweep-2</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/fx2h5q07' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/fx2h5q07</a>"},"metadata":{}},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇▇▇████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▆▇▇▇███</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.66975</td></tr><tr><td>train_loss</td><td>1.08515</td></tr><tr><td>val_accuracy</td><td>0.63397</td></tr><tr><td>val_loss</td><td>1.22073</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">cool-sweep-2</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/fx2h5q07' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/fx2h5q07</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250810_082328-fx2h5q07/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cn34i4ff with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0030315076281821774\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_083041-cn34i4ff</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/cn34i4ff' target=\"_blank\">pious-sweep-3</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/cn34i4ff' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/cn34i4ff</a>"},"metadata":{}},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇▇▇████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇▇▇█▇██</td></tr><tr><td>val_loss</td><td>█▃▃▁▂▃▂▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.85331</td></tr><tr><td>train_loss</td><td>0.48565</td></tr><tr><td>val_accuracy</td><td>0.69376</td></tr><tr><td>val_loss</td><td>1.14946</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">pious-sweep-3</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/cn34i4ff' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/cn34i4ff</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250810_083041-cn34i4ff/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: h2j00wf2 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.009383126656218993\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_083642-h2j00wf2</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/h2j00wf2' target=\"_blank\">logical-sweep-4</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/h2j00wf2' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/h2j00wf2</a>"},"metadata":{}},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇▇▇█▇██</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▄▄▆▇▇█▅</td></tr><tr><td>val_loss</td><td>█▇▆▃▅▆▃▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.56472</td></tr><tr><td>train_loss</td><td>1.39958</td></tr><tr><td>val_accuracy</td><td>0.50193</td></tr><tr><td>val_loss</td><td>1.6292</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">logical-sweep-4</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/h2j00wf2' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/h2j00wf2</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250810_083642-h2j00wf2/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x4ml5nq5 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.006911221668891748\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_084640-x4ml5nq5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/x4ml5nq5' target=\"_blank\">twilight-sweep-5</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/x4ml5nq5' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/x4ml5nq5</a>"},"metadata":{}},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▃▄▃▄▆▇█▆▄</td></tr><tr><td>train_loss</td><td>█▆▄▅▄▂▂▁▃▄</td></tr><tr><td>val_accuracy</td><td>▂▁▁▃▃▃▇█▂▄</td></tr><tr><td>val_loss</td><td>▆▆█▅▅▅▁▁▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.2508</td></tr><tr><td>train_loss</td><td>2.82917</td></tr><tr><td>val_accuracy</td><td>0.23053</td></tr><tr><td>val_loss</td><td>2.97825</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">twilight-sweep-5</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/x4ml5nq5' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/x4ml5nq5</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250810_084640-x4ml5nq5/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vm2ffuwh with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.009947560970155997\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_085213-vm2ffuwh</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/vm2ffuwh' target=\"_blank\">lunar-sweep-6</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/vm2ffuwh' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/vm2ffuwh</a>"},"metadata":{}},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▇▇▇▇▇██▇█</td></tr><tr><td>train_loss</td><td>█▂▁▂▁▁▁▁▂▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▃▃▄█▂▅█</td></tr><tr><td>val_loss</td><td>▇█▄▇▃▃▃▅▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.48319</td></tr><tr><td>train_loss</td><td>1.70215</td></tr><tr><td>val_accuracy</td><td>0.47558</td></tr><tr><td>val_loss</td><td>1.70191</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lunar-sweep-6</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/vm2ffuwh' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/vm2ffuwh</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250810_085213-vm2ffuwh/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u9f4zpds with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.005021942698844929\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_085915-u9f4zpds</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/u9f4zpds' target=\"_blank\">ethereal-sweep-7</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/u9f4zpds' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/u9f4zpds</a>"},"metadata":{}},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▅█▇▆▇▇▇</td></tr><tr><td>val_loss</td><td>█▂▃▄▁▇▅▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.86082</td></tr><tr><td>train_loss</td><td>0.4583</td></tr><tr><td>val_accuracy</td><td>0.69897</td></tr><tr><td>val_loss</td><td>1.16896</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">ethereal-sweep-7</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/u9f4zpds' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/u9f4zpds</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250810_085915-u9f4zpds/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4kcg1153 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001518247469670356\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_090531-4kcg1153</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/4kcg1153' target=\"_blank\">youthful-sweep-8</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/gycjj862</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/4kcg1153' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/4kcg1153</a>"},"metadata":{}},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇▇▇████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▇▇███▇▇▇</td></tr><tr><td>val_loss</td><td>▆▃▁▂▃▄▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.92089</td></tr><tr><td>train_loss</td><td>0.26191</td></tr><tr><td>val_accuracy</td><td>0.71718</td></tr><tr><td>val_loss</td><td>1.21477</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">youthful-sweep-8</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/4kcg1153' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/4kcg1153</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250810_090531-4kcg1153/logs</code>"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"## Test Data","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport pandas as pd\nimport csv\n\n# ---------------- Dataset & Utils ----------------\nclass TransliterationDataset(Dataset):\n    def __init__(self, pairs, input_vocab, output_vocab):\n        self.pairs = pairs\n        self.input_vocab = input_vocab\n        self.output_vocab = output_vocab\n        self.sos = output_vocab['<sos>']\n        self.eos = output_vocab['<eos>']\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        source, target = self.pairs[idx]\n        input_ids = [self.input_vocab[c] for c in source]\n        target_ids = [self.sos] + [self.output_vocab[c] for c in target] + [self.eos]\n        return torch.tensor(input_ids), torch.tensor(target_ids)\n\ndef load_pairs(path):\n    df = pd.read_csv(path, sep='\\t', header=None, names=['target', 'source', 'count'], dtype=str)\n    df.dropna(subset=[\"source\", \"target\"], inplace=True)\n    return list(zip(df['source'], df['target']))\n\ndef build_vocab(pairs):\n    input_chars = set()\n    output_chars = set()\n    for src, tgt in pairs:\n        input_chars.update(src)\n        output_chars.update(tgt)\n    input_vocab = {c: i+1 for i, c in enumerate(sorted(input_chars))}\n    input_vocab['<pad>'] = 0\n    output_vocab = {c: i+3 for i, c in enumerate(sorted(output_chars))}\n    output_vocab.update({'<pad>': 0, '<sos>': 1, '<eos>': 2})\n    return input_vocab, output_vocab\n\ndef collate_fn(batch):\n    inputs, targets = zip(*batch)\n    input_lens = [len(x) for x in inputs]\n    target_lens = [len(x) for x in targets]\n    inputs_padded = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n    targets_padded = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=0)\n    return inputs_padded, targets_padded, input_lens, target_lens\n\n# ---------------- Models ----------------\nclass Encoder(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, num_layers, cell_type, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(input_size, embed_size, padding_idx=0)\n        rnn_cls = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[cell_type]\n        self.rnn = rnn_cls(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n\n    def forward(self, x, lengths):\n        embedded = self.embedding(x)\n        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)\n        outputs, hidden = self.rnn(packed)\n        return hidden\n\nclass Decoder(nn.Module):\n    def __init__(self, output_size, embed_size, hidden_size, num_layers, cell_type, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(output_size, embed_size, padding_idx=0)\n        rnn_cls = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[cell_type]\n        self.rnn = rnn_cls(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, token, hidden):\n        x = self.embedding(token.unsqueeze(1))\n        output, hidden = self.rnn(x, hidden)\n        output = self.fc(output.squeeze(1))\n        return output, hidden\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, src, src_lens, tgt=None, teacher_forcing_ratio=0.5):\n        batch_size = src.size(0)\n        hidden = self.encoder(src, src_lens)\n        tgt_len = tgt.size(1)\n        outputs = torch.zeros(batch_size, tgt_len, self.decoder.fc.out_features).to(src.device)\n        input_token = tgt[:, 0]\n        for t in range(1, tgt_len):\n            output, hidden = self.decoder(input_token, hidden)\n            outputs[:, t] = output\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            input_token = tgt[:, t] if teacher_force else output.argmax(1)\n        return outputs\n\n# ---------------- Train + Eval ----------------\ndef train_model(model, dataloader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    for src, tgt, src_lens, _ in dataloader:\n        src, tgt = src.to(device), tgt.to(device)\n        optimizer.zero_grad()\n        output = model(src, src_lens, tgt)\n        loss = criterion(output[:, 1:].reshape(-1, output.shape[-1]), tgt[:, 1:].reshape(-1))\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(dataloader)\n\ndef evaluate_and_save(model, dataloader, input_vocab, output_vocab, device, csv_path=None):\n    model.eval()\n    inv_input_vocab = {v: k for k, v in input_vocab.items()}\n    inv_output_vocab = {v: k for k, v in output_vocab.items()}\n    correct = 0\n    total = 0\n    results = []\n\n    with torch.no_grad():\n        for src, tgt, src_lens, _ in dataloader:\n            src = src.to(device)\n            hidden = model.encoder(src, src_lens)\n            input_token = torch.tensor([output_vocab['<sos>']] * src.size(0)).to(device)\n            decoded = []\n            for _ in range(20):\n                output, hidden = model.decoder(input_token, hidden)\n                input_token = output.argmax(1)\n                decoded.append(input_token)\n            decoded = torch.stack(decoded, dim=1)\n\n            for i in range(src.size(0)):\n                pred = ''.join([inv_output_vocab[t.item()] for t in decoded[i] if t.item() not in [output_vocab['<eos>'], 0]])\n                truth = ''.join([inv_output_vocab[t.item()] for t in tgt[i][1:-1]])\n                inp = ''.join([inv_input_vocab[t.item()] for t in src[i] if t.item() != 0])\n                results.append((inp, pred, truth))\n                if pred == truth:\n                    correct += 1\n                total += 1\n\n    acc = correct / total * 100\n    print(f\"\\n Test Accuracy: {acc:.2f}%\")\n    for inp, pred, truth in results[:10]:\n        print(f\"{inp:<15} | Pred: {pred:<20} | Truth: {truth}\")\n\n    if csv_path is not None:\n        with open(csv_path, mode='w', newline='', encoding='utf-8') as f:\n            writer = csv.writer(f)\n            writer.writerow(['Input', 'Prediction', 'GroundTruth'])\n            writer.writerows(results)\n        print(f\"\\n Predictions saved to: {csv_path}\")\n\n    return acc, results\n\n\n# ---------------- Run ----------------\nif __name__ == \"__main__\":\n    config = {\n        \"embed_size\": 128,\n        \"hidden_size\": 256,\n        \"num_layers\": 3,\n        \"cell_type\": \"LSTM\",\n        \"dropout\": 0.1,\n        \"batch_size\": 32,\n        \"lr\": 0.001518,\n        \"epochs\": 5,\n    }\n\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    train_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    test_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\")\n    input_vocab, output_vocab = build_vocab(train_pairs)\n    train_dataset = TransliterationDataset(train_pairs, input_vocab, output_vocab)\n    test_dataset = TransliterationDataset(test_pairs, input_vocab, output_vocab)\n\n    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate_fn)\n    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n\n    encoder = Encoder(len(input_vocab), config[\"embed_size\"], config[\"hidden_size\"],\n                      config[\"num_layers\"], config[\"cell_type\"], config[\"dropout\"])\n    decoder = Decoder(len(output_vocab), config[\"embed_size\"], config[\"hidden_size\"],\n                      config[\"num_layers\"], config[\"cell_type\"], config[\"dropout\"])\n    model = Seq2Seq(encoder, decoder).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    best_acc = 0\n    for epoch in range(config[\"epochs\"]):\n        train_loss = train_model(model, train_loader, optimizer, criterion, device)\n        print(f\"Epoch {epoch+1} Train Loss: {train_loss:.4f}\")\n        acc, results = evaluate_and_save(model, test_loader, input_vocab, output_vocab, device, csv_path=None)\n        if acc > best_acc:\n            best_acc = acc\n            torch.save(model.state_dict(), \"best_model.pth\")\n\n    print(\"\\n Loading best model for final evaluation...\")\n    model.load_state_dict(torch.load(\"best_model.pth\"))\n\n    # Save predictions CSV here\n    evaluate_and_save(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T09:40:40.903904Z","iopub.execute_input":"2025-08-10T09:40:40.904669Z","iopub.status.idle":"2025-08-10T09:48:23.125189Z","shell.execute_reply.started":"2025-08-10T09:40:40.904644Z","shell.execute_reply":"2025-08-10T09:48:23.124505Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 Train Loss: 1.6284\n\n Test Accuracy: 24.19%\nank             | Pred: आंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनाकों               | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगकर                | Truth: अंकोर\nankor           | Pred: अंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\nEpoch 2 Train Loss: 0.7540\n\n Test Accuracy: 32.61%\nank             | Pred: आंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनकों                | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगोकर               | Truth: अंकोर\nankor           | Pred: अंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगारक               | Truth: अंगारक\nEpoch 3 Train Loss: 0.5918\n\n Test Accuracy: 34.83%\nank             | Pred: एंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनकों                | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: एंगकोर               | Truth: अंकोर\nankor           | Pred: एंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगराक               | Truth: अंगारक\nEpoch 4 Train Loss: 0.5035\n\n Test Accuracy: 35.45%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनकों                | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगोकर               | Truth: अंकोर\nankor           | Pred: अंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\nEpoch 5 Train Loss: 0.4348\n\n Test Accuracy: 36.65%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: आंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनकों                | Truth: अंकों\nankhon          | Pred: आंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगकोर               | Truth: अंकोर\nankor           | Pred: अंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\n\n Loading best model for final evaluation...\n\n Test Accuracy: 36.65%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: आंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनकों                | Truth: अंकों\nankhon          | Pred: आंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगकोर               | Truth: अंकोर\nankor           | Pred: अंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\n\n Predictions saved to: test_predictions.csv\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  Transformer Model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport wandb\nfrom tqdm import tqdm\nimport math\nimport csv\nfrom collections import namedtuple\n\n# ---------------- Data Processing and Utilities ----------------\n\nclass TransliterationDataset(Dataset):\n    def __init__(self, pairs, input_vocab, output_vocab):\n        self.pairs = pairs\n        self.input_vocab = input_vocab\n        self.output_vocab = output_vocab\n        self.sos = output_vocab['<sos>']\n        self.eos = output_vocab['<eos>']\n        self.unk_in = input_vocab.get('<unk>', 1)\n        self.unk_out = output_vocab.get('<unk>', 3)\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        source, target = self.pairs[idx]\n        input_ids = [self.input_vocab.get(c, self.unk_in) for c in source]\n        target_ids = [self.sos] + [self.output_vocab.get(c, self.unk_out) for c in target] + [self.eos]\n        return torch.tensor(input_ids), torch.tensor(target_ids)\n\ndef build_vocab(pairs):\n    input_chars = set()\n    output_chars = set()\n    for src, tgt in pairs:\n        input_chars.update(src)\n        output_chars.update(tgt)\n    \n    input_vocab = {c: i + 2 for i, c in enumerate(sorted(input_chars))}\n    input_vocab['<pad>'] = 0\n    input_vocab['<unk>'] = 1\n    \n    output_vocab = {c: i + 4 for i, c in enumerate(sorted(output_chars))}\n    output_vocab.update({'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3})\n    \n    return input_vocab, output_vocab\n\ndef load_pairs(path):\n    df = pd.read_csv(path, sep='\\t', header=None, names=['target', 'source', 'count'], dtype=str)\n    df.dropna(subset=[\"source\", \"target\"], inplace=True)\n    return list(zip(df['source'], df['target']))\n\ndef collate_fn(batch):\n    inputs, targets = zip(*batch)\n    inputs_padded = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n    targets_padded = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=0)\n    return inputs_padded, targets_padded\n\n# ---------------- Transformer Specific Components ----------------\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout, max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:, :x.size(1), :]\n        return self.dropout(x)\n\nclass TransformerModel(nn.Module):\n    def __init__(self, input_vocab_size, output_vocab_size, d_model, nhead, num_encoder_layers,\n                 num_decoder_layers, dim_feedforward, dropout):\n        super().__init__()\n        \n        self.d_model = d_model\n        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model, padding_idx=0)\n        self.decoder_embedding = nn.Embedding(output_vocab_size, d_model, padding_idx=0)\n        self.positional_encoding = PositionalEncoding(d_model, dropout)\n        \n        self.transformer = nn.Transformer(\n            d_model=d_model,\n            nhead=nhead,\n            num_encoder_layers=num_encoder_layers,\n            num_decoder_layers=num_decoder_layers,\n            dim_feedforward=dim_feedforward,\n            dropout=dropout,\n            batch_first=True\n        )\n        \n        self.fc_out = nn.Linear(d_model, output_vocab_size)\n        self.output_vocab_size = output_vocab_size\n        self.sos_idx = 1\n        self.eos_idx = 2\n\n    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_padding_mask=None, tgt_padding_mask=None):\n        src_embedded = self.positional_encoding(self.encoder_embedding(src) * math.sqrt(self.d_model))\n        tgt_embedded = self.positional_encoding(self.decoder_embedding(tgt) * math.sqrt(self.d_model))\n        \n        transformer_out = self.transformer(\n            src_embedded, tgt_embedded,\n            src_mask=src_mask,\n            tgt_mask=tgt_mask,\n            src_key_padding_mask=src_padding_mask,\n            tgt_key_padding_mask=tgt_padding_mask\n        )\n        \n        output = self.fc_out(transformer_out)\n        return output\n\n    def generate_square_subsequent_mask(self, sz):\n        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n        return mask\n\n    def create_padding_mask(self, seq, pad_idx=0):\n        return (seq == pad_idx)\n\n# ---------------- Training and Evaluation Functions ----------------\n\ndef accuracy(preds, targets, pad_idx=0):\n    pred_tokens = preds.argmax(dim=-1)\n    correct = ((pred_tokens == targets) & (targets != pad_idx)).sum().item()\n    total = (targets != pad_idx).sum().item()\n    return correct / total if total > 0 else 0.0\n\n@torch.no_grad()\ndef evaluate_word_accuracy(model, dataloader, device, output_vocab):\n    model.eval()\n    correct_words = 0\n    total_words = 0\n    \n    for src, tgt in tqdm(dataloader, desc=\"Evaluating\"):\n        src, tgt = src.to(device), tgt.to(device)\n\n        src_padding_mask = model.create_padding_mask(src).to(device)\n        batch_size = src.size(0)\n        max_len = 20\n        \n        # Inference loop for the decoder\n        generated_tokens = torch.full((batch_size, 1), model.sos_idx, dtype=torch.long, device=device)\n        \n        for t in range(max_len):\n            tgt_mask = model.generate_square_subsequent_mask(generated_tokens.size(1)).to(device)\n            tgt_padding_mask = model.create_padding_mask(generated_tokens).to(device)\n            \n            output = model(src, generated_tokens, src_padding_mask=src_padding_mask, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n            \n            next_token = output[:, -1, :].argmax(dim=-1).unsqueeze(1)\n            generated_tokens = torch.cat([generated_tokens, next_token], dim=1)\n            \n            if (next_token == model.eos_idx).all():\n                break\n\n        for i in range(batch_size):\n            pred_seq = generated_tokens[i]\n            target_seq = tgt[i]\n            \n            pred_end = (pred_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n            target_end = (target_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n            \n            pred_word = pred_seq[1:pred_end[0] if pred_end.numel() > 0 else len(pred_seq)]\n            target_word = target_seq[1:target_end[0] if target_end.numel() > 0 else len(target_seq)]\n\n            if torch.equal(pred_word, target_word):\n                correct_words += 1\n            total_words += 1\n            \n    return correct_words / total_words if total_words > 0 else 0.0\n\ndef train_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss, total_acc = 0, 0\n    for src, tgt in tqdm(loader, desc=\"Training\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n\n        optimizer.zero_grad()\n        \n        src_padding_mask = model.create_padding_mask(src).to(device)\n        tgt_padding_mask = model.create_padding_mask(tgt).to(device)\n        \n        tgt_input = tgt[:, :-1]\n        tgt_output = tgt[:, 1:]\n\n        tgt_mask = model.generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n        \n        output = model(src, tgt_input, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask=tgt_mask)\n        \n        loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n        acc = accuracy(output, tgt_output)\n        \n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        total_acc += acc\n        \n    return total_loss / len(loader), total_acc / len(loader)\n\n# ---------------- Main Function for W&B Sweep ----------------\n\ndef main():\n    import wandb\n    \n    def generate_run_name(config):\n        return f\"transformer_d:{config.d_model}_nhead:{config.nhead}_layers:{config.num_encoder_layers}\"\n\n    wandb.init(project=\"Dakshina-Translitration-Transformer\", config=wandb.config)\n    config = wandb.config\n    wandb.run.name = generate_run_name(config)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    train_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    dev_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\")\n\n    # Build vocab on train + dev pairs for consistency\n    input_vocab, output_vocab = build_vocab(train_pairs + dev_pairs)\n    train_dataset = TransliterationDataset(train_pairs, input_vocab, output_vocab)\n    dev_dataset = TransliterationDataset(dev_pairs, input_vocab, output_vocab)\n\n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n    dev_loader = DataLoader(dev_dataset, batch_size=config.batch_size, shuffle=False, collate_fn=collate_fn)\n\n    model = TransformerModel(\n        input_vocab_size=len(input_vocab),\n        output_vocab_size=len(output_vocab),\n        d_model=config.d_model,\n        nhead=config.nhead,\n        num_encoder_layers=config.num_encoder_layers,\n        num_decoder_layers=config.num_decoder_layers,\n        dim_feedforward=config.dim_feedforward,\n        dropout=config.dropout\n    ).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, betas=(0.9, 0.98), eps=1e-9)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    best_dev_acc = 0\n    for epoch in range(10):\n        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n        dev_acc = evaluate_word_accuracy(model, dev_loader, device, output_vocab)\n        \n        if dev_acc > best_dev_acc:\n            best_dev_acc = dev_acc\n            torch.save(model.state_dict(), 'best_transformer_model.pth')\n            print(f\"Epoch {epoch+1} - New best model saved with dev word accuracy: {best_dev_acc:.4f}\")\n\n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss,\n            \"train_accuracy\": train_acc,\n            \"dev_word_accuracy\": dev_acc\n        })\n\nif __name__ == \"__main__\":\n    sweep_config = {\n        \"method\": \"bayes\",\n        \"metric\": {\"name\": \"dev_word_accuracy\", \"goal\": \"maximize\"},\n        \"parameters\": {\n            \"d_model\": {\"values\": [128, 256, 512]},\n            \"nhead\": {\"values\": [4, 8, 16]},\n            \"num_encoder_layers\": {\"values\": [2, 4]},\n            \"num_decoder_layers\": {\"values\": [2, 4]},\n            \"dim_feedforward\": {\"values\": [512, 1024, 2048]},\n            \"dropout\": {\"values\": [0.1, 0.2, 0.3]},\n            \"lr\": {\"min\": 0.0001, \"max\": 0.001},\n            \"batch_size\": {\"values\": [16, 32, 64]}\n        }\n    }\n    \n    sweep_id = wandb.sweep(sweep_config, project=\"Dakshina-Translitration-Transformer\")\n    wandb.agent(sweep_id, function=main, count=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T09:55:32.657432Z","iopub.execute_input":"2025-08-10T09:55:32.657753Z","iopub.status.idle":"2025-08-10T09:56:32.935105Z","shell.execute_reply.started":"2025-08-10T09:55:32.657730Z","shell.execute_reply":"2025-08-10T09:56:32.934551Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: f7bfyaft\nSweep URL: https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/f7bfyaft\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: drxj6rvz with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 2048\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0006462285506752879\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_095538-drxj6rvz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/drxj6rvz' target=\"_blank\">royal-sweep-1</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/f7bfyaft' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/f7bfyaft</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/f7bfyaft' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/f7bfyaft</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/drxj6rvz' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/drxj6rvz</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/691 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n                                                 \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">transformer_d:256_nhead:16_layers:2</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/drxj6rvz' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/drxj6rvz</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250810_095538-drxj6rvz/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run drxj6rvz errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/2098532379.py\", line 248, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/2098532379.py\", line 194, in train_epoch\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = model(src, tgt_input, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask=tgt_mask)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/2098532379.py\", line 107, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     transformer_out = self.transformer(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                       ^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 279, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = self.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 613, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = mod(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 1108, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x + self._sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 1128, in _sa_block\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x = self.self_attn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         ^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 1373, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\", line 6340, in multi_head_attention_forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _check_key_padding_mask(key_padding_mask, src_len, bsz)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\", line 5989, in _check_key_padding_mask\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     torch._check_with(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1638, in _check_with\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise error_type(message_evaluated)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m AssertionError: Expected key_padded_mask.shape[1] to be 15, but got 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qzdp52xb with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.000887035088632875\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_095559-qzdp52xb</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/qzdp52xb' target=\"_blank\">still-sweep-2</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/f7bfyaft' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/f7bfyaft</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/f7bfyaft' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/f7bfyaft</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/qzdp52xb' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/qzdp52xb</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/691 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n                                                 \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">transformer_d:128_nhead:16_layers:4</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/qzdp52xb' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/qzdp52xb</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250810_095559-qzdp52xb/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run qzdp52xb errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/2098532379.py\", line 248, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/2098532379.py\", line 194, in train_epoch\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = model(src, tgt_input, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask=tgt_mask)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/2098532379.py\", line 107, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     transformer_out = self.transformer(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                       ^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 279, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = self.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 613, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = mod(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 1108, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x + self._sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 1128, in _sa_block\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x = self.self_attn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         ^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 1373, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\", line 6340, in multi_head_attention_forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _check_key_padding_mask(key_padding_mask, src_len, bsz)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\", line 5989, in _check_key_padding_mask\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     torch._check_with(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1638, in _check_with\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise error_type(message_evaluated)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m AssertionError: Expected key_padded_mask.shape[1] to be 13, but got 14\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pc59y6ge with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 2048\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0004115740826136369\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_095620-pc59y6ge</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/pc59y6ge' target=\"_blank\">lilac-sweep-3</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/f7bfyaft' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/f7bfyaft</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/f7bfyaft' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/f7bfyaft</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/pc59y6ge' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/pc59y6ge</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/2763 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n                                                  \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">transformer_d:128_nhead:16_layers:4</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/pc59y6ge' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/pc59y6ge</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250810_095620-pc59y6ge/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run pc59y6ge errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/2098532379.py\", line 248, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/2098532379.py\", line 194, in train_epoch\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = model(src, tgt_input, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask=tgt_mask)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/2098532379.py\", line 107, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     transformer_out = self.transformer(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                       ^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 279, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = self.decoder(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 613, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = mod(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m              ^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 1108, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x + self._sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 1128, in _sa_block\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     x = self.self_attn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m         ^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return self._call_impl(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return forward_call(*args, **kwargs)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\", line 1373, in forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\", line 6340, in multi_head_attention_forward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _check_key_padding_mask(key_padding_mask, src_len, bsz)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\", line 5989, in _check_key_padding_mask\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     torch._check_with(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1638, in _check_with\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     raise error_type(message_evaluated)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m AssertionError: Expected key_padded_mask.shape[1] to be 11, but got 12\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Detected 3 failed runs in the first 60 seconds, killing sweep.\n\u001b[34m\u001b[1mwandb\u001b[0m: To disable this check set WANDB_AGENT_DISABLE_FLAPPING=true\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport wandb\nfrom tqdm import tqdm\nimport math\nimport csv\nfrom collections import namedtuple\n\n# ---------------- Data Processing and Utilities ----------------\n\nclass TransliterationDataset(Dataset):\n    def __init__(self, pairs, input_vocab, output_vocab):\n        self.pairs = pairs\n        self.input_vocab = input_vocab\n        self.output_vocab = output_vocab\n        self.sos = output_vocab['<sos>']\n        self.eos = output_vocab['<eos>']\n        # Robustly get unk indices, with fallbacks\n        self.unk_in = input_vocab.get('<unk>', 1) \n        self.unk_out = output_vocab.get('<unk>', 3)\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        source, target = self.pairs[idx]\n        # Use .get() with unk_in/unk_out for handling unseen characters\n        input_ids = [self.input_vocab.get(c, self.unk_in) for c in source]\n        target_ids = [self.sos] + [self.output_vocab.get(c, self.unk_out) for c in target] + [self.eos]\n        return torch.tensor(input_ids), torch.tensor(target_ids)\n\ndef build_vocab(pairs):\n    input_chars = set()\n    output_chars = set()\n    for src, tgt in pairs:\n        input_chars.update(src)\n        output_chars.update(tgt)\n    \n    # Vocab indexing: <pad>:0, <unk>:1, then sorted chars\n    input_vocab = {c: i + 2 for i, c in enumerate(sorted(input_chars))}\n    input_vocab['<pad>'] = 0\n    input_vocab['<unk>'] = 1\n    \n    # Vocab indexing: <pad>:0, <sos>:1, <eos>:2, <unk>:3, then sorted chars\n    output_vocab = {c: i + 4 for i, c in enumerate(sorted(output_chars))}\n    output_vocab.update({'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3})\n    \n    return input_vocab, output_vocab\n\ndef load_pairs(path):\n    # Ensure the path is correct for your environment (e.g., Kaggle, local, Colab)\n    # Common issue: FileNotFoundError if path is wrong.\n    df = pd.read_csv(path, sep='\\t', header=None, names=['target', 'source', 'count'], dtype=str)\n    df.dropna(subset=[\"source\", \"target\"], inplace=True)\n    return list(zip(df['source'], df['target']))\n\ndef collate_fn(batch):\n    inputs, targets = zip(*batch)\n    inputs_padded = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n    targets_padded = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=0)\n    return inputs_padded, targets_padded\n\n# ---------------- Transformer Specific Components ----------------\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout, max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0) # Add batch dimension\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        # Add positional encoding to input embeddings\n        x = x + self.pe[:, :x.size(1), :]\n        return self.dropout(x)\n\nclass TransformerModel(nn.Module):\n    def __init__(self, input_vocab_size, output_vocab_size, d_model, nhead, num_encoder_layers,\n                 num_decoder_layers, dim_feedforward, dropout):\n        super().__init__()\n        \n        self.d_model = d_model\n        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model, padding_idx=0)\n        self.decoder_embedding = nn.Embedding(output_vocab_size, d_model, padding_idx=0)\n        self.positional_encoding = PositionalEncoding(d_model, dropout)\n        \n        self.transformer = nn.Transformer(\n            d_model=d_model,\n            nhead=nhead,\n            num_encoder_layers=num_encoder_layers,\n            num_decoder_layers=num_decoder_layers,\n            dim_feedforward=dim_feedforward,\n            dropout=dropout,\n            batch_first=True # Important: Use batch_first for convenience\n        )\n        \n        self.fc_out = nn.Linear(d_model, output_vocab_size)\n        self.output_vocab_size = output_vocab_size\n        self.sos_idx = 1\n        self.eos_idx = 2\n\n    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_padding_mask=None, tgt_padding_mask=None):\n        # Embed and add positional encoding\n        src_embedded = self.positional_encoding(self.encoder_embedding(src) * math.sqrt(self.d_model))\n        tgt_embedded = self.positional_encoding(self.decoder_embedding(tgt) * math.sqrt(self.d_model))\n        \n        # Pass through Transformer layers\n        transformer_out = self.transformer(\n            src_embedded, tgt_embedded,\n            src_mask=src_mask,\n            tgt_mask=tgt_mask,\n            src_key_padding_mask=src_padding_mask,\n            tgt_key_padding_mask=tgt_padding_mask\n        )\n        \n        # Linear layer to get vocabulary logits\n        output = self.fc_out(transformer_out)\n        return output\n\n    def generate_square_subsequent_mask(self, sz):\n        # Generates a mask to prevent attention to future tokens in the decoder\n        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n        return mask\n\n    def create_padding_mask(self, seq, pad_idx=0):\n        # Generates a boolean mask for padding tokens\n        return (seq == pad_idx)\n\n# ---------------- Training and Evaluation Functions ----------------\n\ndef accuracy(preds, targets, pad_idx=0):\n    # Calculates character-level accuracy, ignoring padding\n    pred_tokens = preds.argmax(dim=-1)\n    correct = ((pred_tokens == targets) & (targets != pad_idx)).sum().item()\n    total = (targets != pad_idx).sum().item()\n    return correct / total if total > 0 else 0.0\n\n@torch.no_grad()\ndef evaluate_word_accuracy(model, dataloader, device, output_vocab):\n    model.eval()\n    correct_words = 0\n    total_words = 0\n    inv_output_vocab = {v: k for k, v in output_vocab.items()}\n    \n    for src, tgt in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n\n        src_padding_mask = model.create_padding_mask(src).to(device)\n        batch_size = src.size(0)\n        max_len = 20 # Max length for generated output (could be dynamically set based on input length if needed)\n        \n        # Initialize decoder input with <sos> tokens for greedy decoding\n        generated_tokens = torch.full((batch_size, 1), model.sos_idx, dtype=torch.long, device=device)\n        \n        for t in range(max_len):\n            # Create masks for the current generated sequence length\n            tgt_mask = model.generate_square_subsequent_mask(generated_tokens.size(1)).to(device)\n            tgt_padding_mask = model.create_padding_mask(generated_tokens).to(device)\n            \n            # Forward pass to get next token predictions\n            output = model(src, generated_tokens, src_padding_mask=src_padding_mask, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n            \n            # Get the token with the highest probability\n            next_token = output[:, -1, :].argmax(dim=-1).unsqueeze(1)\n            \n            # Append the predicted token to the generated sequence\n            generated_tokens = torch.cat([generated_tokens, next_token], dim=1)\n            \n            # Stop if all sequences in the batch have generated the <eos> token\n            if (next_token == model.eos_idx).all():\n                break\n\n        # Calculate word-level accuracy\n        for i in range(batch_size):\n            pred_seq = generated_tokens[i]\n            target_seq = tgt[i]\n            \n            # Find the first <eos> token to trim the sequence (excluding <sos> and <eos> itself)\n            pred_end = (pred_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n            target_end = (target_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n            \n            # Extract the actual word tokens, excluding <sos> and <eos>\n            pred_word = pred_seq[1:pred_end[0] if pred_end.numel() > 0 else len(pred_seq)]\n            target_word = target_seq[1:target_end[0] if target_end.numel() > 0 else len(target_seq)]\n\n            if torch.equal(pred_word, target_word):\n                correct_words += 1\n            total_words += 1\n            \n    return correct_words / total_words if total_words > 0 else 0.0\n\ndef train_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss, total_char_acc = 0, 0\n    for src, tgt in tqdm(loader, desc=\"Training\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n\n        optimizer.zero_grad()\n        \n        src_padding_mask = model.create_padding_mask(src).to(device)\n        \n        tgt_input = tgt[:, :-1] # Input for decoder, excludes the last token\n        tgt_output = tgt[:, 1:]  # Target for loss, excludes the first token (<sos>)\n\n        # ************ CRITICAL FIX ************\n        # Create tgt_padding_mask from tgt_input to match its length\n        tgt_padding_mask = model.create_padding_mask(tgt_input).to(device)\n       \n        \n        tgt_mask = model.generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n        \n        output = model(src, tgt_input, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask=tgt_mask)\n        \n        # Reshape output and target for CrossEntropyLoss\n        loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n        char_acc = accuracy(output, tgt_output) # Character-level accuracy\n        \n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        total_char_acc += char_acc\n        \n    return total_loss / len(loader), total_char_acc / len(loader)\n\ndef generate_predictions_csv(model, dataloader, input_vocab, output_vocab, device, csv_path):\n    model.eval()\n    inv_input_vocab = {v: k for k, v in input_vocab.items()}\n    inv_output_vocab = {v: k for k, v in output_vocab.items()}\n    results = []\n\n    with torch.no_grad():\n        for src, tgt in tqdm(dataloader, desc=\"Generating Test Predictions\"):\n            src = src.to(device)\n            batch_size = src.size(0)\n            max_len = 20 # Max length for generated output\n\n            # Inference loop for the decoder (similar to evaluate_word_accuracy)\n            generated_tokens = torch.full((batch_size, 1), model.sos_idx, dtype=torch.long, device=device)\n            \n            for t in range(max_len):\n                tgt_mask = model.generate_square_subsequent_mask(generated_tokens.size(1)).to(device)\n                tgt_padding_mask = model.create_padding_mask(generated_tokens).to(device)\n                \n                output = model(src, generated_tokens, src_padding_mask=src_padding_mask, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n                \n                next_token = output[:, -1, :].argmax(dim=-1).unsqueeze(1)\n                generated_tokens = torch.cat([generated_tokens, next_token], dim=1)\n                \n                if (next_token == model.eos_idx).all():\n                    break\n\n            for i in range(batch_size):\n                pred_seq = generated_tokens[i]\n                target_seq = tgt[i]\n                \n                pred_end = (pred_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n                target_end = (target_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n                \n                pred_word_tokens = pred_seq[1:pred_end[0] if pred_end.numel() > 0 else len(pred_seq)]\n                # Ensure truth_word_tokens also excludes any potential padding if it's shorter than predicted length\n                truth_word_tokens = target_seq[1:target_end[0] if target_end.numel() > 0 else len(target_seq)]\n\n                pred_str = ''.join([inv_output_vocab[t.item()] for t in pred_word_tokens if t.item() not in [model.sos_idx, model.eos_idx, 0]])\n                truth_str = ''.join([inv_output_vocab[t.item()] for t in truth_word_tokens if t.item() not in [model.sos_idx, model.eos_idx, 0]])\n                inp_str = ''.join([inv_input_vocab[t.item()] for t in src[i] if t.item() != 0])\n                results.append((inp_str, pred_str, truth_str))\n    \n    with open(csv_path, mode='w', newline='', encoding='utf-8') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Input', 'Prediction', 'GroundTruth'])\n        writer.writerows(results)\n    print(f\"\\nPredictions saved to: {csv_path}\")\n\n# ---------------- Main Function for W&B Sweep ----------------\n\ndef main():\n    import wandb\n    \n    def generate_run_name(config):\n        return f\"transformer_d:{config.d_model}_nhead:{config.nhead}_layers:{config.num_encoder_layers}\"\n\n    wandb.init(project=\"Dakshina-Translitration-Transformer\", config=wandb.config)\n    config = wandb.config\n    wandb.run.name = generate_run_name(config)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    train_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    dev_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\")\n    test_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\")\n    # *******************************************************************\n\n    # Build vocab on train + dev pairs for consistency\n    input_vocab, output_vocab = build_vocab(train_pairs + dev_pairs)\n    train_dataset = TransliterationDataset(train_pairs, input_vocab, output_vocab)\n    dev_dataset = TransliterationDataset(dev_pairs, input_vocab, output_vocab)\n    test_dataset = TransliterationDataset(test_pairs, input_vocab, output_vocab) # Prepare test dataset here\n\n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n    dev_loader = DataLoader(dev_dataset, batch_size=config.batch_size, shuffle=False, collate_fn=collate_fn)\n    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn) # Batch size 1 for individual prediction\n\n    model = TransformerModel(\n        input_vocab_size=len(input_vocab),\n        output_vocab_size=len(output_vocab),\n        d_model=config.d_model,\n        nhead=config.nhead,\n        num_encoder_layers=config.num_encoder_layers,\n        num_decoder_layers=config.num_decoder_layers,\n        dim_feedforward=config.dim_feedforward,\n        dropout=config.dropout\n    ).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, betas=(0.9, 0.98), eps=1e-9)\n    criterion = nn.CrossEntropyLoss(ignore_index=0) # ignore_index=0 for <pad> token\n\n    best_dev_acc = 0\n    # Training loop\n    for epoch in range(10): # Looping for 10 epochs\n        train_loss, train_char_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n        dev_word_acc = evaluate_word_accuracy(model, dev_loader, device, output_vocab)\n        \n        print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Train Char Acc: {train_char_acc:.4f} | Dev Word Acc: {dev_word_acc:.4f}\")\n        \n        if dev_word_acc > best_dev_acc:\n            best_dev_acc = dev_word_acc\n            torch.save(model.state_dict(), 'best_transformer_model.pth')\n            print(f\" -> New best model saved with dev word accuracy: {best_dev_acc:.4f}\")\n\n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss,\n            \"train_char_accuracy\": train_char_acc,\n            \"dev_word_accuracy\": dev_word_acc\n        })\n\n    print(\"\\nTraining complete. Loading best model for final evaluation on test set...\")\n    # Load the best model found during training\n    try:\n        model.load_state_dict(torch.load('best_transformer_model.pth'))\n    except FileNotFoundError:\n        print(\"Error: 'best_transformer_model.pth' not found. Ensure training completed successfully and model was saved.\")\n        return # Exit main if model not found\n\n    # Final evaluation on the test set (using the best saved model)\n    final_test_word_acc = evaluate_word_accuracy(model, test_loader, device, output_vocab)\n    print(f\"\\n--- Final Test Set Evaluation Results ---\")\n    print(f\"Word-level Accuracy on Test Set: {final_test_word_acc:.4f}\")\n    \n    # Generate and save predictions to CSV using the best model\n    generate_predictions_csv(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")\n    print(\"Test predictions saved to test_predictions.csv\")\n\n\nif __name__ == \"__main__\":\n    # Define your W&B sweep configuration\n    sweep_config = {\n        \"method\": \"bayes\", # Bayesian optimization\n        \"metric\": {\"name\": \"dev_word_accuracy\", \"goal\": \"maximize\"},\n        \"parameters\": {\n            \"d_model\": {\"values\": [128, 256, 512]},\n            \"nhead\": {\"values\": [4, 8, 16]},\n            \"num_encoder_layers\": {\"values\": [2, 4]},\n            \"num_decoder_layers\": {\"values\": [2, 4]},\n            \"dim_feedforward\": {\"values\": [512, 1024, 2048]},\n            \"dropout\": {\"values\": [0.1, 0.2, 0.3]},\n            \"lr\": {\"min\": 0.0001, \"max\": 0.001},\n            \"batch_size\": {\"values\": [16, 32, 64]}\n        }\n    }\n    \n    # Initialize and run the W&B agent\n    sweep_id = wandb.sweep(sweep_config, project=\"Dakshina-Translitration-Transformer\")\n    wandb.agent(sweep_id, function=main, count=8) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T10:03:38.681701Z","iopub.execute_input":"2025-08-10T10:03:38.681930Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: ilxyaevh\nSweep URL: https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cxwjmo2x with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 2048\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0006925786628377431\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_100344-cxwjmo2x</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/cxwjmo2x' target=\"_blank\">honest-sweep-1</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/cxwjmo2x' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/cxwjmo2x</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/691 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nEvaluating:   0%|          | 0/69 [00:00<?, ?it/s]         /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n  output = torch._nested_tensor_from_mask(\n                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 1.7770 | Train Char Acc: 0.4555 | Dev Word Acc: 0.0016\n -> New best model saved with dev word accuracy: 0.0016\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.3094 | Train Char Acc: 0.5634 | Dev Word Acc: 0.0092\n -> New best model saved with dev word accuracy: 0.0092\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.1540 | Train Char Acc: 0.6119 | Dev Word Acc: 0.0190\n -> New best model saved with dev word accuracy: 0.0190\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.0516 | Train Char Acc: 0.6457 | Dev Word Acc: 0.0294\n -> New best model saved with dev word accuracy: 0.0294\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 0.9663 | Train Char Acc: 0.6739 | Dev Word Acc: 0.0399\n -> New best model saved with dev word accuracy: 0.0399\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 0.8824 | Train Char Acc: 0.7017 | Dev Word Acc: 0.0441\n -> New best model saved with dev word accuracy: 0.0441\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 0.8021 | Train Char Acc: 0.7289 | Dev Word Acc: 0.0624\n -> New best model saved with dev word accuracy: 0.0624\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 0.7341 | Train Char Acc: 0.7507 | Dev Word Acc: 0.0665\n -> New best model saved with dev word accuracy: 0.0665\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train Loss: 0.6814 | Train Char Acc: 0.7693 | Dev Word Acc: 0.0909\n -> New best model saved with dev word accuracy: 0.0909\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 0.6320 | Train Char Acc: 0.7855 | Dev Word Acc: 0.0808\n\nTraining complete. Loading best model for final evaluation on test set...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n--- Final Test Set Evaluation Results ---\nWord-level Accuracy on Test Set: 0.0760\n","output_type":"stream"},{"name":"stderr","text":"Generating Test Predictions:   0%|          | 0/4502 [00:00<?, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>▁▂▂▃▄▄▆▆█▇</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▅▄▄▃▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>0.08077</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>train_char_accuracy</td><td>0.78549</td></tr><tr><td>train_loss</td><td>0.63196</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">transformer_d:128_nhead:8_layers:4</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/cxwjmo2x' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/cxwjmo2x</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250810_100344-cxwjmo2x/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run cxwjmo2x errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/3770549514.py\", line 361, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     generate_predictions_csv(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/3770549514.py\", line 254, in generate_predictions_csv\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = model(src, generated_tokens, src_padding_mask=src_padding_mask, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                                            ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m NameError: name 'src_padding_mask' is not defined\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cas7wbb8 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 2048\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00046258022865950553\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_101223-cas7wbb8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/cas7wbb8' target=\"_blank\">zany-sweep-2</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/cas7wbb8' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/cas7wbb8</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/2763 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 2.0899 | Train Char Acc: 0.3747 | Dev Word Acc: 0.0083\n -> New best model saved with dev word accuracy: 0.0083\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.6927 | Train Char Acc: 0.4573 | Dev Word Acc: 0.0108\n -> New best model saved with dev word accuracy: 0.0108\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.5802 | Train Char Acc: 0.4862 | Dev Word Acc: 0.0147\n -> New best model saved with dev word accuracy: 0.0147\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.5191 | Train Char Acc: 0.5036 | Dev Word Acc: 0.0145\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 1.4771 | Train Char Acc: 0.5147 | Dev Word Acc: 0.0099\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 1.4439 | Train Char Acc: 0.5251 | Dev Word Acc: 0.0122\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 1.4197 | Train Char Acc: 0.5312 | Dev Word Acc: 0.0172\n -> New best model saved with dev word accuracy: 0.0172\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 1.4027 | Train Char Acc: 0.5381 | Dev Word Acc: 0.0172\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train Loss: 1.3864 | Train Char Acc: 0.5433 | Dev Word Acc: 0.0177\n -> New best model saved with dev word accuracy: 0.0177\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 1.3726 | Train Char Acc: 0.5494 | Dev Word Acc: 0.0170\n\nTraining complete. Loading best model for final evaluation on test set...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n--- Final Test Set Evaluation Results ---\nWord-level Accuracy on Test Set: 0.0284\n","output_type":"stream"},{"name":"stderr","text":"Generating Test Predictions:   0%|          | 0/4502 [00:00<?, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>▁▃▆▆▂▄███▇</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>0.01698</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>train_char_accuracy</td><td>0.5494</td></tr><tr><td>train_loss</td><td>1.37263</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">transformer_d:128_nhead:4_layers:2</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/cas7wbb8' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/cas7wbb8</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250810_101223-cas7wbb8/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run cas7wbb8 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/3770549514.py\", line 361, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     generate_predictions_csv(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/3770549514.py\", line 254, in generate_predictions_csv\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = model(src, generated_tokens, src_padding_mask=src_padding_mask, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                                            ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m NameError: name 'src_padding_mask' is not defined\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s9983zfs with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0006144003442019807\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_102726-s9983zfs</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/s9983zfs' target=\"_blank\">vague-sweep-3</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/s9983zfs' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/s9983zfs</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/691 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 1.9912 | Train Char Acc: 0.4046 | Dev Word Acc: 0.0011\n -> New best model saved with dev word accuracy: 0.0011\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.4863 | Train Char Acc: 0.5148 | Dev Word Acc: 0.0034\n -> New best model saved with dev word accuracy: 0.0034\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.3464 | Train Char Acc: 0.5530 | Dev Word Acc: 0.0053\n -> New best model saved with dev word accuracy: 0.0053\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.2606 | Train Char Acc: 0.5787 | Dev Word Acc: 0.0064\n -> New best model saved with dev word accuracy: 0.0064\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 1.1978 | Train Char Acc: 0.5976 | Dev Word Acc: 0.0050\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 1.1471 | Train Char Acc: 0.6131 | Dev Word Acc: 0.0103\n -> New best model saved with dev word accuracy: 0.0103\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 1.1096 | Train Char Acc: 0.6248 | Dev Word Acc: 0.0147\n -> New best model saved with dev word accuracy: 0.0147\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 1.0693 | Train Char Acc: 0.6387 | Dev Word Acc: 0.0172\n -> New best model saved with dev word accuracy: 0.0172\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train Loss: 1.0282 | Train Char Acc: 0.6527 | Dev Word Acc: 0.0154\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 0.9830 | Train Char Acc: 0.6682 | Dev Word Acc: 0.0259\n -> New best model saved with dev word accuracy: 0.0259\n\nTraining complete. Loading best model for final evaluation on test set...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n--- Final Test Set Evaluation Results ---\nWord-level Accuracy on Test Set: 0.0213\n","output_type":"stream"},{"name":"stderr","text":"Generating Test Predictions:   0%|          | 0/4502 [00:00<?, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>▁▂▂▂▂▄▅▆▅█</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▄▄▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>0.02593</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>train_char_accuracy</td><td>0.6682</td></tr><tr><td>train_loss</td><td>0.98304</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">transformer_d:128_nhead:4_layers:2</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/s9983zfs' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/s9983zfs</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250810_102726-s9983zfs/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run s9983zfs errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/3770549514.py\", line 361, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     generate_predictions_csv(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_36/3770549514.py\", line 254, in generate_predictions_csv\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = model(src, generated_tokens, src_padding_mask=src_padding_mask, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                                            ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m NameError: name 'src_padding_mask' is not defined\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d7bdx0xz with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 2048\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0003695183499940154\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250810_103757-d7bdx0xz</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/d7bdx0xz' target=\"_blank\">winter-sweep-4</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/ilxyaevh</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/d7bdx0xz' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/d7bdx0xz</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/2763 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 1.9718 | Train Char Acc: 0.3977 | Dev Word Acc: 0.0085\n -> New best model saved with dev word accuracy: 0.0085\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.5602 | Train Char Acc: 0.4907 | Dev Word Acc: 0.0133\n -> New best model saved with dev word accuracy: 0.0133\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.4514 | Train Char Acc: 0.5214 | Dev Word Acc: 0.0138\n -> New best model saved with dev word accuracy: 0.0138\n","output_type":"stream"},{"name":"stderr","text":"Training:  28%|██▊       | 780/2763 [00:17<00:44, 44.87it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## For Test data","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nimport pandas as pd\nimport csv\nfrom collections import namedtuple\nimport math\n\n# --- Copy all classes and utility functions from the training script ---\n# This includes:\n# - TransliterationDataset, build_vocab, load_pairs, collate_fn\n# - PositionalEncoding, TransformerModel\n\n# ----------------- (Paste all the above classes and functions here) -----------------\n# For brevity, I'm not duplicating them, but you should copy them exactly as they are in the training code.\n# The TransformerModel class must be exactly the same as the one used for training.\n\n# ----------------- Evaluation Function for Final Test Set -----------------\n\n@torch.no_grad()\ndef evaluate_test_set(model, test_loader, device, output_vocab):\n    model.eval()\n    correct_words = 0\n    total_words = 0\n    results = []\n    inv_input_vocab = {v: k for k, v in output_vocab.items()}\n    inv_output_vocab = {v: k for k, v in output_vocab.items()}\n    \n    for src, tgt in tqdm(test_loader, desc=\"Evaluating Test Set\"):\n        src, tgt = src.to(device), tgt.to(device)\n\n        src_padding_mask = model.create_padding_mask(src).to(device)\n        batch_size = src.size(0)\n        max_len = 20\n        \n        generated_tokens = torch.full((batch_size, 1), model.sos_idx, dtype=torch.long, device=device)\n        \n        for t in range(max_len):\n            tgt_mask = model.generate_square_subsequent_mask(generated_tokens.size(1)).to(device)\n            tgt_padding_mask = model.create_padding_mask(generated_tokens).to(device)\n            \n            output = model(src, generated_tokens, src_padding_mask=src_padding_mask, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n            \n            next_token = output[:, -1, :].argmax(dim=-1).unsqueeze(1)\n            generated_tokens = torch.cat([generated_tokens, next_token], dim=1)\n            \n            if (next_token == model.eos_idx).all():\n                break\n\n        for i in range(batch_size):\n            pred_seq = generated_tokens[i]\n            target_seq = tgt[i]\n            \n            pred_end = (pred_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n            target_end = (target_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n            \n            pred_word = pred_seq[1:pred_end[0] if pred_end.numel() > 0 else len(pred_seq)]\n            target_word = target_seq[1:target_end[0] if target_end.numel() > 0 else len(target_seq)]\n\n            pred_str = ''.join([inv_output_vocab[t.item()] for t in pred_word])\n            truth_str = ''.join([inv_output_vocab[t.item()] for t in target_word])\n            inp_str = ''.join([inv_input_vocab[t.item()] for t in src[i] if t.item() != 0])\n            results.append((inp_str, pred_str, truth_str))\n\n            if torch.equal(pred_word, target_word):\n                correct_words += 1\n            total_words += 1\n            \n    acc = correct_words / total_words if total_words > 0 else 0.0\n    \n    # Save predictions to CSV\n    with open(\"test_predictions.csv\", mode='w', newline='', encoding='utf-8') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Input', 'Prediction', 'GroundTruth'])\n        writer.writerows(results)\n    \n    return acc\n\nif __name__ == \"__0\": # Renamed to avoid running accidentally\n    # --- Load Data and Vocabularies ---\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    train_pairs = load_pairs(\"/kaggle/input/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    dev_pairs = load_pairs(\"/kaggle/input/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\")\n    test_pairs = load_pairs(\"/kaggle/input/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\")\n\n    input_vocab, output_vocab = build_vocab(train_pairs + dev_pairs)\n    test_dataset = TransliterationDataset(test_pairs, input_vocab, output_vocab)\n    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n\n    # --- Define Model and Load Best Weights ---\n    config = namedtuple('Config', ['d_model', 'nhead', 'num_encoder_layers', 'num_decoder_layers', 'dim_feedforward', 'dropout'])\n    # Replace these values with the best ones from your W&B sweep\n    best_config = config(d_model=256, nhead=8, num_encoder_layers=4, num_decoder_layers=4, dim_feedforward=1024, dropout=0.1)\n\n    model = TransformerModel(\n        input_vocab_size=len(input_vocab),\n        output_vocab_size=len(output_vocab),\n        d_model=best_config.d_model,\n        nhead=best_config.nhead,\n        num_encoder_layers=best_config.num_encoder_layers,\n        num_decoder_layers=best_config.num_decoder_layers,\n        dim_feedforward=best_config.dim_feedforward,\n        dropout=best_config.dropout\n    ).to(device)\n\n    try:\n        model.load_state_dict(torch.load('best_transformer_model.pth'))\n        print(\"Successfully loaded the trained model.\")\n    except FileNotFoundError:\n        print(\"Model file 'best_transformer_model.pth' not found. Please train a model and save it first.\")\n        exit()\n\n    # --- Run Final Evaluation ---\n    final_test_acc = evaluate_test_set(model, test_loader, device, output_vocab)\n    print(\"\\n--- Final Test Set Evaluation Results ---\")\n    print(f\"Word-level Accuracy: {final_test_acc:.4f}\")\n    print(\"Predictions saved to test_predictions.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}