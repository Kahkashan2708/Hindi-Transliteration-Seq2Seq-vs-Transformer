{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12723479,"sourceType":"datasetVersion","datasetId":8041935}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\nwandb.login(key=\"fb4c8007ed0d1fb692b2279b11bb69081f2c698d\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:10:32.570535Z","iopub.execute_input":"2025-08-12T07:10:32.570785Z","iopub.status.idle":"2025-08-12T07:10:41.382732Z","shell.execute_reply.started":"2025-08-12T07:10:32.570760Z","shell.execute_reply":"2025-08-12T07:10:41.382077Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma23c014\u001b[0m (\u001b[33mma23c014-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport pandas as pd\nimport wandb\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T08:35:22.963103Z","iopub.execute_input":"2025-08-11T08:35:22.963827Z","iopub.status.idle":"2025-08-11T08:35:31.650488Z","shell.execute_reply.started":"2025-08-11T08:35:22.963800Z","shell.execute_reply":"2025-08-11T08:35:31.649710Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Dataset utilities\nclass TransliterationDataset(Dataset):\n    def __init__(self, pairs, input_vocab, output_vocab):\n        self.pairs = pairs\n        self.input_vocab = input_vocab\n        self.output_vocab = output_vocab\n        self.sos = output_vocab['<sos>']\n        self.eos = output_vocab['<eos>']\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        source, target = self.pairs[idx]\n        input_ids = [self.input_vocab[c] for c in source]\n        target_ids = [self.sos] + [self.output_vocab[c] for c in target] + [self.eos]\n        return torch.tensor(input_ids), torch.tensor(target_ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T08:35:33.459256Z","iopub.execute_input":"2025-08-11T08:35:33.459698Z","iopub.status.idle":"2025-08-11T08:35:33.465245Z","shell.execute_reply.started":"2025-08-11T08:35:33.459677Z","shell.execute_reply":"2025-08-11T08:35:33.464247Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def build_vocab(pairs):\n    input_chars = set()\n    output_chars = set()\n    for source, target in pairs:\n        input_chars.update(source)\n        output_chars.update(target)\n    input_vocab = {c: i + 1 for i, c in enumerate(sorted(input_chars))}\n    input_vocab['<pad>'] = 0\n    output_vocab = {c: i + 3 for i, c in enumerate(sorted(output_chars))}\n    output_vocab.update({'<pad>': 0, '<sos>': 1, '<eos>': 2})\n    return input_vocab, output_vocab\n\ndef load_pairs(path):\n    df = pd.read_csv(path, sep=\"\\t\", header=None, names=[\"target\", \"source\", \"count\"], dtype=str)\n    df.dropna(subset=[\"source\", \"target\"], inplace=True)\n    return list(zip(df[\"source\"], df[\"target\"]))\n\ndef collate_fn(batch):\n    inputs, targets = zip(*batch)\n    input_lens = [len(seq) for seq in inputs]\n    target_lens = [len(seq) for seq in targets]\n    inputs_padded = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n    targets_padded = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=0)\n    return inputs_padded, targets_padded, input_lens, target_lens\n\nclass Encoder(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, num_layers, cell_type, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(input_size, embed_size, padding_idx=0)\n        rnn_class = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[cell_type]\n        self.rnn = rnn_class(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n\n    def forward(self, x, lengths):\n        x = self.embedding(x)\n        packed = nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n        outputs, hidden = self.rnn(packed)\n        return hidden\n\nclass Decoder(nn.Module):\n    def __init__(self, output_size, embed_size, hidden_size, num_layers, cell_type, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(output_size, embed_size, padding_idx=0)\n        rnn_class = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[cell_type]\n        self.rnn = rnn_class(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, input_token, hidden):\n        x = self.embedding(input_token.unsqueeze(1))\n        output, hidden = self.rnn(x, hidden)\n        output = self.fc(output.squeeze(1))\n        return output, hidden\n\n    def beam_search(self, hidden, max_len, sos_idx, eos_idx, beam_size=3):\n        device = next(self.parameters()).device\n        sequences = [[torch.tensor([sos_idx], device=device), hidden, 0.0]]\n        completed = []\n\n        for _ in range(max_len):\n            new_sequences = []\n            for seq, h, score in sequences:\n                input_token = seq[-1].unsqueeze(0)\n                output, new_hidden = self.forward(input_token, h)\n                probs = torch.log_softmax(output, dim=-1).squeeze(0)\n                topk_probs, topk_indices = probs.topk(beam_size)\n                for i in range(beam_size):\n                    next_token = topk_indices[i].item()\n                    new_score = score + topk_probs[i].item()\n                    new_seq = torch.cat([seq, torch.tensor([next_token], device=device)])\n                    new_sequences.append([new_seq, new_hidden, new_score])\n            sequences = sorted(new_sequences, key=lambda x: x[2], reverse=True)[:beam_size]\n            completed.extend([seq for seq in sequences if seq[0][-1].item() == eos_idx])\n            sequences = [seq for seq in sequences if seq[0][-1].item() != eos_idx]\n            if not sequences:\n                break\n        completed = sorted(completed, key=lambda x: x[2], reverse=True)\n        return completed[0][0] if completed else sequences[0][0]\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, src, src_lens, tgt=None, teacher_forcing_ratio=0.5):\n        batch_size = src.size(0)\n        device = src.device\n        hidden = self.encoder(src, src_lens)\n        if tgt is not None:\n            tgt_len = tgt.size(1)\n            outputs = torch.zeros(batch_size, tgt_len, self.decoder.fc.out_features, device=device)\n            input_token = tgt[:, 0]\n            for t in range(1, tgt_len):\n                output, hidden = self.decoder(input_token, hidden)\n                outputs[:, t] = output\n                teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n                input_token = tgt[:, t] if teacher_force else output.argmax(1)\n            return outputs\n        else:\n            return [self.decoder.beam_search(hidden, max_len=20, sos_idx=1, eos_idx=2) for _ in range(batch_size)]\n\ndef accuracy(preds, targets, pad_idx=0):\n    pred_tokens = preds.argmax(dim=-1)\n    correct = ((pred_tokens == targets) & (targets != pad_idx)).sum().item()\n    total = (targets != pad_idx).sum().item()\n    return correct / total if total > 0 else 0.0\n\ndef train(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss, total_acc = 0, 0\n    for src, tgt, src_lens, tgt_lens in tqdm(loader, desc=\"Training\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n        optimizer.zero_grad()\n        output = model(src, src_lens, tgt)\n        loss = criterion(output[:, 1:].reshape(-1, output.size(-1)), tgt[:, 1:].reshape(-1))\n        acc = accuracy(output[:, 1:], tgt[:, 1:])\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n        total_acc += acc\n    return total_loss / len(loader), total_acc / len(loader)\n\n@torch.no_grad()\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    total_loss, total_acc = 0, 0\n    for src, tgt, src_lens, tgt_lens in tqdm(loader, desc=\"Evaluating\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n        output = model(src, src_lens, tgt, teacher_forcing_ratio=0.0)\n        loss = criterion(output[:, 1:].reshape(-1, output.size(-1)), tgt[:, 1:].reshape(-1))\n        acc = accuracy(output[:, 1:], tgt[:, 1:])\n        total_loss += loss.item()\n        total_acc += acc\n    return total_loss / len(loader), total_acc / len(loader)\n\ndef main():\n    import wandb\n    # Run name will be assigned after wandb.init with config\n    def generate_run_name(config):\n        return f\"cell:{config.cell_type}_embed:{config.embed_size}_hid:{config.hidden_size}_layers:{config.num_layers}_beam:{config.beam_size}\"\n\n    # First initialize W&B run with placeholder name\n    wandb.init(project=\"Dakshina-Translitration\", config=wandb.config)\n    config = wandb.config\n\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    train_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    dev_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\")\n\n    input_vocab, output_vocab = build_vocab(train_pairs)\n    train_dataset = TransliterationDataset(train_pairs, input_vocab, output_vocab)\n    dev_dataset = TransliterationDataset(dev_pairs, input_vocab, output_vocab)\n\n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n    dev_loader = DataLoader(dev_dataset, batch_size=config.batch_size, shuffle=False, collate_fn=collate_fn)\n\n    encoder = Encoder(len(input_vocab), config.embed_size, config.hidden_size, config.num_layers, config.cell_type, config.dropout)\n    decoder = Decoder(len(output_vocab), config.embed_size, config.hidden_size, config.num_layers, config.cell_type, config.dropout)\n    model = Seq2Seq(encoder, decoder).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    for epoch in range(10):\n        train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n        val_loss, val_acc = evaluate(model, dev_loader, criterion, device)\n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss,\n            \"train_accuracy\": train_acc,\n            \"val_loss\": val_loss,\n            \"val_accuracy\": val_acc\n        })\n\n\nif __name__ == \"__main__\":\n    sweep_config = {\n        \"method\": \"bayes\",\n        \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n        \"parameters\": {\n            \"embed_size\": {\"values\": [32, 64, 128]},\n            \"hidden_size\": {\"values\": [64, 128, 256]},\n            \"num_layers\": {\"values\": [1,2,3]},\n            \"cell_type\": {\"values\": [\"RNN\", \"GRU\", \"LSTM\"]},\n            \"dropout\": {\"values\": [0.1,0.2, 0.3]},\n            \"lr\": {\"min\": 0.0001, \"max\": 0.01},\n            \"batch_size\": {\"values\": [16,32, 64]},\n            \"beam_size\": {\"values\": [1, 3, 5]}  \n        }\n    }\n\n    sweep_id = wandb.sweep(sweep_config, project=\"Dakshina-Translitration\")\n    wandb.agent(sweep_id, function=main, count=8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T04:33:16.404401Z","iopub.execute_input":"2025-08-11T04:33:16.404902Z","iopub.status.idle":"2025-08-11T05:08:40.340731Z","shell.execute_reply.started":"2025-08-11T04:33:16.404879Z","shell.execute_reply":"2025-08-11T05:08:40.340053Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: 2tyssrla\nSweep URL: https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 17tszmhk with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001304138743761311\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_043322-17tszmhk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/17tszmhk' target=\"_blank\">grateful-sweep-1</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/17tszmhk' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/17tszmhk</a>"},"metadata":{}},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.72436</td></tr><tr><td>train_loss</td><td>0.91199</td></tr><tr><td>val_accuracy</td><td>0.61568</td></tr><tr><td>val_loss</td><td>1.33007</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">grateful-sweep-1</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/17tszmhk' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/17tszmhk</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250811_043322-17tszmhk/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kr1oziud with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.008928603235359364\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_043615-kr1oziud</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/kr1oziud' target=\"_blank\">leafy-sweep-2</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/kr1oziud' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/kr1oziud</a>"},"metadata":{}},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▃▅▁▂▅▇█▇▇▇</td></tr><tr><td>train_loss</td><td>▇▄█▇▄▂▁▁▂▂</td></tr><tr><td>val_accuracy</td><td>▆▄▁▃▆▆█▇▇▇</td></tr><tr><td>val_loss</td><td>▄▅█▆▂▂▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.61779</td></tr><tr><td>train_loss</td><td>1.23448</td></tr><tr><td>val_accuracy</td><td>0.54762</td></tr><tr><td>val_loss</td><td>1.50012</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">leafy-sweep-2</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/kr1oziud' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/kr1oziud</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250811_043615-kr1oziud/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gtm2ijqi with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.007252656727280787\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_043931-gtm2ijqi</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/gtm2ijqi' target=\"_blank\">lilac-sweep-3</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/gtm2ijqi' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/gtm2ijqi</a>"},"metadata":{}},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▄▇██▇▇▇▇▇</td></tr><tr><td>train_loss</td><td>█▄▂▁▁▂▂▂▂▂</td></tr><tr><td>val_accuracy</td><td>▁▄▅█▆▂▄▆▅▄</td></tr><tr><td>val_loss</td><td>█▄▃▁▃▅▃▄▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.28978</td></tr><tr><td>train_loss</td><td>2.71986</td></tr><tr><td>val_accuracy</td><td>0.24745</td></tr><tr><td>val_loss</td><td>2.9461</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">lilac-sweep-3</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/gtm2ijqi' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/gtm2ijqi</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250811_043931-gtm2ijqi/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ol2iohhk with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0071306615646824344\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_044217-ol2iohhk</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/ol2iohhk' target=\"_blank\">classic-sweep-4</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/ol2iohhk' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/ol2iohhk</a>"},"metadata":{}},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▆▇███████</td></tr><tr><td>train_loss</td><td>█▃▂▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▅█▇██▇▇▇</td></tr><tr><td>val_loss</td><td>█▄▃▁▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.64433</td></tr><tr><td>train_loss</td><td>1.1502</td></tr><tr><td>val_accuracy</td><td>0.56188</td></tr><tr><td>val_loss</td><td>1.4729</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">classic-sweep-4</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/ol2iohhk' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/ol2iohhk</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250811_044217-ol2iohhk/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5urv4w9d with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.005812507068956667\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_044950-5urv4w9d</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/5urv4w9d' target=\"_blank\">dauntless-sweep-5</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/5urv4w9d' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/5urv4w9d</a>"},"metadata":{}},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▆▇▇▇███</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.78461</td></tr><tr><td>train_loss</td><td>0.7041</td></tr><tr><td>val_accuracy</td><td>0.67656</td></tr><tr><td>val_loss</td><td>1.13033</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">dauntless-sweep-5</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/5urv4w9d' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/5urv4w9d</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250811_044950-5urv4w9d/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: az09bijt with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.007155022857331171\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_045533-az09bijt</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/az09bijt' target=\"_blank\">wandering-sweep-6</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/az09bijt' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/az09bijt</a>"},"metadata":{}},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▅▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇▇████</td></tr><tr><td>val_loss</td><td>█▃▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.7529</td></tr><tr><td>train_loss</td><td>0.80252</td></tr><tr><td>val_accuracy</td><td>0.68392</td></tr><tr><td>val_loss</td><td>1.10677</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">wandering-sweep-6</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/az09bijt' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/az09bijt</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250811_045533-az09bijt/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kqw98w3c with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0024613924036533076\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_045944-kqw98w3c</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/kqw98w3c' target=\"_blank\">floral-sweep-7</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/kqw98w3c' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/kqw98w3c</a>"},"metadata":{}},{"name":"stderr","text":"                                                            \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇▇▇████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇█████</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▂▂▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.84783</td></tr><tr><td>train_loss</td><td>0.49896</td></tr><tr><td>val_accuracy</td><td>0.70821</td></tr><tr><td>val_loss</td><td>1.11037</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">floral-sweep-7</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/kqw98w3c' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/kqw98w3c</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250811_045944-kqw98w3c/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fzz4hix9 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembed_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0005545456743751991\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_050306-fzz4hix9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/fzz4hix9' target=\"_blank\">frosty-sweep-8</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/sweeps/2tyssrla</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/fzz4hix9' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/fzz4hix9</a>"},"metadata":{}},{"name":"stderr","text":"                                                              \r","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.7178</td></tr><tr><td>train_loss</td><td>0.91093</td></tr><tr><td>val_accuracy</td><td>0.64961</td></tr><tr><td>val_loss</td><td>1.16323</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">frosty-sweep-8</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/fzz4hix9' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration/runs/fzz4hix9</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250811_050306-fzz4hix9/logs</code>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## Test Data","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport pandas as pd\nimport csv\n\n# ---------------- Dataset & Utils ----------------\nclass TransliterationDataset(Dataset):\n    def __init__(self, pairs, input_vocab, output_vocab):\n        self.pairs = pairs\n        self.input_vocab = input_vocab\n        self.output_vocab = output_vocab\n        self.sos = output_vocab['<sos>']\n        self.eos = output_vocab['<eos>']\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        source, target = self.pairs[idx]\n        input_ids = [self.input_vocab[c] for c in source]\n        target_ids = [self.sos] + [self.output_vocab[c] for c in target] + [self.eos]\n        return torch.tensor(input_ids), torch.tensor(target_ids)\n\ndef load_pairs(path):\n    df = pd.read_csv(path, sep='\\t', header=None, names=['target', 'source', 'count'], dtype=str)\n    df.dropna(subset=[\"source\", \"target\"], inplace=True)\n    return list(zip(df['source'], df['target']))\n\ndef build_vocab(pairs):\n    input_chars = set()\n    output_chars = set()\n    for src, tgt in pairs:\n        input_chars.update(src)\n        output_chars.update(tgt)\n    input_vocab = {c: i+1 for i, c in enumerate(sorted(input_chars))}\n    input_vocab['<pad>'] = 0\n    output_vocab = {c: i+3 for i, c in enumerate(sorted(output_chars))}\n    output_vocab.update({'<pad>': 0, '<sos>': 1, '<eos>': 2})\n    return input_vocab, output_vocab\n\ndef collate_fn(batch):\n    inputs, targets = zip(*batch)\n    input_lens = [len(x) for x in inputs]\n    target_lens = [len(x) for x in targets]\n    inputs_padded = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n    targets_padded = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=0)\n    return inputs_padded, targets_padded, input_lens, target_lens\n\n# ---------------- Models ----------------\nclass Encoder(nn.Module):\n    def __init__(self, input_size, embed_size, hidden_size, num_layers, cell_type, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(input_size, embed_size, padding_idx=0)\n        rnn_cls = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[cell_type]\n        self.rnn = rnn_cls(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n\n    def forward(self, x, lengths):\n        embedded = self.embedding(x)\n        packed = nn.utils.rnn.pack_padded_sequence(embedded, lengths, batch_first=True, enforce_sorted=False)\n        outputs, hidden = self.rnn(packed)\n        return hidden\n\nclass Decoder(nn.Module):\n    def __init__(self, output_size, embed_size, hidden_size, num_layers, cell_type, dropout):\n        super().__init__()\n        self.embedding = nn.Embedding(output_size, embed_size, padding_idx=0)\n        rnn_cls = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[cell_type]\n        self.rnn = rnn_cls(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, token, hidden):\n        x = self.embedding(token.unsqueeze(1))\n        output, hidden = self.rnn(x, hidden)\n        output = self.fc(output.squeeze(1))\n        return output, hidden\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, src, src_lens, tgt=None, teacher_forcing_ratio=0.5):\n        batch_size = src.size(0)\n        hidden = self.encoder(src, src_lens)\n        tgt_len = tgt.size(1)\n        outputs = torch.zeros(batch_size, tgt_len, self.decoder.fc.out_features).to(src.device)\n        input_token = tgt[:, 0]\n        for t in range(1, tgt_len):\n            output, hidden = self.decoder(input_token, hidden)\n            outputs[:, t] = output\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            input_token = tgt[:, t] if teacher_force else output.argmax(1)\n        return outputs\n\n# ---------------- Train + Eval ----------------\ndef train_model(model, dataloader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    for src, tgt, src_lens, _ in dataloader:\n        src, tgt = src.to(device), tgt.to(device)\n        optimizer.zero_grad()\n        output = model(src, src_lens, tgt)\n        loss = criterion(output[:, 1:].reshape(-1, output.shape[-1]), tgt[:, 1:].reshape(-1))\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(dataloader)\n\ndef evaluate_and_save(model, dataloader, input_vocab, output_vocab, device, csv_path=None):\n    model.eval()\n    inv_input_vocab = {v: k for k, v in input_vocab.items()}\n    inv_output_vocab = {v: k for k, v in output_vocab.items()}\n    correct = 0\n    total = 0\n    results = []\n\n    with torch.no_grad():\n        for src, tgt, src_lens, _ in dataloader:\n            src = src.to(device)\n            hidden = model.encoder(src, src_lens)\n            input_token = torch.tensor([output_vocab['<sos>']] * src.size(0)).to(device)\n            decoded = []\n            for _ in range(20):\n                output, hidden = model.decoder(input_token, hidden)\n                input_token = output.argmax(1)\n                decoded.append(input_token)\n            decoded = torch.stack(decoded, dim=1)\n\n            for i in range(src.size(0)):\n                pred = ''.join([inv_output_vocab[t.item()] for t in decoded[i] if t.item() not in [output_vocab['<eos>'], 0]])\n                truth = ''.join([inv_output_vocab[t.item()] for t in tgt[i][1:-1]])\n                inp = ''.join([inv_input_vocab[t.item()] for t in src[i] if t.item() != 0])\n                results.append((inp, pred, truth))\n                if pred == truth:\n                    correct += 1\n                total += 1\n\n    acc = correct / total * 100\n    print(f\"\\n Test Accuracy: {acc:.2f}%\")\n    for inp, pred, truth in results[:10]:\n        print(f\"{inp:<15} | Pred: {pred:<20} | Truth: {truth}\")\n\n    if csv_path is not None:\n        with open(csv_path, mode='w', newline='', encoding='utf-8') as f:\n            writer = csv.writer(f)\n            writer.writerow(['Input', 'Prediction', 'GroundTruth'])\n            writer.writerows(results)\n        print(f\"\\n Predictions saved to: {csv_path}\")\n\n    return acc, results\n\n\n# ---------------- Run ----------------\nif __name__ == \"__main__\":\n    config = {\n        \"embed_size\": 128,\n        \"hidden_size\": 256,\n        \"num_layers\": 2,\n        \"cell_type\": \"LSTM\",\n        \"dropout\": 0.3,\n        \"batch_size\": 64,\n        \"lr\": 0.002461,\n        \"epochs\": 10,\n    }\n\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    train_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    test_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\")\n    input_vocab, output_vocab = build_vocab(train_pairs)\n    train_dataset = TransliterationDataset(train_pairs, input_vocab, output_vocab)\n    test_dataset = TransliterationDataset(test_pairs, input_vocab, output_vocab)\n\n    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, collate_fn=collate_fn)\n    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n\n    encoder = Encoder(len(input_vocab), config[\"embed_size\"], config[\"hidden_size\"],\n                      config[\"num_layers\"], config[\"cell_type\"], config[\"dropout\"])\n    decoder = Decoder(len(output_vocab), config[\"embed_size\"], config[\"hidden_size\"],\n                      config[\"num_layers\"], config[\"cell_type\"], config[\"dropout\"])\n    model = Seq2Seq(encoder, decoder).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    best_acc = 0\n    for epoch in range(config[\"epochs\"]):\n        train_loss = train_model(model, train_loader, optimizer, criterion, device)\n        print(f\"Epoch {epoch+1} Train Loss: {train_loss:.4f}\")\n        acc, results = evaluate_and_save(model, test_loader, input_vocab, output_vocab, device, csv_path=None)\n        if acc > best_acc:\n            best_acc = acc\n            torch.save(model.state_dict(), \"best_model.pth\")\n\n    print(\"\\n Loading best model for final evaluation...\")\n    model.load_state_dict(torch.load(\"best_model.pth\"))\n\n    # Save predictions CSV here\n    evaluate_and_save(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T05:32:36.917745Z","iopub.execute_input":"2025-08-11T05:32:36.918011Z","iopub.status.idle":"2025-08-11T05:42:12.175105Z","shell.execute_reply.started":"2025-08-11T05:32:36.917991Z","shell.execute_reply":"2025-08-11T05:42:12.174500Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 Train Loss: 1.4576\n\n Test Accuracy: 23.01%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनाकों               | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगोकर               | Truth: अंकोर\nankor           | Pred: अंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगररक               | Truth: अंगारक\nEpoch 2 Train Loss: 0.7836\n\n Test Accuracy: 30.90%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अनकित                | Truth: अंकित\nanakon          | Pred: अनकों                | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगकर                | Truth: अंकोर\nankor           | Pred: अंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\nEpoch 3 Train Loss: 0.6317\n\n Test Accuracy: 33.96%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनाकों               | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगकोर               | Truth: अंकोर\nankor           | Pred: अंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\nEpoch 4 Train Loss: 0.5581\n\n Test Accuracy: 34.18%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनाकों               | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगकोर               | Truth: अंकोर\nankor           | Pred: अंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगराक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\nEpoch 5 Train Loss: 0.4979\n\n Test Accuracy: 33.14%\nank             | Pred: एंक                  | Truth: अंक\nanka            | Pred: आंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: आनाकों               | Truth: अंकों\nankhon          | Pred: आंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगकोर               | Truth: अंकोर\nankor           | Pred: एंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\nEpoch 6 Train Loss: 0.4555\n\n Test Accuracy: 34.34%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनाकों               | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अंकों                | Truth: अंकों\nangkor          | Pred: अंगकर                | Truth: अंकोर\nankor           | Pred: अंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगररक               | Truth: अंगारक\nEpoch 7 Train Loss: 0.4243\n\n Test Accuracy: 35.03%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अनकीत                | Truth: अंकित\nanakon          | Pred: अनकों                | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अनकों                | Truth: अंकों\nangkor          | Pred: अंगकर                | Truth: अंकोर\nankor           | Pred: एंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अगराा                | Truth: अंगारक\nEpoch 8 Train Loss: 0.3942\n\n Test Accuracy: 34.61%\nank             | Pred: एंक                  | Truth: अंक\nanka            | Pred: आंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: आनकों                | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: आंकों                | Truth: अंकों\nangkor          | Pred: अंगकर                | Truth: अंकोर\nankor           | Pred: अंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगरक                | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\nEpoch 9 Train Loss: 0.3695\n\n Test Accuracy: 34.56%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: आंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनकों                | Truth: अंकों\nankhon          | Pred: आंखों                | Truth: अंकों\nankon           | Pred: आंकों                | Truth: अंकों\nangkor          | Pred: अंगकर                | Truth: अंकोर\nankor           | Pred: अंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगराक               | Truth: अंगारक\nangarak         | Pred: अंगरक                | Truth: अंगारक\nEpoch 10 Train Loss: 0.3575\n\n Test Accuracy: 34.45%\nank             | Pred: एंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अंकित                | Truth: अंकित\nanakon          | Pred: अनाकोंं              | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: एनकों                | Truth: अंकों\nangkor          | Pred: एंगकरर               | Truth: अंकोर\nankor           | Pred: एंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अंगराक               | Truth: अंगारक\n\n Loading best model for final evaluation...\n\n Test Accuracy: 35.03%\nank             | Pred: अंक                  | Truth: अंक\nanka            | Pred: अंका                 | Truth: अंक\nankit           | Pred: अनकीत                | Truth: अंकित\nanakon          | Pred: अनकों                | Truth: अंकों\nankhon          | Pred: अंखों                | Truth: अंकों\nankon           | Pred: अनकों                | Truth: अंकों\nangkor          | Pred: अंगकर                | Truth: अंकोर\nankor           | Pred: एंकोर                | Truth: अंकोर\nangaarak        | Pred: अंगारक               | Truth: अंगारक\nangarak         | Pred: अगराा                | Truth: अंगारक\n\n Predictions saved to: test_predictions.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"___\n___","metadata":{}},{"cell_type":"markdown","source":"#  **$$Transformer-Model$$**","metadata":{}},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T07:00:40.779755Z","iopub.execute_input":"2025-08-11T07:00:40.780023Z","iopub.status.idle":"2025-08-11T07:00:40.787501Z","shell.execute_reply.started":"2025-08-11T07:00:40.779999Z","shell.execute_reply":"2025-08-11T07:00:40.786776Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport wandb\nfrom tqdm import tqdm\nimport math\nimport csv\nfrom collections import namedtuple","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T06:58:22.067875Z","iopub.execute_input":"2025-08-11T06:58:22.068119Z","iopub.status.idle":"2025-08-11T06:58:26.842157Z","shell.execute_reply.started":"2025-08-11T06:58:22.068102Z","shell.execute_reply":"2025-08-11T06:58:26.841408Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport wandb\nfrom tqdm import tqdm\nimport math\nimport csv\nfrom collections import namedtuple\n\n# ---------------- Data Processing and Utilities ----------------\n\nclass TransliterationDataset(Dataset):\n    def __init__(self, pairs, input_vocab, output_vocab):\n        self.pairs = pairs\n        self.input_vocab = input_vocab\n        self.output_vocab = output_vocab\n        self.sos = output_vocab['<sos>']\n        self.eos = output_vocab['<eos>']\n        # Robustly get unk indices, with fallbacks\n        self.unk_in = input_vocab.get('<unk>', 1) \n        self.unk_out = output_vocab.get('<unk>', 3)\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        source, target = self.pairs[idx]\n        # Use .get() with unk_in/unk_out for handling unseen characters\n        input_ids = [self.input_vocab.get(c, self.unk_in) for c in source]\n        target_ids = [self.sos] + [self.output_vocab.get(c, self.unk_out) for c in target] + [self.eos]\n        return torch.tensor(input_ids), torch.tensor(target_ids)\n\ndef build_vocab(pairs):\n    input_chars = set()\n    output_chars = set()\n    for src, tgt in pairs:\n        input_chars.update(src)\n        output_chars.update(tgt)\n    \n    # Vocab indexing: <pad>:0, <unk>:1, then sorted chars\n    input_vocab = {c: i + 2 for i, c in enumerate(sorted(input_chars))}\n    input_vocab['<pad>'] = 0\n    input_vocab['<unk>'] = 1\n    \n    # Vocab indexing: <pad>:0, <sos>:1, <eos>:2, <unk>:3, then sorted chars\n    output_vocab = {c: i + 4 for i, c in enumerate(sorted(output_chars))}\n    output_vocab.update({'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3})\n    \n    return input_vocab, output_vocab\n\ndef load_pairs(path):\n    # Ensure the path is correct for your environment (e.g., Kaggle, local, Colab)\n    # Common issue: FileNotFoundError if path is wrong.\n    df = pd.read_csv(path, sep='\\t', header=None, names=['target', 'source', 'count'], dtype=str)\n    df.dropna(subset=[\"source\", \"target\"], inplace=True)\n    return list(zip(df['source'], df['target']))\n\ndef collate_fn(batch):\n    inputs, targets = zip(*batch)\n    inputs_padded = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n    targets_padded = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=0)\n    return inputs_padded, targets_padded\n\n# ---------------- Transformer Specific Components ----------------\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout, max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0) # Add batch dimension\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        # Add positional encoding to input embeddings\n        x = x + self.pe[:, :x.size(1), :]\n        return self.dropout(x)\n\nclass TransformerModel(nn.Module):\n    def __init__(self, input_vocab_size, output_vocab_size, d_model, nhead, num_encoder_layers,\n                 num_decoder_layers, dim_feedforward, dropout):\n        super().__init__()\n        \n        self.d_model = d_model\n        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model, padding_idx=0)\n        self.decoder_embedding = nn.Embedding(output_vocab_size, d_model, padding_idx=0)\n        self.positional_encoding = PositionalEncoding(d_model, dropout)\n        \n        self.transformer = nn.Transformer(\n            d_model=d_model,\n            nhead=nhead,\n            num_encoder_layers=num_encoder_layers,\n            num_decoder_layers=num_decoder_layers,\n            dim_feedforward=dim_feedforward,\n            dropout=dropout,\n            batch_first=True # Important: Use batch_first for convenience\n        )\n        \n        self.fc_out = nn.Linear(d_model, output_vocab_size)\n        self.output_vocab_size = output_vocab_size\n        self.sos_idx = 1\n        self.eos_idx = 2\n\n    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_padding_mask=None, tgt_padding_mask=None):\n        # Embed and add positional encoding\n        src_embedded = self.positional_encoding(self.encoder_embedding(src) * math.sqrt(self.d_model))\n        tgt_embedded = self.positional_encoding(self.decoder_embedding(tgt) * math.sqrt(self.d_model))\n        \n        # Pass through Transformer layers\n        transformer_out = self.transformer(\n            src_embedded, tgt_embedded,\n            src_mask=src_mask,\n            tgt_mask=tgt_mask,\n            src_key_padding_mask=src_padding_mask,\n            tgt_key_padding_mask=tgt_padding_mask\n        )\n        \n        # Linear layer to get vocabulary logits\n        output = self.fc_out(transformer_out)\n        return output\n\n    def generate_square_subsequent_mask(self, sz):\n        # Generates a mask to prevent attention to future tokens in the decoder\n        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n        return mask\n\n    def create_padding_mask(self, seq, pad_idx=0):\n        # Generates a boolean mask for padding tokens\n        return (seq == pad_idx)\n\n# ---------------- Training and Evaluation Functions ----------------\n\ndef accuracy(preds, targets, pad_idx=0):\n    # Calculates character-level accuracy, ignoring padding\n    pred_tokens = preds.argmax(dim=-1)\n    correct = ((pred_tokens == targets) & (targets != pad_idx)).sum().item()\n    total = (targets != pad_idx).sum().item()\n    return correct / total if total > 0 else 0.0\n\n@torch.no_grad()\ndef evaluate_word_accuracy(model, dataloader, device, output_vocab):\n    model.eval()\n    correct_words = 0\n    total_words = 0\n    inv_output_vocab = {v: k for k, v in output_vocab.items()}\n    \n    for src, tgt in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n\n        src_padding_mask = model.create_padding_mask(src).to(device)\n        batch_size = src.size(0)\n        max_len = 20 # Max length for generated output (could be dynamically set based on input length if needed)\n        \n        # Initialize decoder input with <sos> tokens for greedy decoding\n        generated_tokens = torch.full((batch_size, 1), model.sos_idx, dtype=torch.long, device=device)\n        \n        for t in range(max_len):\n            # Create masks for the current generated sequence length\n            tgt_mask = model.generate_square_subsequent_mask(generated_tokens.size(1)).to(device)\n            tgt_padding_mask = model.create_padding_mask(generated_tokens).to(device)\n            \n            # Forward pass to get next token predictions\n            output = model(src, generated_tokens, src_padding_mask=src_padding_mask, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n            \n            # Get the token with the highest probability\n            next_token = output[:, -1, :].argmax(dim=-1).unsqueeze(1)\n            \n            # Append the predicted token to the generated sequence\n            generated_tokens = torch.cat([generated_tokens, next_token], dim=1)\n            \n            # Stop if all sequences in the batch have generated the <eos> token\n            if (next_token == model.eos_idx).all():\n                break\n\n        # Calculate word-level accuracy\n        for i in range(batch_size):\n            pred_seq = generated_tokens[i]\n            target_seq = tgt[i]\n            \n            # Find the first <eos> token to trim the sequence (excluding <sos> and <eos> itself)\n            pred_end = (pred_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n            target_end = (target_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n            \n            # Extract the actual word tokens, excluding <sos> and <eos>\n            pred_word = pred_seq[1:pred_end[0] if pred_end.numel() > 0 else len(pred_seq)]\n            target_word = target_seq[1:target_end[0] if target_end.numel() > 0 else len(target_seq)]\n\n            if torch.equal(pred_word, target_word):\n                correct_words += 1\n            total_words += 1\n            \n    return correct_words / total_words if total_words > 0 else 0.0\n\ndef train_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss, total_char_acc = 0, 0\n    for src, tgt in tqdm(loader, desc=\"Training\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n\n        optimizer.zero_grad()\n        \n        src_padding_mask = model.create_padding_mask(src).to(device)\n        \n        tgt_input = tgt[:, :-1] # Input for decoder, excludes the last token\n        tgt_output = tgt[:, 1:]  # Target for loss, excludes the first token (<sos>)\n\n        # ************ CRITICAL FIX ************\n        # Create tgt_padding_mask from tgt_input to match its length\n        tgt_padding_mask = model.create_padding_mask(tgt_input).to(device)\n       \n        \n        tgt_mask = model.generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n        \n        output = model(src, tgt_input, src_padding_mask=src_padding_mask, tgt_padding_mask=tgt_padding_mask, tgt_mask=tgt_mask)\n        \n        # Reshape output and target for CrossEntropyLoss\n        loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n        char_acc = accuracy(output, tgt_output) # Character-level accuracy\n        \n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        total_char_acc += char_acc\n        \n    return total_loss / len(loader), total_char_acc / len(loader)\n\ndef generate_predictions_csv(model, dataloader, input_vocab, output_vocab, device, csv_path):\n    model.eval()\n    inv_input_vocab = {v: k for k, v in input_vocab.items()}\n    inv_output_vocab = {v: k for k, v in output_vocab.items()}\n    results = []\n\n    with torch.no_grad():\n        for src, tgt in tqdm(dataloader, desc=\"Generating Test Predictions\"):\n            src = src.to(device)\n            batch_size = src.size(0)\n            max_len = 20 # Max length for generated output\n\n            # Inference loop for the decoder (similar to evaluate_word_accuracy)\n            generated_tokens = torch.full((batch_size, 1), model.sos_idx, dtype=torch.long, device=device)\n            \n            for t in range(max_len):\n                tgt_mask = model.generate_square_subsequent_mask(generated_tokens.size(1)).to(device)\n                tgt_padding_mask = model.create_padding_mask(generated_tokens).to(device)\n                \n                output = model(src, generated_tokens, src_padding_mask=src_padding_mask, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n                \n                next_token = output[:, -1, :].argmax(dim=-1).unsqueeze(1)\n                generated_tokens = torch.cat([generated_tokens, next_token], dim=1)\n                \n                if (next_token == model.eos_idx).all():\n                    break\n\n            for i in range(batch_size):\n                pred_seq = generated_tokens[i]\n                target_seq = tgt[i]\n                \n                pred_end = (pred_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n                target_end = (target_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n                \n                pred_word_tokens = pred_seq[1:pred_end[0] if pred_end.numel() > 0 else len(pred_seq)]\n                # Ensure truth_word_tokens also excludes any potential padding if it's shorter than predicted length\n                truth_word_tokens = target_seq[1:target_end[0] if target_end.numel() > 0 else len(target_seq)]\n\n                pred_str = ''.join([inv_output_vocab[t.item()] for t in pred_word_tokens if t.item() not in [model.sos_idx, model.eos_idx, 0]])\n                truth_str = ''.join([inv_output_vocab[t.item()] for t in truth_word_tokens if t.item() not in [model.sos_idx, model.eos_idx, 0]])\n                inp_str = ''.join([inv_input_vocab[t.item()] for t in src[i] if t.item() != 0])\n                results.append((inp_str, pred_str, truth_str))\n    \n    with open(csv_path, mode='w', newline='', encoding='utf-8') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Input', 'Prediction', 'GroundTruth'])\n        writer.writerows(results)\n    print(f\"\\nPredictions saved to: {csv_path}\")\n\n# ---------------- Main Function for W&B Sweep ----------------\n\ndef main():\n    import wandb\n    \n    def generate_run_name(config):\n        return f\"transformer_d:{config.d_model}_nhead:{config.nhead}_layers:{config.num_encoder_layers}\"\n\n    wandb.init(project=\"Dakshina-Translitration-Transformer\", config=wandb.config)\n    config = wandb.config\n    wandb.run.name = generate_run_name(config)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    train_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    dev_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\")\n    test_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\")\n    # *******************************************************************\n\n    # Build vocab on train + dev pairs for consistency\n    input_vocab, output_vocab = build_vocab(train_pairs + dev_pairs)\n    train_dataset = TransliterationDataset(train_pairs, input_vocab, output_vocab)\n    dev_dataset = TransliterationDataset(dev_pairs, input_vocab, output_vocab)\n    test_dataset = TransliterationDataset(test_pairs, input_vocab, output_vocab) # Prepare test dataset here\n\n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n    dev_loader = DataLoader(dev_dataset, batch_size=config.batch_size, shuffle=False, collate_fn=collate_fn)\n    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn) # Batch size 1 for individual prediction\n\n    model = TransformerModel(\n        input_vocab_size=len(input_vocab),\n        output_vocab_size=len(output_vocab),\n        d_model=config.d_model,\n        nhead=config.nhead,\n        num_encoder_layers=config.num_encoder_layers,\n        num_decoder_layers=config.num_decoder_layers,\n        dim_feedforward=config.dim_feedforward,\n        dropout=config.dropout\n    ).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, betas=(0.9, 0.98), eps=1e-9)\n    criterion = nn.CrossEntropyLoss(ignore_index=0) # ignore_index=0 for <pad> token\n\n    best_dev_acc = 0\n    # Training loop\n    for epoch in range(10): -\n        train_loss, train_char_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n        dev_word_acc = evaluate_word_accuracy(model, dev_loader, device, output_vocab)\n        \n        print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Train Char Acc: {train_char_acc:.4f} | Dev Word Acc: {dev_word_acc:.4f}\")\n        \n        if dev_word_acc > best_dev_acc:\n            best_dev_acc = dev_word_acc\n            torch.save(model.state_dict(), 'best_transformer_model.pth')\n            print(f\" -> New best model saved with dev word accuracy: {best_dev_acc:.4f}\")\n\n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss,\n            \"train_char_accuracy\": train_char_acc,\n            \"dev_word_accuracy\": dev_word_acc\n        })\n\n    print(\"\\nTraining complete. Loading best model for final evaluation on test set...\")\n    # Load the best model found during training\n    try:\n        model.load_state_dict(torch.load('best_transformer_model.pth'))\n    except FileNotFoundError:\n        print(\"Error: 'best_transformer_model.pth' not found. Ensure training completed successfully and model was saved.\")\n        return # Exit main if model not found\n\n    # Final evaluation on the test set (using the best saved model)\n    final_test_word_acc = evaluate_word_accuracy(model, test_loader, device, output_vocab)\n    print(f\"\\n--- Final Test Set Evaluation Results ---\")\n    print(f\"Word-level Accuracy on Test Set: {final_test_word_acc:.4f}\")\n    \n    # Generate and save predictions to CSV using the best model\n    generate_predictions_csv(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")\n    print(\"Test predictions saved to test_predictions.csv\")\n\n\nif __name__ == \"__main__\":\n    # Define your W&B sweep configuration\n    sweep_config = {\n        \"method\": \"bayes\", # Bayesian optimization\n        \"metric\": {\"name\": \"dev_word_accuracy\", \"goal\": \"maximize\"},\n        \"parameters\": {\n            \"d_model\": {\"values\": [128, 256, 512]},\n            \"nhead\": {\"values\": [4, 8, 16]},\n            \"num_encoder_layers\": {\"values\": [2, 4]},\n            \"num_decoder_layers\": {\"values\": [2, 4]},\n            \"dim_feedforward\": {\"values\": [512, 1024, 2048]},\n            \"dropout\": {\"values\": [0.1, 0.2, 0.3]},\n            \"lr\": {\"min\": 0.0001, \"max\": 0.001},\n            \"batch_size\": {\"values\": [16, 32, 64]}\n        }\n    }\n    \n    # Initialize and run the W&B agent\n    sweep_id = wandb.sweep(sweep_config, project=\"Dakshina-Translitration-Transformer\")\n    wandb.agent(sweep_id, function=main, count=5) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T08:36:08.871755Z","iopub.execute_input":"2025-08-11T08:36:08.872040Z","iopub.status.idle":"2025-08-11T09:54:05.114951Z","shell.execute_reply.started":"2025-08-11T08:36:08.872018Z","shell.execute_reply":"2025-08-11T09:54:05.114407Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: 3x0zlqsl\nSweep URL: https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5vnrk5u5 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0006418468204446201\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_083633-5vnrk5u5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/5vnrk5u5' target=\"_blank\">radiant-sweep-1</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/5vnrk5u5' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/5vnrk5u5</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/2763 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nEvaluating:   0%|          | 0/273 [00:00<?, ?it/s]          /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n  output = torch._nested_tensor_from_mask(\n                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 1.9561 | Train Char Acc: 0.4013 | Dev Word Acc: 0.0083\n -> New best model saved with dev word accuracy: 0.0083\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.5652 | Train Char Acc: 0.4881 | Dev Word Acc: 0.0133\n -> New best model saved with dev word accuracy: 0.0133\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.4650 | Train Char Acc: 0.5164 | Dev Word Acc: 0.0135\n -> New best model saved with dev word accuracy: 0.0135\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.4066 | Train Char Acc: 0.5319 | Dev Word Acc: 0.0174\n -> New best model saved with dev word accuracy: 0.0174\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 1.3683 | Train Char Acc: 0.5441 | Dev Word Acc: 0.0195\n -> New best model saved with dev word accuracy: 0.0195\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 1.3418 | Train Char Acc: 0.5523 | Dev Word Acc: 0.0186\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 1.3187 | Train Char Acc: 0.5576 | Dev Word Acc: 0.0202\n -> New best model saved with dev word accuracy: 0.0202\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 1.3004 | Train Char Acc: 0.5644 | Dev Word Acc: 0.0243\n -> New best model saved with dev word accuracy: 0.0243\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train Loss: 1.2874 | Train Char Acc: 0.5682 | Dev Word Acc: 0.0243\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 1.2714 | Train Char Acc: 0.5736 | Dev Word Acc: 0.0172\n\nTraining complete. Loading best model for final evaluation on test set...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n--- Final Test Set Evaluation Results ---\nWord-level Accuracy on Test Set: 0.0293\n","output_type":"stream"},{"name":"stderr","text":"Generating Test Predictions:   0%|          | 0/4502 [00:00<?, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>▁▃▃▅▆▅▆██▅</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▅▆▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>0.01721</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>train_char_accuracy</td><td>0.57364</td></tr><tr><td>train_loss</td><td>1.27137</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">transformer_d:128_nhead:4_layers:4</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/5vnrk5u5' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/5vnrk5u5</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250811_083633-5vnrk5u5/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 5vnrk5u5 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_56/1848154019.py\", line 361, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     generate_predictions_csv(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_56/1848154019.py\", line 254, in generate_predictions_csv\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = model(src, generated_tokens, src_padding_mask=src_padding_mask, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                                            ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m NameError: name 'src_padding_mask' is not defined\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 56pt3olf with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 2048\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0009524657717494196\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_085436-56pt3olf</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/56pt3olf' target=\"_blank\">spring-sweep-2</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/56pt3olf' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/56pt3olf</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/691 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 2.4921 | Train Char Acc: 0.2538 | Dev Word Acc: 0.0002\n -> New best model saved with dev word accuracy: 0.0002\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.9518 | Train Char Acc: 0.3652 | Dev Word Acc: 0.0014\n -> New best model saved with dev word accuracy: 0.0014\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.7862 | Train Char Acc: 0.4170 | Dev Word Acc: 0.0055\n -> New best model saved with dev word accuracy: 0.0055\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.6590 | Train Char Acc: 0.4572 | Dev Word Acc: 0.0032\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 1.5579 | Train Char Acc: 0.4885 | Dev Word Acc: 0.0044\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 1.4941 | Train Char Acc: 0.5073 | Dev Word Acc: 0.0062\n -> New best model saved with dev word accuracy: 0.0062\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 1.4401 | Train Char Acc: 0.5241 | Dev Word Acc: 0.0078\n -> New best model saved with dev word accuracy: 0.0078\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 1.4008 | Train Char Acc: 0.5364 | Dev Word Acc: 0.0087\n -> New best model saved with dev word accuracy: 0.0087\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train Loss: 1.3695 | Train Char Acc: 0.5451 | Dev Word Acc: 0.0099\n -> New best model saved with dev word accuracy: 0.0099\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 1.3366 | Train Char Acc: 0.5561 | Dev Word Acc: 0.0060\n\nTraining complete. Loading best model for final evaluation on test set...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n--- Final Test Set Evaluation Results ---\nWord-level Accuracy on Test Set: 0.0078\n","output_type":"stream"},{"name":"stderr","text":"Generating Test Predictions:   0%|          | 0/4502 [00:00<?, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>▁▂▅▃▄▅▇▇█▅</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▄▅▆▆▇▇███</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>0.00597</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>train_char_accuracy</td><td>0.55605</td></tr><tr><td>train_loss</td><td>1.33656</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">transformer_d:256_nhead:8_layers:2</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/56pt3olf' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/56pt3olf</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250811_085436-56pt3olf/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 56pt3olf errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_56/1848154019.py\", line 361, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     generate_predictions_csv(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_56/1848154019.py\", line 254, in generate_predictions_csv\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = model(src, generated_tokens, src_padding_mask=src_padding_mask, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                                            ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m NameError: name 'src_padding_mask' is not defined\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rnzdibxb with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0003177450107690548\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_090535-rnzdibxb</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/rnzdibxb' target=\"_blank\">misunderstood-sweep-3</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/rnzdibxb' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/rnzdibxb</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/1382 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 1.6366 | Train Char Acc: 0.4832 | Dev Word Acc: 0.0076\n -> New best model saved with dev word accuracy: 0.0076\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.2648 | Train Char Acc: 0.5743 | Dev Word Acc: 0.0101\n -> New best model saved with dev word accuracy: 0.0101\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.1536 | Train Char Acc: 0.6090 | Dev Word Acc: 0.0154\n -> New best model saved with dev word accuracy: 0.0154\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.0744 | Train Char Acc: 0.6347 | Dev Word Acc: 0.0156\n -> New best model saved with dev word accuracy: 0.0156\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 1.0096 | Train Char Acc: 0.6555 | Dev Word Acc: 0.0193\n -> New best model saved with dev word accuracy: 0.0193\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 0.9556 | Train Char Acc: 0.6742 | Dev Word Acc: 0.0278\n -> New best model saved with dev word accuracy: 0.0278\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 0.9077 | Train Char Acc: 0.6910 | Dev Word Acc: 0.0248\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 0.8675 | Train Char Acc: 0.7042 | Dev Word Acc: 0.0321\n -> New best model saved with dev word accuracy: 0.0321\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train Loss: 0.8348 | Train Char Acc: 0.7148 | Dev Word Acc: 0.0365\n -> New best model saved with dev word accuracy: 0.0365\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 0.8006 | Train Char Acc: 0.7263 | Dev Word Acc: 0.0328\n\nTraining complete. Loading best model for final evaluation on test set...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n--- Final Test Set Evaluation Results ---\nWord-level Accuracy on Test Set: 0.0271\n","output_type":"stream"},{"name":"stderr","text":"Generating Test Predictions:   0%|          | 0/4502 [00:00<?, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>▁▂▃▃▄▆▅▇█▇</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▄▅▅▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>0.03281</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>train_char_accuracy</td><td>0.72634</td></tr><tr><td>train_loss</td><td>0.80065</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">transformer_d:256_nhead:16_layers:4</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/rnzdibxb' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/rnzdibxb</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250811_090535-rnzdibxb/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run rnzdibxb errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_56/1848154019.py\", line 361, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     generate_predictions_csv(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_56/1848154019.py\", line 254, in generate_predictions_csv\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = model(src, generated_tokens, src_padding_mask=src_padding_mask, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                                            ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m NameError: name 'src_padding_mask' is not defined\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fm9x0atm with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0006555628286508731\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_091728-fm9x0atm</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/fm9x0atm' target=\"_blank\">balmy-sweep-4</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/fm9x0atm' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/fm9x0atm</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/2763 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 1.6696 | Train Char Acc: 0.4764 | Dev Word Acc: 0.0092\n -> New best model saved with dev word accuracy: 0.0092\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.2850 | Train Char Acc: 0.5752 | Dev Word Acc: 0.0218\n -> New best model saved with dev word accuracy: 0.0218\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.1436 | Train Char Acc: 0.6209 | Dev Word Acc: 0.0301\n -> New best model saved with dev word accuracy: 0.0301\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.0230 | Train Char Acc: 0.6599 | Dev Word Acc: 0.0468\n -> New best model saved with dev word accuracy: 0.0468\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 0.9055 | Train Char Acc: 0.6980 | Dev Word Acc: 0.0863\n -> New best model saved with dev word accuracy: 0.0863\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 0.8051 | Train Char Acc: 0.7310 | Dev Word Acc: 0.0950\n -> New best model saved with dev word accuracy: 0.0950\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 0.7260 | Train Char Acc: 0.7573 | Dev Word Acc: 0.1065\n -> New best model saved with dev word accuracy: 0.1065\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 0.6621 | Train Char Acc: 0.7771 | Dev Word Acc: 0.1487\n -> New best model saved with dev word accuracy: 0.1487\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train Loss: 0.6129 | Train Char Acc: 0.7949 | Dev Word Acc: 0.1333\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 0.5739 | Train Char Acc: 0.8080 | Dev Word Acc: 0.1592\n -> New best model saved with dev word accuracy: 0.1592\n\nTraining complete. Loading best model for final evaluation on test set...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n--- Final Test Set Evaluation Results ---\nWord-level Accuracy on Test Set: 0.1357\n","output_type":"stream"},{"name":"stderr","text":"Generating Test Predictions:   0%|          | 0/4502 [00:00<?, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>▁▂▂▃▅▅▆█▇█</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▃▄▅▆▆▇▇██</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>0.15925</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>train_char_accuracy</td><td>0.80795</td></tr><tr><td>train_loss</td><td>0.57392</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">transformer_d:128_nhead:4_layers:2</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/fm9x0atm' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/fm9x0atm</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250811_091728-fm9x0atm/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run fm9x0atm errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_56/1848154019.py\", line 361, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     generate_predictions_csv(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_56/1848154019.py\", line 254, in generate_predictions_csv\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = model(src, generated_tokens, src_padding_mask=src_padding_mask, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                                            ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m NameError: name 'src_padding_mask' is not defined\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c2zi2lbu with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0005931888340613948\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_093811-c2zi2lbu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/c2zi2lbu' target=\"_blank\">autumn-sweep-5</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/3x0zlqsl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/c2zi2lbu' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/c2zi2lbu</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/1382 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 2.2757 | Train Char Acc: 0.3377 | Dev Word Acc: 0.0009\n -> New best model saved with dev word accuracy: 0.0009\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.6777 | Train Char Acc: 0.4626 | Dev Word Acc: 0.0025\n -> New best model saved with dev word accuracy: 0.0025\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.5013 | Train Char Acc: 0.5086 | Dev Word Acc: 0.0037\n -> New best model saved with dev word accuracy: 0.0037\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.4154 | Train Char Acc: 0.5313 | Dev Word Acc: 0.0046\n -> New best model saved with dev word accuracy: 0.0046\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 1.3549 | Train Char Acc: 0.5491 | Dev Word Acc: 0.0050\n -> New best model saved with dev word accuracy: 0.0050\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 1.3092 | Train Char Acc: 0.5622 | Dev Word Acc: 0.0034\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 1.2727 | Train Char Acc: 0.5721 | Dev Word Acc: 0.0053\n -> New best model saved with dev word accuracy: 0.0053\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 1.2431 | Train Char Acc: 0.5833 | Dev Word Acc: 0.0032\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9 | Train Loss: 1.2183 | Train Char Acc: 0.5903 | Dev Word Acc: 0.0071\n -> New best model saved with dev word accuracy: 0.0071\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10 | Train Loss: 1.1971 | Train Char Acc: 0.5961 | Dev Word Acc: 0.0071\n\nTraining complete. Loading best model for final evaluation on test set...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n--- Final Test Set Evaluation Results ---\nWord-level Accuracy on Test Set: 0.0104\n","output_type":"stream"},{"name":"stderr","text":"Generating Test Predictions:   0%|          | 0/4502 [00:00<?, ?it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>▁▃▄▅▆▄▆▄██</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▄▆▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>0.00711</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>train_char_accuracy</td><td>0.5961</td></tr><tr><td>train_loss</td><td>1.19713</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">transformer_d:128_nhead:16_layers:4</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/c2zi2lbu' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/c2zi2lbu</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250811_093811-c2zi2lbu/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run c2zi2lbu errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 302, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_56/1848154019.py\", line 361, in main\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     generate_predictions_csv(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_56/1848154019.py\", line 254, in generate_predictions_csv\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     output = model(src, generated_tokens, src_padding_mask=src_padding_mask, tgt_mask=tgt_mask, tgt_padding_mask=tgt_padding_mask)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m                                                            ^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m NameError: name 'src_padding_mask' is not defined\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport wandb\nfrom tqdm import tqdm\nimport math\nimport csv\nfrom collections import namedtuple\n\n# ---------------- Data Processing and Utilities ----------------\n\nclass TransliterationDataset(Dataset):\n    def __init__(self, pairs, input_vocab, output_vocab):\n        self.pairs = pairs\n        self.input_vocab = input_vocab\n        self.output_vocab = output_vocab\n        self.sos = output_vocab['<sos>']\n        self.eos = output_vocab['<eos>']\n        self.unk_in = input_vocab.get('<unk>', 1)\n        self.unk_out = output_vocab.get('<unk>', 3)\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        source, target = self.pairs[idx]\n        input_ids = [self.input_vocab.get(c, self.unk_in) for c in source]\n        target_ids = [self.sos] + [self.output_vocab.get(c, self.unk_out) for c in target] + [self.eos]\n        return torch.tensor(input_ids), torch.tensor(target_ids)\n\ndef build_vocab(pairs):\n    input_chars = set()\n    output_chars = set()\n    for src, tgt in pairs:\n        input_chars.update(src)\n        output_chars.update(tgt)\n    \n    input_vocab = {c: i + 2 for i, c in enumerate(sorted(input_chars))}\n    input_vocab['<pad>'] = 0\n    input_vocab['<unk>'] = 1\n    \n    output_vocab = {c: i + 4 for i, c in enumerate(sorted(output_chars))}\n    output_vocab.update({'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3})\n    \n    return input_vocab, output_vocab\n\ndef load_pairs(path):\n    df = pd.read_csv(path, sep='\\t', header=None, names=['target', 'source', 'count'], dtype=str)\n    df.dropna(subset=[\"source\", \"target\"], inplace=True)\n    return list(zip(df['source'], df['target']))\n\ndef collate_fn(batch):\n    inputs, targets = zip(*batch)\n    inputs_padded = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n    targets_padded = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=0)\n    return inputs_padded, targets_padded\n\n# ---------------- Transformer Specific Components ----------------\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout, max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:, :x.size(1), :]\n        return self.dropout(x)\n\nclass TransformerModel(nn.Module):\n    def __init__(self, input_vocab_size, output_vocab_size, d_model, nhead, num_encoder_layers,\n                 num_decoder_layers, dim_feedforward, dropout):\n        super().__init__()\n        \n        self.d_model = d_model\n        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model, padding_idx=0)\n        self.decoder_embedding = nn.Embedding(output_vocab_size, d_model, padding_idx=0)\n        self.positional_encoding = PositionalEncoding(d_model, dropout)\n        \n        self.transformer = nn.Transformer(\n            d_model=d_model,\n            nhead=nhead,\n            num_encoder_layers=num_encoder_layers,\n            num_decoder_layers=num_decoder_layers,\n            dim_feedforward=dim_feedforward,\n            dropout=dropout,\n            batch_first=True\n        )\n        \n        self.fc_out = nn.Linear(d_model, output_vocab_size)\n        self.output_vocab_size = output_vocab_size\n        self.sos_idx = 1\n        self.eos_idx = 2\n\n    # Corrected forward method signature\n    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_key_padding_mask=None, tgt_key_padding_mask=None):\n        src_embedded = self.positional_encoding(self.encoder_embedding(src) * math.sqrt(self.d_model))\n        tgt_embedded = self.positional_encoding(self.decoder_embedding(tgt) * math.sqrt(self.d_model))\n        \n        transformer_out = self.transformer(\n            src_embedded, tgt_embedded,\n            src_mask=src_mask,\n            tgt_mask=tgt_mask,\n            src_key_padding_mask=src_key_padding_mask,\n            tgt_key_padding_mask=tgt_key_padding_mask\n        )\n        \n        output = self.fc_out(transformer_out)\n        return output\n\n    def generate_square_subsequent_mask(self, sz):\n        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n        return mask\n\n    def create_padding_mask(self, seq, pad_idx=0):\n        return (seq == pad_idx)\n\n# ---------------- Training and Evaluation Functions ----------------\n\ndef accuracy(preds, targets, pad_idx=0):\n    pred_tokens = preds.argmax(dim=-1)\n    correct = ((pred_tokens == targets) & (targets != pad_idx)).sum().item()\n    total = (targets != pad_idx).sum().item()\n    return correct / total if total > 0 else 0.0\n\n@torch.no_grad()\ndef evaluate_word_accuracy(model, dataloader, device, output_vocab):\n    model.eval()\n    correct_words = 0\n    total_words = 0\n    inv_output_vocab = {v: k for k, v in output_vocab.items()}\n    \n    for src, tgt in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n\n        src_padding_mask = model.create_padding_mask(src).to(device)\n        batch_size = src.size(0)\n        max_len = 20\n        \n        generated_tokens = torch.full((batch_size, 1), model.sos_idx, dtype=torch.long, device=device)\n        \n        for t in range(max_len):\n            tgt_mask = model.generate_square_subsequent_mask(generated_tokens.size(1)).to(device)\n            tgt_padding_mask = model.create_padding_mask(generated_tokens).to(device)\n            \n            # Corrected keyword arguments\n            output = model(src, generated_tokens, \n                           src_key_padding_mask=src_padding_mask, \n                           tgt_key_padding_mask=tgt_padding_mask, \n                           tgt_mask=tgt_mask)\n            \n            next_token = output[:, -1, :].argmax(dim=-1).unsqueeze(1)\n            generated_tokens = torch.cat([generated_tokens, next_token], dim=1)\n            \n            if (next_token == model.eos_idx).all():\n                break\n\n        for i in range(batch_size):\n            pred_seq = generated_tokens[i]\n            target_seq = tgt[i]\n            \n            pred_end = (pred_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n            target_end = (target_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n            \n            pred_word = pred_seq[1:pred_end[0] if pred_end.numel() > 0 else len(pred_seq)]\n            target_word = target_seq[1:target_end[0] if target_end.numel() > 0 else len(target_seq)]\n\n            if torch.equal(pred_word, target_word):\n                correct_words += 1\n            total_words += 1\n            \n    return correct_words / total_words if total_words > 0 else 0.0\n\ndef train_epoch(model, loader, optimizer, criterion, device):\n    model.train()\n    total_loss, total_char_acc = 0, 0\n    for src, tgt in tqdm(loader, desc=\"Training\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n\n        optimizer.zero_grad()\n        \n        src_padding_mask = model.create_padding_mask(src).to(device)\n        tgt_input = tgt[:, :-1]\n        \n        tgt_padding_mask = model.create_padding_mask(tgt_input).to(device)\n        \n        tgt_output = tgt[:, 1:]\n\n        tgt_mask = model.generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n        \n        # Corrected keyword arguments\n        output = model(src, tgt_input, \n                       src_key_padding_mask=src_padding_mask, \n                       tgt_key_padding_mask=tgt_padding_mask, \n                       tgt_mask=tgt_mask)\n        \n        loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n        char_acc = accuracy(output, tgt_output)\n        \n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        total_char_acc += char_acc\n        \n    return total_loss / len(loader), total_char_acc / len(loader)\n\ndef generate_predictions_csv(model, dataloader, input_vocab, output_vocab, device, csv_path):\n    model.eval()\n    inv_input_vocab = {v: k for k, v in input_vocab.items()}\n    inv_output_vocab = {v: k for k, v in output_vocab.items()}\n    results = []\n\n    with torch.no_grad():\n        for src, tgt in tqdm(dataloader, desc=\"Generating Test Predictions\"):\n            src = src.to(device)\n            batch_size = src.size(0)\n            max_len = 20\n\n            src_padding_mask = model.create_padding_mask(src).to(device)\n            generated_tokens = torch.full((batch_size, 1), model.sos_idx, dtype=torch.long, device=device)\n            \n            for t in range(max_len):\n                tgt_mask = model.generate_square_subsequent_mask(generated_tokens.size(1)).to(device)\n                tgt_padding_mask = model.create_padding_mask(generated_tokens).to(device)\n                \n                # Corrected keyword arguments\n                output = model(src, generated_tokens, \n                               src_key_padding_mask=src_padding_mask, \n                               tgt_key_padding_mask=tgt_padding_mask, \n                               tgt_mask=tgt_mask)\n                \n                next_token = output[:, -1, :].argmax(dim=-1).unsqueeze(1)\n                generated_tokens = torch.cat([generated_tokens, next_token], dim=1)\n                \n                if (next_token == model.eos_idx).all():\n                    break\n\n            for i in range(batch_size):\n                pred_seq = generated_tokens[i]\n                target_seq = tgt[i]\n                \n                pred_end = (pred_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n                target_end = (target_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n                \n                pred_word_tokens = pred_seq[1:pred_end[0] if pred_end.numel() > 0 else len(pred_seq)]\n                truth_word_tokens = target_seq[1:target_end[0] if target_end.numel() > 0 else len(target_seq)]\n\n                pred_str = ''.join([inv_output_vocab[t.item()] for t in pred_word_tokens if t.item() not in [model.sos_idx, model.eos_idx, 0]])\n                truth_str = ''.join([inv_output_vocab[t.item()] for t in truth_word_tokens if t.item() not in [model.sos_idx, model.eos_idx, 0]])\n                inp_str = ''.join([inv_input_vocab[t.item()] for t in src[i] if t.item() != 0])\n                results.append((inp_str, pred_str, truth_str))\n    \n    with open(csv_path, mode='w', newline='', encoding='utf-8') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Input', 'Prediction', 'GroundTruth'])\n        writer.writerows(results)\n    print(f\"\\nPredictions saved to: {csv_path}\")\n\n# ---------------- Main Function for W&B Sweep ----------------\n\ndef main():\n    import wandb\n    \n    def generate_run_name(config):\n        return f\"transformer_d:{config.d_model}_nhead:{config.nhead}_layers:{config.num_encoder_layers}\"\n\n    wandb.init(project=\"Dakshina-Translitration-Transformer\", config=wandb.config)\n    config = wandb.config\n    wandb.run.name = generate_run_name(config)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    train_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    dev_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\")\n    test_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\")\n\n    # Build vocab on train + dev pairs for consistency\n    input_vocab, output_vocab = build_vocab(train_pairs + dev_pairs)\n    train_dataset = TransliterationDataset(train_pairs, input_vocab, output_vocab)\n    dev_dataset = TransliterationDataset(dev_pairs, input_vocab, output_vocab)\n    test_dataset = TransliterationDataset(test_pairs, input_vocab, output_vocab)\n\n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n    dev_loader = DataLoader(dev_dataset, batch_size=config.batch_size, shuffle=False, collate_fn=collate_fn)\n    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n\n    model = TransformerModel(\n        input_vocab_size=len(input_vocab),\n        output_vocab_size=len(output_vocab),\n        d_model=config.d_model,\n        nhead=config.nhead,\n        num_encoder_layers=config.num_encoder_layers,\n        num_decoder_layers=config.num_decoder_layers,\n        dim_feedforward=config.dim_feedforward,\n        dropout=config.dropout\n    ).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, betas=(0.9, 0.98), eps=1e-9)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    best_dev_acc = 0\n    # Training loop\n    for epoch in range(8):\n        train_loss, train_char_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n        dev_word_acc = evaluate_word_accuracy(model, dev_loader, device, output_vocab)\n        \n        print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Train Char Acc: {train_char_acc:.4f} | Dev Word Acc: {dev_word_acc:.4f}\")\n        \n        if dev_word_acc > best_dev_acc:\n            best_dev_acc = dev_word_acc\n            # Save the model with a unique filename using the W&B run ID\n            model_path = f'best_transformer_model_{wandb.run.id}.pth'\n            torch.save(model.state_dict(), model_path)\n            print(f\" -> New best model saved to {model_path} with dev word accuracy: {best_dev_acc:.4f}\")\n\n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss,\n            \"train_char_accuracy\": train_char_acc,\n            \"dev_word_accuracy\": dev_word_acc\n        })\n\n    print(\"\\nTraining complete. Loading best model for final evaluation on test set...\")\n    \n    # Load the best model found during this run\n    try:\n        model_path = f'best_transformer_model_{wandb.run.id}.pth'\n        model.load_state_dict(torch.load(model_path))\n    except FileNotFoundError:\n        print(\"Error: 'best_transformer_model.pth' not found. Ensure training completed successfully and model was saved.\")\n        return\n\n    final_test_word_acc = evaluate_word_accuracy(model, test_loader, device, output_vocab)\n    print(f\"\\n--- Final Test Set Evaluation Results ---\")\n    print(f\"Word-level Accuracy on Test Set: {final_test_word_acc:.4f}\")\n    \n    generate_predictions_csv(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")\n    print(\"Test predictions saved to test_predictions.csv\")\n\nif __name__ == \"__main__\":\n    sweep_config = {\n        \"method\": \"bayes\",\n        \"metric\": {\"name\": \"dev_word_accuracy\", \"goal\": \"maximize\"},\n        \"parameters\": {\n            \"d_model\": {\"values\": [128, 256, 512]},\n            \"nhead\": {\"values\": [4, 8, 16]},\n            \"num_encoder_layers\": {\"values\": [2, 4]},\n            \"num_decoder_layers\": {\"values\": [2, 4]},\n            \"dim_feedforward\": {\"values\": [512, 1024, 2048]},\n            \"dropout\": {\"values\": [0.1, 0.2, 0.3]},\n            \"lr\": {\"min\": 0.0001, \"max\": 0.001},\n            \"batch_size\": {\"values\": [16, 32, 64]}\n        }\n    }\n    \n    sweep_id = wandb.sweep(sweep_config, project=\"Dakshina-Translitration-Transformer\")\n    wandb.agent(sweep_id, function=main, count=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T07:11:49.473987Z","iopub.execute_input":"2025-08-12T07:11:49.474228Z","execution_failed":"2025-08-12T09:12:17.062Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: 1ht7n35v\nSweep URL: https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 45pzphlu with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00043491182926006633\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250812_071202-45pzphlu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/45pzphlu' target=\"_blank\">legendary-sweep-1</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/45pzphlu' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/45pzphlu</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/2763 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nEvaluating:   0%|          | 0/273 [00:00<?, ?it/s]          /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n  output = torch._nested_tensor_from_mask(\n                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 1.6346 | Train Char Acc: 0.4752 | Dev Word Acc: 0.0126\n -> New best model saved to best_transformer_model_45pzphlu.pth with dev word accuracy: 0.0126\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.3989 | Train Char Acc: 0.5331 | Dev Word Acc: 0.0108\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.3117 | Train Char Acc: 0.5576 | Dev Word Acc: 0.0223\n -> New best model saved to best_transformer_model_45pzphlu.pth with dev word accuracy: 0.0223\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.2548 | Train Char Acc: 0.5751 | Dev Word Acc: 0.0154\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 1.2121 | Train Char Acc: 0.5881 | Dev Word Acc: 0.0193\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 1.1810 | Train Char Acc: 0.5984 | Dev Word Acc: 0.0179\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 1.1485 | Train Char Acc: 0.6089 | Dev Word Acc: 0.0252\n -> New best model saved to best_transformer_model_45pzphlu.pth with dev word accuracy: 0.0252\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 1.1241 | Train Char Acc: 0.6167 | Dev Word Acc: 0.0151\n\nTraining complete. Loading best model for final evaluation on test set...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n--- Final Test Set Evaluation Results ---\nWord-level Accuracy on Test Set: 0.0295\n","output_type":"stream"},{"name":"stderr","text":"Generating Test Predictions: 100%|██████████| 4502/4502 [02:59<00:00, 25.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nPredictions saved to: test_predictions.csv\nTest predictions saved to test_predictions.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>▂▁▇▃▅▄█▃</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▄▅▆▇▇██</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>0.01514</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_char_accuracy</td><td>0.61672</td></tr><tr><td>train_loss</td><td>1.12414</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">transformer_d:512_nhead:16_layers:2</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/45pzphlu' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/45pzphlu</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250812_071202-45pzphlu/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d9h46hb7 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0005251776156309645\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250812_072824-d9h46hb7</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/d9h46hb7' target=\"_blank\">skilled-sweep-2</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/d9h46hb7' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/d9h46hb7</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/2763 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 1.6748 | Train Char Acc: 0.4716 | Dev Word Acc: 0.0057\n -> New best model saved to best_transformer_model_d9h46hb7.pth with dev word accuracy: 0.0057\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.2871 | Train Char Acc: 0.5692 | Dev Word Acc: 0.0122\n -> New best model saved to best_transformer_model_d9h46hb7.pth with dev word accuracy: 0.0122\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.1822 | Train Char Acc: 0.6012 | Dev Word Acc: 0.0227\n -> New best model saved to best_transformer_model_d9h46hb7.pth with dev word accuracy: 0.0227\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.1137 | Train Char Acc: 0.6234 | Dev Word Acc: 0.0241\n -> New best model saved to best_transformer_model_d9h46hb7.pth with dev word accuracy: 0.0241\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 1.0556 | Train Char Acc: 0.6410 | Dev Word Acc: 0.0186\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 1.0144 | Train Char Acc: 0.6548 | Dev Word Acc: 0.0273\n -> New best model saved to best_transformer_model_d9h46hb7.pth with dev word accuracy: 0.0273\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 0.9776 | Train Char Acc: 0.6673 | Dev Word Acc: 0.0202\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 0.9483 | Train Char Acc: 0.6770 | Dev Word Acc: 0.0211\n\nTraining complete. Loading best model for final evaluation on test set...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n--- Final Test Set Evaluation Results ---\nWord-level Accuracy on Test Set: 0.0198\n","output_type":"stream"},{"name":"stderr","text":"Generating Test Predictions: 100%|██████████| 4502/4502 [05:12<00:00, 14.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nPredictions saved to: test_predictions.csv\nTest predictions saved to test_predictions.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>▁▃▇▇▅█▆▆</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▄▅▆▇▇██</td></tr><tr><td>train_loss</td><td>█▄▃▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>0.02111</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_char_accuracy</td><td>0.677</td></tr><tr><td>train_loss</td><td>0.94827</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">transformer_d:256_nhead:16_layers:4</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/d9h46hb7' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/d9h46hb7</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250812_072824-d9h46hb7/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 46au1jj8 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0005160100581465826\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 8\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 4\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250812_075439-46au1jj8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/46au1jj8' target=\"_blank\">magic-sweep-3</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/46au1jj8' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/46au1jj8</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/691 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 2.6923 | Train Char Acc: 0.2304 | Dev Word Acc: 0.0007\n -> New best model saved to best_transformer_model_46au1jj8.pth with dev word accuracy: 0.0007\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 2.1088 | Train Char Acc: 0.3287 | Dev Word Acc: 0.0016\n -> New best model saved to best_transformer_model_46au1jj8.pth with dev word accuracy: 0.0016\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 2.0317 | Train Char Acc: 0.3453 | Dev Word Acc: 0.0041\n -> New best model saved to best_transformer_model_46au1jj8.pth with dev word accuracy: 0.0041\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.9745 | Train Char Acc: 0.3592 | Dev Word Acc: 0.0085\n -> New best model saved to best_transformer_model_46au1jj8.pth with dev word accuracy: 0.0085\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 1.9373 | Train Char Acc: 0.3679 | Dev Word Acc: 0.0060\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 1.9193 | Train Char Acc: 0.3732 | Dev Word Acc: 0.0048\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 1.8913 | Train Char Acc: 0.3809 | Dev Word Acc: 0.0076\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 1.8595 | Train Char Acc: 0.3888 | Dev Word Acc: 0.0108\n -> New best model saved to best_transformer_model_46au1jj8.pth with dev word accuracy: 0.0108\n\nTraining complete. Loading best model for final evaluation on test set...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n--- Final Test Set Evaluation Results ---\nWord-level Accuracy on Test Set: 0.0102\n","output_type":"stream"},{"name":"stderr","text":"Generating Test Predictions: 100%|██████████| 4502/4502 [04:02<00:00, 18.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nPredictions saved to: test_predictions.csv\nTest predictions saved to test_predictions.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>▁▂▃▆▅▄▆█</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>train_char_accuracy</td><td>▁▅▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dev_word_accuracy</td><td>0.01078</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>train_char_accuracy</td><td>0.38881</td></tr><tr><td>train_loss</td><td>1.8595</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">transformer_d:512_nhead:8_layers:4</strong> at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/46au1jj8' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/46au1jj8</a><br> View project at: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a><br>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250812_075439-46au1jj8/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6dlrfv2c with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \td_model: 512\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdim_feedforward: 1024\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.00026237109157088695\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnhead: 16\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'Dakshina-Translitration-Transformer' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.20.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250812_081041-6dlrfv2c</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/6dlrfv2c' target=\"_blank\">cool-sweep-4</a></strong> to <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/sweeps/1ht7n35v</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/6dlrfv2c' target=\"_blank\">https://wandb.ai/ma23c014-indian-institute-of-technology-madras/Dakshina-Translitration-Transformer/runs/6dlrfv2c</a>"},"metadata":{}},{"name":"stderr","text":"Training:   0%|          | 0/691 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\n                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1 | Train Loss: 1.9560 | Train Char Acc: 0.4012 | Dev Word Acc: 0.0021\n -> New best model saved to best_transformer_model_6dlrfv2c.pth with dev word accuracy: 0.0021\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2 | Train Loss: 1.5340 | Train Char Acc: 0.4958 | Dev Word Acc: 0.0057\n -> New best model saved to best_transformer_model_6dlrfv2c.pth with dev word accuracy: 0.0057\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3 | Train Loss: 1.4163 | Train Char Acc: 0.5292 | Dev Word Acc: 0.0089\n -> New best model saved to best_transformer_model_6dlrfv2c.pth with dev word accuracy: 0.0089\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4 | Train Loss: 1.3438 | Train Char Acc: 0.5491 | Dev Word Acc: 0.0067\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5 | Train Loss: 1.2897 | Train Char Acc: 0.5663 | Dev Word Acc: 0.0078\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6 | Train Loss: 1.2462 | Train Char Acc: 0.5790 | Dev Word Acc: 0.0096\n -> New best model saved to best_transformer_model_6dlrfv2c.pth with dev word accuracy: 0.0096\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7 | Train Loss: 1.2146 | Train Char Acc: 0.5894 | Dev Word Acc: 0.0106\n -> New best model saved to best_transformer_model_6dlrfv2c.pth with dev word accuracy: 0.0106\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8 | Train Loss: 1.1851 | Train Char Acc: 0.5984 | Dev Word Acc: 0.0128\n -> New best model saved to best_transformer_model_6dlrfv2c.pth with dev word accuracy: 0.0128\n\nTraining complete. Loading best model for final evaluation on test set...\n","output_type":"stream"},{"name":"stderr","text":"                                                               \r","output_type":"stream"},{"name":"stdout","text":"\n--- Final Test Set Evaluation Results ---\nWord-level Accuracy on Test Set: 0.0164\n","output_type":"stream"},{"name":"stderr","text":"Generating Test Predictions:  36%|███▋      | 1641/4502 [01:10<02:01, 23.51it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## For Test data","metadata":{}},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T09:15:52.131733Z","iopub.execute_input":"2025-08-12T09:15:52.131945Z","iopub.status.idle":"2025-08-12T09:15:52.140776Z","shell.execute_reply.started":"2025-08-12T09:15:52.131928Z","shell.execute_reply":"2025-08-12T09:15:52.140000Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nimport math\nimport csv\nfrom collections import namedtuple\n\n# ---------------- Data Processing and Utilities ----------------\n\nclass TransliterationDataset(Dataset):\n    \"\"\"\n    A PyTorch Dataset for transliteration data.\n    \"\"\"\n    def __init__(self, pairs, input_vocab, output_vocab):\n        self.pairs = pairs\n        self.input_vocab = input_vocab\n        self.output_vocab = output_vocab\n        self.sos = output_vocab['<sos>']\n        self.eos = output_vocab['<eos>']\n        self.unk_in = input_vocab.get('<unk>', 1)\n        self.unk_out = output_vocab.get('<unk>', 3)\n\n    def __len__(self):\n        return len(self.pairs)\n\n    def __getitem__(self, idx):\n        source, target = self.pairs[idx]\n        input_ids = [self.input_vocab.get(c, self.unk_in) for c in source]\n        target_ids = [self.sos] + [self.output_vocab.get(c, self.unk_out) for c in target] + [self.eos]\n        return torch.tensor(input_ids), torch.tensor(target_ids)\n\ndef build_vocab(pairs):\n    \"\"\"\n    Builds character-level vocabularies from a list of (source, target) pairs.\n    \"\"\"\n    input_chars = set()\n    output_chars = set()\n    for src, tgt in pairs:\n        input_chars.update(src)\n        output_chars.update(tgt)\n    \n    input_vocab = {c: i + 2 for i, c in enumerate(sorted(input_chars))}\n    input_vocab['<pad>'] = 0\n    input_vocab['<unk>'] = 1\n    \n    output_vocab = {c: i + 4 for i, c in enumerate(sorted(output_chars))}\n    output_vocab.update({'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3})\n    \n    return input_vocab, output_vocab\n\ndef load_pairs(path):\n    \"\"\"\n    Loads transliteration pairs from a TSV file.\n    \"\"\"\n    df = pd.read_csv(path, sep='\\t', header=None, names=['target', 'source', 'count'], dtype=str)\n    df.dropna(subset=[\"source\", \"target\"], inplace=True)\n    return list(zip(df['source'], df['target']))\n\ndef collate_fn(batch):\n    \"\"\"\n    Pads sequences in a batch to the same length.\n    \"\"\"\n    inputs, targets = zip(*batch)\n    inputs_padded = nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n    targets_padded = nn.utils.rnn.pad_sequence(targets, batch_first=True, padding_value=0)\n    return inputs_padded, targets_padded\n\n# ---------------- Transformer Specific Components ----------------\n\nclass PositionalEncoding(nn.Module):\n    \"\"\"\n    Injects positional information into the input embeddings.\n    \"\"\"\n    def __init__(self, d_model, dropout, max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:, :x.size(1), :]\n        return self.dropout(x)\n\nclass TransformerModel(nn.Module):\n    \"\"\"\n    The main Transformer model for sequence-to-sequence transliteration.\n    \"\"\"\n    def __init__(self, input_vocab_size, output_vocab_size, d_model, nhead, num_encoder_layers,\n                 num_decoder_layers, dim_feedforward, dropout):\n        super().__init__()\n        \n        self.d_model = d_model\n        self.encoder_embedding = nn.Embedding(input_vocab_size, d_model, padding_idx=0)\n        self.decoder_embedding = nn.Embedding(output_vocab_size, d_model, padding_idx=0)\n        self.positional_encoding = PositionalEncoding(d_model, dropout)\n        \n        self.transformer = nn.Transformer(\n            d_model=d_model,\n            nhead=nhead,\n            num_encoder_layers=num_encoder_layers,\n            num_decoder_layers=num_decoder_layers,\n            dim_feedforward=dim_feedforward,\n            dropout=dropout,\n            batch_first=True\n        )\n        \n        self.fc_out = nn.Linear(d_model, output_vocab_size)\n        self.output_vocab_size = output_vocab_size\n        self.sos_idx = 1\n        self.eos_idx = 2\n\n    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_key_padding_mask=None, tgt_key_padding_mask=None):\n        src_embedded = self.positional_encoding(self.encoder_embedding(src) * math.sqrt(self.d_model))\n        tgt_embedded = self.positional_encoding(self.decoder_embedding(tgt) * math.sqrt(self.d_model))\n        \n        transformer_out = self.transformer(\n            src_embedded, tgt_embedded,\n            src_mask=src_mask,\n            tgt_mask=tgt_mask,\n            src_key_padding_mask=src_key_padding_mask,\n            tgt_key_padding_mask=tgt_key_padding_mask\n        )\n        \n        output = self.fc_out(transformer_out)\n        return output\n\n    def generate_square_subsequent_mask(self, sz):\n        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n        return mask\n\n    def create_padding_mask(self, seq, pad_idx=0):\n        return (seq == pad_idx)\n\n# ---------------- Training and Evaluation Functions ----------------\n\ndef accuracy(preds, targets, pad_idx=0):\n    \"\"\"\n    Calculates character-level accuracy, ignoring padding tokens.\n    \"\"\"\n    pred_tokens = preds.argmax(dim=-1)\n    correct = ((pred_tokens == targets) & (targets != pad_idx)).sum().item()\n    total = (targets != pad_idx).sum().item()\n    return correct / total if total > 0 else 0.0\n\n@torch.no_grad()\ndef evaluate_and_sample(model, dataloader, device, input_vocab, output_vocab, num_samples=10):\n    \"\"\"\n    Evaluates the model's word-level accuracy and returns a sample of predictions.\n    \"\"\"\n    model.eval()\n    correct_words = 0\n    total_words = 0\n    \n    inv_input_vocab = {v: k for k, v in input_vocab.items()}\n    inv_output_vocab = {v: k for k, v in output_vocab.items()}\n    sample_predictions = []\n    samples_collected = 0\n\n    for src, tgt in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n\n        src_padding_mask = model.create_padding_mask(src).to(device)\n        batch_size = src.size(0)\n        max_len = 20\n        \n        generated_tokens = torch.full((batch_size, 1), model.sos_idx, dtype=torch.long, device=device)\n        \n        for t in range(max_len):\n            tgt_mask = model.generate_square_subsequent_mask(generated_tokens.size(1)).to(device)\n            tgt_padding_mask = model.create_padding_mask(generated_tokens).to(device)\n            \n            output = model(src, generated_tokens, \n                           src_key_padding_mask=src_padding_mask, \n                           tgt_key_padding_mask=tgt_padding_mask, \n                           tgt_mask=tgt_mask)\n            \n            next_token = output[:, -1, :].argmax(dim=-1).unsqueeze(1)\n            generated_tokens = torch.cat([generated_tokens, next_token], dim=1)\n            \n            if (next_token == model.eos_idx).all():\n                break\n\n        for i in range(batch_size):\n            pred_seq = generated_tokens[i]\n            target_seq = tgt[i]\n            \n            pred_end = (pred_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n            target_end = (target_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n            \n            pred_word = pred_seq[1:pred_end[0] if pred_end.numel() > 0 else len(pred_seq)]\n            target_word = target_seq[1:target_end[0] if target_end.numel() > 0 else len(target_seq)]\n\n            if torch.equal(pred_word, target_word):\n                correct_words += 1\n            total_words += 1\n            \n            if samples_collected < num_samples:\n                inp_str = ''.join([inv_input_vocab[t.item()] for t in src[i] if t.item() != 0])\n                pred_str = ''.join([inv_output_vocab.get(t.item(), '<unk>') for t in pred_word if t.item() not in [model.sos_idx, model.eos_idx, 0]])\n                truth_str = ''.join([inv_output_vocab.get(t.item(), '<unk>') for t in target_word if t.item() not in [model.sos_idx, model.eos_idx, 0]])\n                sample_predictions.append((inp_str, pred_str, truth_str))\n                samples_collected += 1\n            \n    return correct_words / total_words if total_words > 0 else 0.0, sample_predictions\n\ndef train_epoch(model, loader, optimizer, criterion, device):\n    \"\"\"\n    Trains the model for one epoch.\n    \"\"\"\n    model.train()\n    total_loss, total_char_acc = 0, 0\n    for src, tgt in tqdm(loader, desc=\"Training\", leave=False):\n        src, tgt = src.to(device), tgt.to(device)\n\n        optimizer.zero_grad()\n        \n        src_padding_mask = model.create_padding_mask(src).to(device)\n        tgt_input = tgt[:, :-1]\n        \n        tgt_padding_mask = model.create_padding_mask(tgt_input).to(device)\n        \n        tgt_output = tgt[:, 1:]\n\n        tgt_mask = model.generate_square_subsequent_mask(tgt_input.size(1)).to(device)\n        \n        output = model(src, tgt_input, \n                       src_key_padding_mask=src_padding_mask, \n                       tgt_key_padding_mask=tgt_padding_mask, \n                       tgt_mask=tgt_mask)\n        \n        loss = criterion(output.reshape(-1, output.size(-1)), tgt_output.reshape(-1))\n        char_acc = accuracy(output, tgt_output)\n        \n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        total_char_acc += char_acc\n        \n    return total_loss / len(loader), total_char_acc / len(loader)\n\ndef generate_predictions_csv(model, dataloader, input_vocab, output_vocab, device, csv_path):\n    \"\"\"\n    Generates predictions for a test set and saves them to a CSV file.\n    \"\"\"\n    model.eval()\n    inv_input_vocab = {v: k for k, v in input_vocab.items()}\n    inv_output_vocab = {v: k for k, v in output_vocab.items()}\n    results = []\n\n    with torch.no_grad():\n        for src, tgt in tqdm(dataloader, desc=\"Generating Test Predictions\"):\n            src = src.to(device)\n            batch_size = src.size(0)\n            max_len = 20\n\n            src_padding_mask = model.create_padding_mask(src).to(device)\n            generated_tokens = torch.full((batch_size, 1), model.sos_idx, dtype=torch.long, device=device)\n            \n            for t in range(max_len):\n                tgt_mask = model.generate_square_subsequent_mask(generated_tokens.size(1)).to(device)\n                tgt_padding_mask = model.create_padding_mask(generated_tokens).to(device)\n                \n                output = model(src, generated_tokens, \n                               src_key_padding_mask=src_padding_mask, \n                               tgt_key_padding_mask=tgt_padding_mask, \n                               tgt_mask=tgt_mask)\n                \n                next_token = output[:, -1, :].argmax(dim=-1).unsqueeze(1)\n                generated_tokens = torch.cat([generated_tokens, next_token], dim=1)\n                \n                if (next_token == model.eos_idx).all():\n                    break\n\n            for i in range(batch_size):\n                pred_seq = generated_tokens[i]\n                target_seq = tgt[i]\n                \n                pred_end = (pred_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n                target_end = (target_seq == model.eos_idx).nonzero(as_tuple=True)[0]\n                \n                pred_word_tokens = pred_seq[1:pred_end[0] if pred_end.numel() > 0 else len(pred_seq)]\n                truth_word_tokens = target_seq[1:target_end[0] if target_end.numel() > 0 else len(target_seq)]\n\n                pred_str = ''.join([inv_output_vocab.get(t.item(), '<unk>') for t in pred_word_tokens if t.item() not in [model.sos_idx, model.eos_idx, 0]])\n                truth_str = ''.join([inv_output_vocab.get(t.item(), '<unk>') for t in truth_word_tokens if t.item() not in [model.sos_idx, model.eos_idx, 0]])\n                inp_str = ''.join([inv_input_vocab.get(t.item(), '<unk>') for t in src[i] if t.item() != 0])\n                results.append((inp_str, pred_str, truth_str))\n    \n    with open(csv_path, mode='w', newline='', encoding='utf-8') as f:\n        writer = csv.writer(f)\n        writer.writerow(['Input', 'Prediction', 'GroundTruth'])\n        writer.writerows(results)\n    print(f\"\\nPredictions saved to: {csv_path}\")\n\n# ---------------- Main Function ----------------\n\ndef main():\n    # Model Hyperparameters\n    # These are fixed values for a simple run.\n    # You can change them to explore different configurations.\n    config = namedtuple(\"Config\", [\n        \"d_model\", \"nhead\", \"num_encoder_layers\", \"num_decoder_layers\",\n        \"dim_feedforward\", \"dropout\", \"lr\", \"batch_size\", \"num_epochs\"\n    ])(\n        d_model=256,\n        nhead=4,\n        num_encoder_layers=4,\n        num_decoder_layers=2,\n        dim_feedforward=1024,\n        dropout=0.1,\n        lr=0.0005,\n        batch_size=32,\n        num_epochs=10\n    )\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n\n    # Load data\n    train_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv\")\n    dev_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv\")\n    test_pairs = load_pairs(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv\")\n\n    # Build vocab on train + dev pairs for consistency\n    input_vocab, output_vocab = build_vocab(train_pairs + dev_pairs)\n    train_dataset = TransliterationDataset(train_pairs, input_vocab, output_vocab)\n    dev_dataset = TransliterationDataset(dev_pairs, input_vocab, output_vocab)\n    test_dataset = TransliterationDataset(test_pairs, input_vocab, output_vocab)\n\n    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, collate_fn=collate_fn)\n    dev_loader = DataLoader(dev_dataset, batch_size=config.batch_size, shuffle=False, collate_fn=collate_fn)\n    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n\n    model = TransformerModel(\n        input_vocab_size=len(input_vocab),\n        output_vocab_size=len(output_vocab),\n        d_model=config.d_model,\n        nhead=config.nhead,\n        num_encoder_layers=config.num_encoder_layers,\n        num_decoder_layers=config.num_decoder_layers,\n        dim_feedforward=config.dim_feedforward,\n        dropout=config.dropout\n    ).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, betas=(0.9, 0.98), eps=1e-9)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    best_dev_acc = 0\n    best_model_path = 'best_transformer_model.pth'\n\n    # Training loop\n    for epoch in range(config.num_epochs):\n        train_loss, _ = train_epoch(model, train_loader, optimizer, criterion, device)\n        dev_word_acc, dev_samples = evaluate_and_sample(model, dev_loader, device, input_vocab, output_vocab, num_samples=10)\n        \n        print(f\"\\nEpoch {epoch+1} Train Loss: {train_loss:.4f}\\n\")\n        print(f\" Test Accuracy: {dev_word_acc:.2%}\")\n        for inp, pred, truth in dev_samples:\n            print(f\"{inp:<15}| Pred: {pred:<20}| Truth: {truth}\")\n        \n        if dev_word_acc > best_dev_acc:\n            best_dev_acc = dev_word_acc\n            torch.save(model.state_dict(), best_model_path)\n            print(f\"\\n -> New best model saved to {best_model_path} with dev word accuracy: {best_dev_acc:.4f}\")\n\n    print(\"\\n Loading best model for final evaluation...\")\n    \n    # Load the best model found during this run\n    try:\n        model.load_state_dict(torch.load(best_model_path))\n    except FileNotFoundError:\n        print(\"Error: Best model checkpoint not found. Using the last trained model.\")\n        \n    final_test_word_acc, test_samples = evaluate_and_sample(model, test_loader, device, input_vocab, output_vocab, num_samples=10)\n    print(f\"\\n Final Test Accuracy: {final_test_word_acc:.2%}\")\n    for inp, pred, truth in test_samples:\n        print(f\"{inp:<15}| Pred: {pred:<20}| Truth: {truth}\")\n    \n    generate_predictions_csv(model, test_loader, input_vocab, output_vocab, device, csv_path=\"test_predictions.csv\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-12T09:15:57.845954Z","iopub.execute_input":"2025-08-12T09:15:57.846267Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/1382 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n  warnings.warn(\nEvaluating:   0%|          | 0/137 [00:00<?, ?it/s]          /usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n  output = torch._nested_tensor_from_mask(\n                                                             \r","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1 Train Loss: 1.6923\n\n Test Accuracy: 0.80%\nankan          | Pred: काना                | Truth: अंकन\nangkor         | Pred: कार्णग              | Truth: अंगकोर\nangira         | Pred: अंग्री              | Truth: अंगिरा\nangithi        | Pred: इंग्थिया            | Truth: अंगीठी\nangrej         | Pred: जरेंग               | Truth: अंग्रेज\nangrejon       | Pred: जारों               | Truth: अंग्रेजों\nanjaam         | Pred: मजना                | Truth: अंजाम\nanjam          | Pred: मजना                | Truth: अंजाम\nantakaran      | Pred: नात्रक              | Truth: अंतकरण\nantkaran       | Pred: नात्रक              | Truth: अंतकरण\n\n -> New best model saved to best_transformer_model.pth with dev word accuracy: 0.0080\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2 Train Loss: 1.3372\n\n Test Accuracy: 1.49%\nankan          | Pred: कानार्ण             | Truth: अंकन\nangkor         | Pred: कर्गों              | Truth: अंगकोर\nangira         | Pred: गरणिर्णा            | Truth: अंगिरा\nangithi        | Pred: गित्नि              | Truth: अंगीठी\nangrej         | Pred: जार्गंजी            | Truth: अंग्रेज\nangrejon       | Pred: जानोर्गं            | Truth: अंग्रेजों\nanjaam         | Pred: माजन                | Truth: अंजाम\nanjam          | Pred: मजान                | Truth: अंजाम\nantakaran      | Pred: नतर्कतारण           | Truth: अंतकरण\nantkaran       | Pred: नात्रकरण            | Truth: अंतकरण\n\n -> New best model saved to best_transformer_model.pth with dev word accuracy: 0.0149\n","output_type":"stream"},{"name":"stderr","text":"                                                             \r","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3 Train Loss: 1.2232\n\n Test Accuracy: 1.65%\nankan          | Pred: कान्नायक            | Truth: अंकन\nangkor         | Pred: कार्गणोंकर          | Truth: अंगकोर\nangira         | Pred: निग्रारण            | Truth: अंगिरा\nangithi        | Pred: निघट                | Truth: अंगीठी\nangrej         | Pred: राजनगीर             | Truth: अंग्रेज\nangrejon       | Pred: रांगजन              | Truth: अंग्रेजों\nanjaam         | Pred: जमन्मान             | Truth: अंजाम\nanjam          | Pred: जमन्मान             | Truth: अंजाम\nantakaran      | Pred: नाकार्तानक          | Truth: अंतकरण\nantkaran       | Pred: नाक्रतान            | Truth: अंतकरण\n\n -> New best model saved to best_transformer_model.pth with dev word accuracy: 0.0165\n","output_type":"stream"},{"name":"stderr","text":"Training:  19%|█▉        | 264/1382 [00:06<00:24, 46.34it/s]","output_type":"stream"}],"execution_count":null}]}