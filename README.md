# Hindi-Transliteration-Seq2Seq-vs-Transformer
Developed and evaluated Hindi transliteration models using the Dakshina dataset, implementing both Seq2Seq (RNN/GRU/LSTM) and Transformer architectures. Performed hyperparameter optimization with Bayesian sweeps in Weights &amp; Biases, achieving improved accuracy and comparative analysis of both approaches.
